{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"WCNN_training_scale=2.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a8ZwrAfjd580","executionInfo":{"status":"ok","timestamp":1620788043289,"user_tz":-540,"elapsed":1488,"user":{"displayName":"김정기","photoUrl":"","userId":"02654207523640478753"}},"outputId":"44ef2a68-1d9a-4d95-c51b-b1f595da4099"},"source":["# 모델 정의\n","\n","import os\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision.transforms import *\n","import torch\n","import math\n","from os.path import join\n","import torch.utils.data as data\n","import numpy as np\n","from os import listdir\n","from os.path import join\n","from PIL import Image, ImageOps\n","import random\n","from random import randrange\n","from math import sqrt\n","from torchsummary import summary\n","\n","'''\n","1. Channel_weighted_Conv\n","   어떤 '한개의' filter 에 대해, \n","   입력 [r^2, N, N] 인 feature map 의 각 channel 의 conv. 결과를 순차적으로 mapping 한 [1, rN, rN] 크기의 feature map 생성하고,\n","   생성한 feature map 에 rxr inner filtering 을 적용한 [1, N, N] 크기의 결과를 출력하는 함수 \n","'''\n","class Channel_weighted_Conv(nn.Module):\n","  def __init__(self, input_size, kernel_size, stride=1, bias=True):\n","    super(Channel_weighted_Conv, self).__init__()\n","    self.input_size = input_size \n","    # input_size = r^2\n","\n","    self.conv = torch.nn.Conv2d(1, 1, kernel_size, stride, padding=int((kernel_size-1)/2), bias=bias)\n","    # 입력 feature map [batch, r^2, N, N]에서 [batch, i, N, N] 을 입력으로 받아 1 개의 feature map 출력\n","    # 출력이 [batch, i, N, N] 가 되게 하기 위해 padding = int((kernel_size-1)/2)\n","    self.PS =  nn.PixelShuffle (upscale_factor = int(math.sqrt(input_size)))\n","    # upscale_factor = r\n","    self.inner_conv = torch.nn.Conv2d(1, 1, kernel_size=int(math.sqrt(input_size)), stride=int(math.sqrt(input_size)), padding=0, bias=bias)\n","\n","    '''\n","    apply 함수로 initialization 하기 힘들기 때문에 class 내에서 initialization 을 수행하도록 함\n","    '''\n","    for m in self.modules():\n","        # 이 class 에서 정의한 self.(변수)[인스턴스 변수] 목록 (conv, PS, inner_conv) 불러오기 \n","            classname = m.__class__.__name__\n","            # 불러온 module의 class 이름\n","            if classname.find('Conv2d') != -1:\n","                torch.nn.init.kaiming_normal_(m.weight)\n","                if m.bias is not None:\n","                    m.bias.data.zero_()\n","            # Conv2d Layer 라면 He 방법으로 해당 Layer 의 weight 들을 초기화, bias 가 True 면 bias 를 0 으로 초기화\n","            elif classname.find('ConvTranspose2d') != -1:\n","                torch.nn.init.kaiming_normal_(m.weight)\n","                if m.bias is not None:\n","                    m.bias.data.zero_()\n","           # ConvTranspose2d Layer 라면 He 방법으로 해당 Layer 의 weight 들을 초기화, bias 가 True 면 bias 를 0 으로 초기화\n","\n","  def forward(self, x):\n","    s = self.conv(x[:, 0:1, :, :])\n","\n","    for i in range(1, self.input_size):\n","      m = self.conv(x[:, i:i+1, :, :])\n","      s = torch.cat([s, m], dim=1)\n","      \n","    # s.shape = [batch, r^2, N, N]\n","    # s = 입력 feature map의 각 channel에 대해 한개의 filter 와의 단순 convolution 결과 feature map\n","    \n","    ps = self.PS(s)\n","    # ps.shape = [batch, 1, rN, rN]\n","    # ps = 한 filter에 대해 입력 feature map 의 각 channel 가중치를 학습하기 전 feature map\n","\n","    out = self.inner_conv(ps)\n","    # out.shape = [batch, 1, N, N]\n","    # out = 가중치를 학습하고 난 후 필터링 결과\n","    return out\n","\n","'''\n","2. WCNN_block \n","   기존의 Conv2d 와 같은 입력을 받아, 각 Channel 의 가중치 (inner_filter) 를 학습하는 과정을 추가하여\n","   입력과 동일한 크기의 output_size 개 만큼의 feature map 을 출력하는 New Conv2d layer\n","'''\n","class WCNN_block(nn.Module):\n","  def __init__(self, input_size, output_size, kernel_size):\n","    super(WCNN_block, self).__init__()\n","    self.filters = [0]*output_size\n","\n","    '''\n","    여기서 filter 갯수(=output_size)만큼 Channel_weighted_Conv 을 list 형태로 담고,\n","    '''\n","    self.filters = nn.ModuleList([Channel_weighted_Conv(input_size, kernel_size, stride=1, bias=True) for _ in range(0, output_size)])\n","    self.filter_num = output_size\n","  \n","  def forward(self, x):\n","    '''\n","    여기서 각 Channel_weighted_Conv에 x(입력) 를 대입하고 나온 출력을 concatenation 해 준다.\n","    -> ModuleList 는 list 안의 각 Module 을 하나씩 접근 할 수 있게 해 줌\n","    '''\n","    out = self.filters[0](x)\n","    for i in range(1, self.filter_num):\n","      filtering = self.filters[i](x)\n","      out = torch.cat([out, filtering], dim=1)\n","    # out.shape = [batch, K, N, N]\n","    # out = 각 filter 들의 WCNN 결과의 concatenation\n","    return out\n","\n","'''\n","3. ConvBlock\n","'''\n","class ConvBlock(nn.Module):\n","    def __init__(self, input_size, output_size, kernel_size=3, stride=1, padding=1, bias=True, activation='relu', norm=None):\n","        super(ConvBlock, self).__init__()\n","        self.conv = torch.nn.Conv2d(input_size, output_size, kernel_size, stride, padding, bias=bias)\n","\n","        self.norm = norm\n","        if self.norm =='batch':\n","            self.bn = torch.nn.BatchNorm2d(output_size)\n","        elif self.norm == 'instance':\n","            self.bn = torch.nn.InstanceNorm2d(output_size)\n","        \n","        # self.bn : Conv Layer 출력에서 normalization 을 Instance 로 할지 Batch 로 할지 선택\n","        \n","        self.activation = activation\n","        if self.activation == 'relu':\n","            self.act = torch.nn.ReLU(True)\n","        elif self.activation == 'prelu':\n","            self.act = torch.nn.PReLU()\n","        elif self.activation == 'lrelu':\n","            self.act = torch.nn.LeakyReLU(0.2, True)\n","        elif self.activation == 'tanh':\n","            self.act = torch.nn.Tanh()\n","        elif self.activation == 'sigmoid':\n","            self.act = torch.nn.Sigmoid()\n","        \n","        # self.act : Conv Layer 출력 Activation Function 선택\n","\n","        for m in self.modules():\n","            classname = m.__class__.__name__\n","            if classname.find('Conv2d') != -1:\n","                torch.nn.init.kaiming_normal_(m.weight)\n","                if m.bias is not None:\n","                    m.bias.data.zero_()\n","            # Conv2d Layer 라면 He 방법으로 해당 Layer 의 weight 들을 초기화, bias 가 True 면 bias 를 0 으로 초기화\n","            elif classname.find('ConvTranspose2d') != -1:\n","                torch.nn.init.kaiming_normal_(m.weight)\n","                if m.bias is not None:\n","                    m.bias.data.zero_()\n","           # ConvTranspose2d Layer 라면 He 방법으로 해당 Layer 의 weight 들을 초기화, bias 가 True 면 bias 를 0 으로 초기화\n","        \n","    def forward(self, x):\n","        if self.norm is not None:\n","            out = self.bn(self.conv(x))\n","        else:\n","            out = self.conv(x)\n","\n","        if self.activation is not None:\n","            return self.act(out)\n","        else:\n","            return out\n","\n","'''\n","4. WCNN\n","'''\n","class WCNN(nn.Module):\n","    def __init__(self):\n","        super(WCNN, self).__init__()\n","        \n","        '''\n","        1. layer2 만을 WCNN_block 으로 바꿈\n","        2. WCNN_block 의 input_size = r^2 이어야 하는 것을 유의함\n","        '''\n","        self.layer1 = ConvBlock(3, 64, kernel_size=9, stride=1, padding=4, activation='relu', norm=None)\n","        self.layer2 = nn.Sequential(\n","            WCNN_block(input_size=64, output_size=32, kernel_size=3),\n","            nn.ReLU(),\n","        )\n","        # WCNN_block 의 Kernel_size = 홀수 여야 출력이미지의 size 가 입력과 같아진다\n","        self.layer3 = self.layer3 = ConvBlock(32, 3, kernel_size=5, stride=1, padding=2, activation=None, norm=None)\n","\n","    def forward(self, x):\n","        f1 = self.layer1(x)\n","        f2 = self.layer2(f1)\n","        y = self.layer3(f2)\n","        \n","        return y\n","print('finish')\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["finish\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LbuS2FoTv_Ai","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620736339270,"user_tz":-540,"elapsed":2006,"user":{"displayName":"김정기","photoUrl":"","userId":"02654207523640478753"}},"outputId":"32f1bde2-d27c-4070-a93d-0e7828d91ae7"},"source":["# 모델 확인\n","\n","import os\n","import torch\n","import torch.nn as nn\n","import torch.backends.cudnn as cudnn\n","from google.colab import drive\n","\n","\n","drive.mount('/content/gdrive')\n","\n","'''\n","1. GPU 설정 및 parameter print\n","'''\n","gpus_list = range(1)\n","cudnn.benchmark = True\n","\n","cuda = True\n","if cuda and not torch.cuda.is_available():\n","    raise Exception(\"No GPU found, please run without --cuda\")\n","\n","model = WCNN()\n","\n","'''\n","4. GPU 사용 여부 및 pretrained model 사용 여부 설정\n","'''\n","if cuda:\n","    model = model.cuda(gpus_list[0])\n","    model = torch.nn.DataParallel(model, device_ids=gpus_list)\n","    \n","summary(model, (3,32,32))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 64, 32, 32]          15,616\n","              ReLU-2           [-1, 64, 32, 32]               0\n","         ConvBlock-3           [-1, 64, 32, 32]               0\n","            Conv2d-4            [-1, 1, 32, 32]              10\n","            Conv2d-5            [-1, 1, 32, 32]              10\n","            Conv2d-6            [-1, 1, 32, 32]              10\n","            Conv2d-7            [-1, 1, 32, 32]              10\n","            Conv2d-8            [-1, 1, 32, 32]              10\n","            Conv2d-9            [-1, 1, 32, 32]              10\n","           Conv2d-10            [-1, 1, 32, 32]              10\n","           Conv2d-11            [-1, 1, 32, 32]              10\n","           Conv2d-12            [-1, 1, 32, 32]              10\n","           Conv2d-13            [-1, 1, 32, 32]              10\n","           Conv2d-14            [-1, 1, 32, 32]              10\n","           Conv2d-15            [-1, 1, 32, 32]              10\n","           Conv2d-16            [-1, 1, 32, 32]              10\n","           Conv2d-17            [-1, 1, 32, 32]              10\n","           Conv2d-18            [-1, 1, 32, 32]              10\n","           Conv2d-19            [-1, 1, 32, 32]              10\n","           Conv2d-20            [-1, 1, 32, 32]              10\n","           Conv2d-21            [-1, 1, 32, 32]              10\n","           Conv2d-22            [-1, 1, 32, 32]              10\n","           Conv2d-23            [-1, 1, 32, 32]              10\n","           Conv2d-24            [-1, 1, 32, 32]              10\n","           Conv2d-25            [-1, 1, 32, 32]              10\n","           Conv2d-26            [-1, 1, 32, 32]              10\n","           Conv2d-27            [-1, 1, 32, 32]              10\n","           Conv2d-28            [-1, 1, 32, 32]              10\n","           Conv2d-29            [-1, 1, 32, 32]              10\n","           Conv2d-30            [-1, 1, 32, 32]              10\n","           Conv2d-31            [-1, 1, 32, 32]              10\n","           Conv2d-32            [-1, 1, 32, 32]              10\n","           Conv2d-33            [-1, 1, 32, 32]              10\n","           Conv2d-34            [-1, 1, 32, 32]              10\n","           Conv2d-35            [-1, 1, 32, 32]              10\n","           Conv2d-36            [-1, 1, 32, 32]              10\n","           Conv2d-37            [-1, 1, 32, 32]              10\n","           Conv2d-38            [-1, 1, 32, 32]              10\n","           Conv2d-39            [-1, 1, 32, 32]              10\n","           Conv2d-40            [-1, 1, 32, 32]              10\n","           Conv2d-41            [-1, 1, 32, 32]              10\n","           Conv2d-42            [-1, 1, 32, 32]              10\n","           Conv2d-43            [-1, 1, 32, 32]              10\n","           Conv2d-44            [-1, 1, 32, 32]              10\n","           Conv2d-45            [-1, 1, 32, 32]              10\n","           Conv2d-46            [-1, 1, 32, 32]              10\n","           Conv2d-47            [-1, 1, 32, 32]              10\n","           Conv2d-48            [-1, 1, 32, 32]              10\n","           Conv2d-49            [-1, 1, 32, 32]              10\n","           Conv2d-50            [-1, 1, 32, 32]              10\n","           Conv2d-51            [-1, 1, 32, 32]              10\n","           Conv2d-52            [-1, 1, 32, 32]              10\n","           Conv2d-53            [-1, 1, 32, 32]              10\n","           Conv2d-54            [-1, 1, 32, 32]              10\n","           Conv2d-55            [-1, 1, 32, 32]              10\n","           Conv2d-56            [-1, 1, 32, 32]              10\n","           Conv2d-57            [-1, 1, 32, 32]              10\n","           Conv2d-58            [-1, 1, 32, 32]              10\n","           Conv2d-59            [-1, 1, 32, 32]              10\n","           Conv2d-60            [-1, 1, 32, 32]              10\n","           Conv2d-61            [-1, 1, 32, 32]              10\n","           Conv2d-62            [-1, 1, 32, 32]              10\n","           Conv2d-63            [-1, 1, 32, 32]              10\n","           Conv2d-64            [-1, 1, 32, 32]              10\n","           Conv2d-65            [-1, 1, 32, 32]              10\n","           Conv2d-66            [-1, 1, 32, 32]              10\n","           Conv2d-67            [-1, 1, 32, 32]              10\n","     PixelShuffle-68          [-1, 1, 256, 256]               0\n","           Conv2d-69            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-70            [-1, 1, 32, 32]               0\n","           Conv2d-71            [-1, 1, 32, 32]              10\n","           Conv2d-72            [-1, 1, 32, 32]              10\n","           Conv2d-73            [-1, 1, 32, 32]              10\n","           Conv2d-74            [-1, 1, 32, 32]              10\n","           Conv2d-75            [-1, 1, 32, 32]              10\n","           Conv2d-76            [-1, 1, 32, 32]              10\n","           Conv2d-77            [-1, 1, 32, 32]              10\n","           Conv2d-78            [-1, 1, 32, 32]              10\n","           Conv2d-79            [-1, 1, 32, 32]              10\n","           Conv2d-80            [-1, 1, 32, 32]              10\n","           Conv2d-81            [-1, 1, 32, 32]              10\n","           Conv2d-82            [-1, 1, 32, 32]              10\n","           Conv2d-83            [-1, 1, 32, 32]              10\n","           Conv2d-84            [-1, 1, 32, 32]              10\n","           Conv2d-85            [-1, 1, 32, 32]              10\n","           Conv2d-86            [-1, 1, 32, 32]              10\n","           Conv2d-87            [-1, 1, 32, 32]              10\n","           Conv2d-88            [-1, 1, 32, 32]              10\n","           Conv2d-89            [-1, 1, 32, 32]              10\n","           Conv2d-90            [-1, 1, 32, 32]              10\n","           Conv2d-91            [-1, 1, 32, 32]              10\n","           Conv2d-92            [-1, 1, 32, 32]              10\n","           Conv2d-93            [-1, 1, 32, 32]              10\n","           Conv2d-94            [-1, 1, 32, 32]              10\n","           Conv2d-95            [-1, 1, 32, 32]              10\n","           Conv2d-96            [-1, 1, 32, 32]              10\n","           Conv2d-97            [-1, 1, 32, 32]              10\n","           Conv2d-98            [-1, 1, 32, 32]              10\n","           Conv2d-99            [-1, 1, 32, 32]              10\n","          Conv2d-100            [-1, 1, 32, 32]              10\n","          Conv2d-101            [-1, 1, 32, 32]              10\n","          Conv2d-102            [-1, 1, 32, 32]              10\n","          Conv2d-103            [-1, 1, 32, 32]              10\n","          Conv2d-104            [-1, 1, 32, 32]              10\n","          Conv2d-105            [-1, 1, 32, 32]              10\n","          Conv2d-106            [-1, 1, 32, 32]              10\n","          Conv2d-107            [-1, 1, 32, 32]              10\n","          Conv2d-108            [-1, 1, 32, 32]              10\n","          Conv2d-109            [-1, 1, 32, 32]              10\n","          Conv2d-110            [-1, 1, 32, 32]              10\n","          Conv2d-111            [-1, 1, 32, 32]              10\n","          Conv2d-112            [-1, 1, 32, 32]              10\n","          Conv2d-113            [-1, 1, 32, 32]              10\n","          Conv2d-114            [-1, 1, 32, 32]              10\n","          Conv2d-115            [-1, 1, 32, 32]              10\n","          Conv2d-116            [-1, 1, 32, 32]              10\n","          Conv2d-117            [-1, 1, 32, 32]              10\n","          Conv2d-118            [-1, 1, 32, 32]              10\n","          Conv2d-119            [-1, 1, 32, 32]              10\n","          Conv2d-120            [-1, 1, 32, 32]              10\n","          Conv2d-121            [-1, 1, 32, 32]              10\n","          Conv2d-122            [-1, 1, 32, 32]              10\n","          Conv2d-123            [-1, 1, 32, 32]              10\n","          Conv2d-124            [-1, 1, 32, 32]              10\n","          Conv2d-125            [-1, 1, 32, 32]              10\n","          Conv2d-126            [-1, 1, 32, 32]              10\n","          Conv2d-127            [-1, 1, 32, 32]              10\n","          Conv2d-128            [-1, 1, 32, 32]              10\n","          Conv2d-129            [-1, 1, 32, 32]              10\n","          Conv2d-130            [-1, 1, 32, 32]              10\n","          Conv2d-131            [-1, 1, 32, 32]              10\n","          Conv2d-132            [-1, 1, 32, 32]              10\n","          Conv2d-133            [-1, 1, 32, 32]              10\n","          Conv2d-134            [-1, 1, 32, 32]              10\n","    PixelShuffle-135          [-1, 1, 256, 256]               0\n","          Conv2d-136            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-137            [-1, 1, 32, 32]               0\n","          Conv2d-138            [-1, 1, 32, 32]              10\n","          Conv2d-139            [-1, 1, 32, 32]              10\n","          Conv2d-140            [-1, 1, 32, 32]              10\n","          Conv2d-141            [-1, 1, 32, 32]              10\n","          Conv2d-142            [-1, 1, 32, 32]              10\n","          Conv2d-143            [-1, 1, 32, 32]              10\n","          Conv2d-144            [-1, 1, 32, 32]              10\n","          Conv2d-145            [-1, 1, 32, 32]              10\n","          Conv2d-146            [-1, 1, 32, 32]              10\n","          Conv2d-147            [-1, 1, 32, 32]              10\n","          Conv2d-148            [-1, 1, 32, 32]              10\n","          Conv2d-149            [-1, 1, 32, 32]              10\n","          Conv2d-150            [-1, 1, 32, 32]              10\n","          Conv2d-151            [-1, 1, 32, 32]              10\n","          Conv2d-152            [-1, 1, 32, 32]              10\n","          Conv2d-153            [-1, 1, 32, 32]              10\n","          Conv2d-154            [-1, 1, 32, 32]              10\n","          Conv2d-155            [-1, 1, 32, 32]              10\n","          Conv2d-156            [-1, 1, 32, 32]              10\n","          Conv2d-157            [-1, 1, 32, 32]              10\n","          Conv2d-158            [-1, 1, 32, 32]              10\n","          Conv2d-159            [-1, 1, 32, 32]              10\n","          Conv2d-160            [-1, 1, 32, 32]              10\n","          Conv2d-161            [-1, 1, 32, 32]              10\n","          Conv2d-162            [-1, 1, 32, 32]              10\n","          Conv2d-163            [-1, 1, 32, 32]              10\n","          Conv2d-164            [-1, 1, 32, 32]              10\n","          Conv2d-165            [-1, 1, 32, 32]              10\n","          Conv2d-166            [-1, 1, 32, 32]              10\n","          Conv2d-167            [-1, 1, 32, 32]              10\n","          Conv2d-168            [-1, 1, 32, 32]              10\n","          Conv2d-169            [-1, 1, 32, 32]              10\n","          Conv2d-170            [-1, 1, 32, 32]              10\n","          Conv2d-171            [-1, 1, 32, 32]              10\n","          Conv2d-172            [-1, 1, 32, 32]              10\n","          Conv2d-173            [-1, 1, 32, 32]              10\n","          Conv2d-174            [-1, 1, 32, 32]              10\n","          Conv2d-175            [-1, 1, 32, 32]              10\n","          Conv2d-176            [-1, 1, 32, 32]              10\n","          Conv2d-177            [-1, 1, 32, 32]              10\n","          Conv2d-178            [-1, 1, 32, 32]              10\n","          Conv2d-179            [-1, 1, 32, 32]              10\n","          Conv2d-180            [-1, 1, 32, 32]              10\n","          Conv2d-181            [-1, 1, 32, 32]              10\n","          Conv2d-182            [-1, 1, 32, 32]              10\n","          Conv2d-183            [-1, 1, 32, 32]              10\n","          Conv2d-184            [-1, 1, 32, 32]              10\n","          Conv2d-185            [-1, 1, 32, 32]              10\n","          Conv2d-186            [-1, 1, 32, 32]              10\n","          Conv2d-187            [-1, 1, 32, 32]              10\n","          Conv2d-188            [-1, 1, 32, 32]              10\n","          Conv2d-189            [-1, 1, 32, 32]              10\n","          Conv2d-190            [-1, 1, 32, 32]              10\n","          Conv2d-191            [-1, 1, 32, 32]              10\n","          Conv2d-192            [-1, 1, 32, 32]              10\n","          Conv2d-193            [-1, 1, 32, 32]              10\n","          Conv2d-194            [-1, 1, 32, 32]              10\n","          Conv2d-195            [-1, 1, 32, 32]              10\n","          Conv2d-196            [-1, 1, 32, 32]              10\n","          Conv2d-197            [-1, 1, 32, 32]              10\n","          Conv2d-198            [-1, 1, 32, 32]              10\n","          Conv2d-199            [-1, 1, 32, 32]              10\n","          Conv2d-200            [-1, 1, 32, 32]              10\n","          Conv2d-201            [-1, 1, 32, 32]              10\n","    PixelShuffle-202          [-1, 1, 256, 256]               0\n","          Conv2d-203            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-204            [-1, 1, 32, 32]               0\n","          Conv2d-205            [-1, 1, 32, 32]              10\n","          Conv2d-206            [-1, 1, 32, 32]              10\n","          Conv2d-207            [-1, 1, 32, 32]              10\n","          Conv2d-208            [-1, 1, 32, 32]              10\n","          Conv2d-209            [-1, 1, 32, 32]              10\n","          Conv2d-210            [-1, 1, 32, 32]              10\n","          Conv2d-211            [-1, 1, 32, 32]              10\n","          Conv2d-212            [-1, 1, 32, 32]              10\n","          Conv2d-213            [-1, 1, 32, 32]              10\n","          Conv2d-214            [-1, 1, 32, 32]              10\n","          Conv2d-215            [-1, 1, 32, 32]              10\n","          Conv2d-216            [-1, 1, 32, 32]              10\n","          Conv2d-217            [-1, 1, 32, 32]              10\n","          Conv2d-218            [-1, 1, 32, 32]              10\n","          Conv2d-219            [-1, 1, 32, 32]              10\n","          Conv2d-220            [-1, 1, 32, 32]              10\n","          Conv2d-221            [-1, 1, 32, 32]              10\n","          Conv2d-222            [-1, 1, 32, 32]              10\n","          Conv2d-223            [-1, 1, 32, 32]              10\n","          Conv2d-224            [-1, 1, 32, 32]              10\n","          Conv2d-225            [-1, 1, 32, 32]              10\n","          Conv2d-226            [-1, 1, 32, 32]              10\n","          Conv2d-227            [-1, 1, 32, 32]              10\n","          Conv2d-228            [-1, 1, 32, 32]              10\n","          Conv2d-229            [-1, 1, 32, 32]              10\n","          Conv2d-230            [-1, 1, 32, 32]              10\n","          Conv2d-231            [-1, 1, 32, 32]              10\n","          Conv2d-232            [-1, 1, 32, 32]              10\n","          Conv2d-233            [-1, 1, 32, 32]              10\n","          Conv2d-234            [-1, 1, 32, 32]              10\n","          Conv2d-235            [-1, 1, 32, 32]              10\n","          Conv2d-236            [-1, 1, 32, 32]              10\n","          Conv2d-237            [-1, 1, 32, 32]              10\n","          Conv2d-238            [-1, 1, 32, 32]              10\n","          Conv2d-239            [-1, 1, 32, 32]              10\n","          Conv2d-240            [-1, 1, 32, 32]              10\n","          Conv2d-241            [-1, 1, 32, 32]              10\n","          Conv2d-242            [-1, 1, 32, 32]              10\n","          Conv2d-243            [-1, 1, 32, 32]              10\n","          Conv2d-244            [-1, 1, 32, 32]              10\n","          Conv2d-245            [-1, 1, 32, 32]              10\n","          Conv2d-246            [-1, 1, 32, 32]              10\n","          Conv2d-247            [-1, 1, 32, 32]              10\n","          Conv2d-248            [-1, 1, 32, 32]              10\n","          Conv2d-249            [-1, 1, 32, 32]              10\n","          Conv2d-250            [-1, 1, 32, 32]              10\n","          Conv2d-251            [-1, 1, 32, 32]              10\n","          Conv2d-252            [-1, 1, 32, 32]              10\n","          Conv2d-253            [-1, 1, 32, 32]              10\n","          Conv2d-254            [-1, 1, 32, 32]              10\n","          Conv2d-255            [-1, 1, 32, 32]              10\n","          Conv2d-256            [-1, 1, 32, 32]              10\n","          Conv2d-257            [-1, 1, 32, 32]              10\n","          Conv2d-258            [-1, 1, 32, 32]              10\n","          Conv2d-259            [-1, 1, 32, 32]              10\n","          Conv2d-260            [-1, 1, 32, 32]              10\n","          Conv2d-261            [-1, 1, 32, 32]              10\n","          Conv2d-262            [-1, 1, 32, 32]              10\n","          Conv2d-263            [-1, 1, 32, 32]              10\n","          Conv2d-264            [-1, 1, 32, 32]              10\n","          Conv2d-265            [-1, 1, 32, 32]              10\n","          Conv2d-266            [-1, 1, 32, 32]              10\n","          Conv2d-267            [-1, 1, 32, 32]              10\n","          Conv2d-268            [-1, 1, 32, 32]              10\n","    PixelShuffle-269          [-1, 1, 256, 256]               0\n","          Conv2d-270            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-271            [-1, 1, 32, 32]               0\n","          Conv2d-272            [-1, 1, 32, 32]              10\n","          Conv2d-273            [-1, 1, 32, 32]              10\n","          Conv2d-274            [-1, 1, 32, 32]              10\n","          Conv2d-275            [-1, 1, 32, 32]              10\n","          Conv2d-276            [-1, 1, 32, 32]              10\n","          Conv2d-277            [-1, 1, 32, 32]              10\n","          Conv2d-278            [-1, 1, 32, 32]              10\n","          Conv2d-279            [-1, 1, 32, 32]              10\n","          Conv2d-280            [-1, 1, 32, 32]              10\n","          Conv2d-281            [-1, 1, 32, 32]              10\n","          Conv2d-282            [-1, 1, 32, 32]              10\n","          Conv2d-283            [-1, 1, 32, 32]              10\n","          Conv2d-284            [-1, 1, 32, 32]              10\n","          Conv2d-285            [-1, 1, 32, 32]              10\n","          Conv2d-286            [-1, 1, 32, 32]              10\n","          Conv2d-287            [-1, 1, 32, 32]              10\n","          Conv2d-288            [-1, 1, 32, 32]              10\n","          Conv2d-289            [-1, 1, 32, 32]              10\n","          Conv2d-290            [-1, 1, 32, 32]              10\n","          Conv2d-291            [-1, 1, 32, 32]              10\n","          Conv2d-292            [-1, 1, 32, 32]              10\n","          Conv2d-293            [-1, 1, 32, 32]              10\n","          Conv2d-294            [-1, 1, 32, 32]              10\n","          Conv2d-295            [-1, 1, 32, 32]              10\n","          Conv2d-296            [-1, 1, 32, 32]              10\n","          Conv2d-297            [-1, 1, 32, 32]              10\n","          Conv2d-298            [-1, 1, 32, 32]              10\n","          Conv2d-299            [-1, 1, 32, 32]              10\n","          Conv2d-300            [-1, 1, 32, 32]              10\n","          Conv2d-301            [-1, 1, 32, 32]              10\n","          Conv2d-302            [-1, 1, 32, 32]              10\n","          Conv2d-303            [-1, 1, 32, 32]              10\n","          Conv2d-304            [-1, 1, 32, 32]              10\n","          Conv2d-305            [-1, 1, 32, 32]              10\n","          Conv2d-306            [-1, 1, 32, 32]              10\n","          Conv2d-307            [-1, 1, 32, 32]              10\n","          Conv2d-308            [-1, 1, 32, 32]              10\n","          Conv2d-309            [-1, 1, 32, 32]              10\n","          Conv2d-310            [-1, 1, 32, 32]              10\n","          Conv2d-311            [-1, 1, 32, 32]              10\n","          Conv2d-312            [-1, 1, 32, 32]              10\n","          Conv2d-313            [-1, 1, 32, 32]              10\n","          Conv2d-314            [-1, 1, 32, 32]              10\n","          Conv2d-315            [-1, 1, 32, 32]              10\n","          Conv2d-316            [-1, 1, 32, 32]              10\n","          Conv2d-317            [-1, 1, 32, 32]              10\n","          Conv2d-318            [-1, 1, 32, 32]              10\n","          Conv2d-319            [-1, 1, 32, 32]              10\n","          Conv2d-320            [-1, 1, 32, 32]              10\n","          Conv2d-321            [-1, 1, 32, 32]              10\n","          Conv2d-322            [-1, 1, 32, 32]              10\n","          Conv2d-323            [-1, 1, 32, 32]              10\n","          Conv2d-324            [-1, 1, 32, 32]              10\n","          Conv2d-325            [-1, 1, 32, 32]              10\n","          Conv2d-326            [-1, 1, 32, 32]              10\n","          Conv2d-327            [-1, 1, 32, 32]              10\n","          Conv2d-328            [-1, 1, 32, 32]              10\n","          Conv2d-329            [-1, 1, 32, 32]              10\n","          Conv2d-330            [-1, 1, 32, 32]              10\n","          Conv2d-331            [-1, 1, 32, 32]              10\n","          Conv2d-332            [-1, 1, 32, 32]              10\n","          Conv2d-333            [-1, 1, 32, 32]              10\n","          Conv2d-334            [-1, 1, 32, 32]              10\n","          Conv2d-335            [-1, 1, 32, 32]              10\n","    PixelShuffle-336          [-1, 1, 256, 256]               0\n","          Conv2d-337            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-338            [-1, 1, 32, 32]               0\n","          Conv2d-339            [-1, 1, 32, 32]              10\n","          Conv2d-340            [-1, 1, 32, 32]              10\n","          Conv2d-341            [-1, 1, 32, 32]              10\n","          Conv2d-342            [-1, 1, 32, 32]              10\n","          Conv2d-343            [-1, 1, 32, 32]              10\n","          Conv2d-344            [-1, 1, 32, 32]              10\n","          Conv2d-345            [-1, 1, 32, 32]              10\n","          Conv2d-346            [-1, 1, 32, 32]              10\n","          Conv2d-347            [-1, 1, 32, 32]              10\n","          Conv2d-348            [-1, 1, 32, 32]              10\n","          Conv2d-349            [-1, 1, 32, 32]              10\n","          Conv2d-350            [-1, 1, 32, 32]              10\n","          Conv2d-351            [-1, 1, 32, 32]              10\n","          Conv2d-352            [-1, 1, 32, 32]              10\n","          Conv2d-353            [-1, 1, 32, 32]              10\n","          Conv2d-354            [-1, 1, 32, 32]              10\n","          Conv2d-355            [-1, 1, 32, 32]              10\n","          Conv2d-356            [-1, 1, 32, 32]              10\n","          Conv2d-357            [-1, 1, 32, 32]              10\n","          Conv2d-358            [-1, 1, 32, 32]              10\n","          Conv2d-359            [-1, 1, 32, 32]              10\n","          Conv2d-360            [-1, 1, 32, 32]              10\n","          Conv2d-361            [-1, 1, 32, 32]              10\n","          Conv2d-362            [-1, 1, 32, 32]              10\n","          Conv2d-363            [-1, 1, 32, 32]              10\n","          Conv2d-364            [-1, 1, 32, 32]              10\n","          Conv2d-365            [-1, 1, 32, 32]              10\n","          Conv2d-366            [-1, 1, 32, 32]              10\n","          Conv2d-367            [-1, 1, 32, 32]              10\n","          Conv2d-368            [-1, 1, 32, 32]              10\n","          Conv2d-369            [-1, 1, 32, 32]              10\n","          Conv2d-370            [-1, 1, 32, 32]              10\n","          Conv2d-371            [-1, 1, 32, 32]              10\n","          Conv2d-372            [-1, 1, 32, 32]              10\n","          Conv2d-373            [-1, 1, 32, 32]              10\n","          Conv2d-374            [-1, 1, 32, 32]              10\n","          Conv2d-375            [-1, 1, 32, 32]              10\n","          Conv2d-376            [-1, 1, 32, 32]              10\n","          Conv2d-377            [-1, 1, 32, 32]              10\n","          Conv2d-378            [-1, 1, 32, 32]              10\n","          Conv2d-379            [-1, 1, 32, 32]              10\n","          Conv2d-380            [-1, 1, 32, 32]              10\n","          Conv2d-381            [-1, 1, 32, 32]              10\n","          Conv2d-382            [-1, 1, 32, 32]              10\n","          Conv2d-383            [-1, 1, 32, 32]              10\n","          Conv2d-384            [-1, 1, 32, 32]              10\n","          Conv2d-385            [-1, 1, 32, 32]              10\n","          Conv2d-386            [-1, 1, 32, 32]              10\n","          Conv2d-387            [-1, 1, 32, 32]              10\n","          Conv2d-388            [-1, 1, 32, 32]              10\n","          Conv2d-389            [-1, 1, 32, 32]              10\n","          Conv2d-390            [-1, 1, 32, 32]              10\n","          Conv2d-391            [-1, 1, 32, 32]              10\n","          Conv2d-392            [-1, 1, 32, 32]              10\n","          Conv2d-393            [-1, 1, 32, 32]              10\n","          Conv2d-394            [-1, 1, 32, 32]              10\n","          Conv2d-395            [-1, 1, 32, 32]              10\n","          Conv2d-396            [-1, 1, 32, 32]              10\n","          Conv2d-397            [-1, 1, 32, 32]              10\n","          Conv2d-398            [-1, 1, 32, 32]              10\n","          Conv2d-399            [-1, 1, 32, 32]              10\n","          Conv2d-400            [-1, 1, 32, 32]              10\n","          Conv2d-401            [-1, 1, 32, 32]              10\n","          Conv2d-402            [-1, 1, 32, 32]              10\n","    PixelShuffle-403          [-1, 1, 256, 256]               0\n","          Conv2d-404            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-405            [-1, 1, 32, 32]               0\n","          Conv2d-406            [-1, 1, 32, 32]              10\n","          Conv2d-407            [-1, 1, 32, 32]              10\n","          Conv2d-408            [-1, 1, 32, 32]              10\n","          Conv2d-409            [-1, 1, 32, 32]              10\n","          Conv2d-410            [-1, 1, 32, 32]              10\n","          Conv2d-411            [-1, 1, 32, 32]              10\n","          Conv2d-412            [-1, 1, 32, 32]              10\n","          Conv2d-413            [-1, 1, 32, 32]              10\n","          Conv2d-414            [-1, 1, 32, 32]              10\n","          Conv2d-415            [-1, 1, 32, 32]              10\n","          Conv2d-416            [-1, 1, 32, 32]              10\n","          Conv2d-417            [-1, 1, 32, 32]              10\n","          Conv2d-418            [-1, 1, 32, 32]              10\n","          Conv2d-419            [-1, 1, 32, 32]              10\n","          Conv2d-420            [-1, 1, 32, 32]              10\n","          Conv2d-421            [-1, 1, 32, 32]              10\n","          Conv2d-422            [-1, 1, 32, 32]              10\n","          Conv2d-423            [-1, 1, 32, 32]              10\n","          Conv2d-424            [-1, 1, 32, 32]              10\n","          Conv2d-425            [-1, 1, 32, 32]              10\n","          Conv2d-426            [-1, 1, 32, 32]              10\n","          Conv2d-427            [-1, 1, 32, 32]              10\n","          Conv2d-428            [-1, 1, 32, 32]              10\n","          Conv2d-429            [-1, 1, 32, 32]              10\n","          Conv2d-430            [-1, 1, 32, 32]              10\n","          Conv2d-431            [-1, 1, 32, 32]              10\n","          Conv2d-432            [-1, 1, 32, 32]              10\n","          Conv2d-433            [-1, 1, 32, 32]              10\n","          Conv2d-434            [-1, 1, 32, 32]              10\n","          Conv2d-435            [-1, 1, 32, 32]              10\n","          Conv2d-436            [-1, 1, 32, 32]              10\n","          Conv2d-437            [-1, 1, 32, 32]              10\n","          Conv2d-438            [-1, 1, 32, 32]              10\n","          Conv2d-439            [-1, 1, 32, 32]              10\n","          Conv2d-440            [-1, 1, 32, 32]              10\n","          Conv2d-441            [-1, 1, 32, 32]              10\n","          Conv2d-442            [-1, 1, 32, 32]              10\n","          Conv2d-443            [-1, 1, 32, 32]              10\n","          Conv2d-444            [-1, 1, 32, 32]              10\n","          Conv2d-445            [-1, 1, 32, 32]              10\n","          Conv2d-446            [-1, 1, 32, 32]              10\n","          Conv2d-447            [-1, 1, 32, 32]              10\n","          Conv2d-448            [-1, 1, 32, 32]              10\n","          Conv2d-449            [-1, 1, 32, 32]              10\n","          Conv2d-450            [-1, 1, 32, 32]              10\n","          Conv2d-451            [-1, 1, 32, 32]              10\n","          Conv2d-452            [-1, 1, 32, 32]              10\n","          Conv2d-453            [-1, 1, 32, 32]              10\n","          Conv2d-454            [-1, 1, 32, 32]              10\n","          Conv2d-455            [-1, 1, 32, 32]              10\n","          Conv2d-456            [-1, 1, 32, 32]              10\n","          Conv2d-457            [-1, 1, 32, 32]              10\n","          Conv2d-458            [-1, 1, 32, 32]              10\n","          Conv2d-459            [-1, 1, 32, 32]              10\n","          Conv2d-460            [-1, 1, 32, 32]              10\n","          Conv2d-461            [-1, 1, 32, 32]              10\n","          Conv2d-462            [-1, 1, 32, 32]              10\n","          Conv2d-463            [-1, 1, 32, 32]              10\n","          Conv2d-464            [-1, 1, 32, 32]              10\n","          Conv2d-465            [-1, 1, 32, 32]              10\n","          Conv2d-466            [-1, 1, 32, 32]              10\n","          Conv2d-467            [-1, 1, 32, 32]              10\n","          Conv2d-468            [-1, 1, 32, 32]              10\n","          Conv2d-469            [-1, 1, 32, 32]              10\n","    PixelShuffle-470          [-1, 1, 256, 256]               0\n","          Conv2d-471            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-472            [-1, 1, 32, 32]               0\n","          Conv2d-473            [-1, 1, 32, 32]              10\n","          Conv2d-474            [-1, 1, 32, 32]              10\n","          Conv2d-475            [-1, 1, 32, 32]              10\n","          Conv2d-476            [-1, 1, 32, 32]              10\n","          Conv2d-477            [-1, 1, 32, 32]              10\n","          Conv2d-478            [-1, 1, 32, 32]              10\n","          Conv2d-479            [-1, 1, 32, 32]              10\n","          Conv2d-480            [-1, 1, 32, 32]              10\n","          Conv2d-481            [-1, 1, 32, 32]              10\n","          Conv2d-482            [-1, 1, 32, 32]              10\n","          Conv2d-483            [-1, 1, 32, 32]              10\n","          Conv2d-484            [-1, 1, 32, 32]              10\n","          Conv2d-485            [-1, 1, 32, 32]              10\n","          Conv2d-486            [-1, 1, 32, 32]              10\n","          Conv2d-487            [-1, 1, 32, 32]              10\n","          Conv2d-488            [-1, 1, 32, 32]              10\n","          Conv2d-489            [-1, 1, 32, 32]              10\n","          Conv2d-490            [-1, 1, 32, 32]              10\n","          Conv2d-491            [-1, 1, 32, 32]              10\n","          Conv2d-492            [-1, 1, 32, 32]              10\n","          Conv2d-493            [-1, 1, 32, 32]              10\n","          Conv2d-494            [-1, 1, 32, 32]              10\n","          Conv2d-495            [-1, 1, 32, 32]              10\n","          Conv2d-496            [-1, 1, 32, 32]              10\n","          Conv2d-497            [-1, 1, 32, 32]              10\n","          Conv2d-498            [-1, 1, 32, 32]              10\n","          Conv2d-499            [-1, 1, 32, 32]              10\n","          Conv2d-500            [-1, 1, 32, 32]              10\n","          Conv2d-501            [-1, 1, 32, 32]              10\n","          Conv2d-502            [-1, 1, 32, 32]              10\n","          Conv2d-503            [-1, 1, 32, 32]              10\n","          Conv2d-504            [-1, 1, 32, 32]              10\n","          Conv2d-505            [-1, 1, 32, 32]              10\n","          Conv2d-506            [-1, 1, 32, 32]              10\n","          Conv2d-507            [-1, 1, 32, 32]              10\n","          Conv2d-508            [-1, 1, 32, 32]              10\n","          Conv2d-509            [-1, 1, 32, 32]              10\n","          Conv2d-510            [-1, 1, 32, 32]              10\n","          Conv2d-511            [-1, 1, 32, 32]              10\n","          Conv2d-512            [-1, 1, 32, 32]              10\n","          Conv2d-513            [-1, 1, 32, 32]              10\n","          Conv2d-514            [-1, 1, 32, 32]              10\n","          Conv2d-515            [-1, 1, 32, 32]              10\n","          Conv2d-516            [-1, 1, 32, 32]              10\n","          Conv2d-517            [-1, 1, 32, 32]              10\n","          Conv2d-518            [-1, 1, 32, 32]              10\n","          Conv2d-519            [-1, 1, 32, 32]              10\n","          Conv2d-520            [-1, 1, 32, 32]              10\n","          Conv2d-521            [-1, 1, 32, 32]              10\n","          Conv2d-522            [-1, 1, 32, 32]              10\n","          Conv2d-523            [-1, 1, 32, 32]              10\n","          Conv2d-524            [-1, 1, 32, 32]              10\n","          Conv2d-525            [-1, 1, 32, 32]              10\n","          Conv2d-526            [-1, 1, 32, 32]              10\n","          Conv2d-527            [-1, 1, 32, 32]              10\n","          Conv2d-528            [-1, 1, 32, 32]              10\n","          Conv2d-529            [-1, 1, 32, 32]              10\n","          Conv2d-530            [-1, 1, 32, 32]              10\n","          Conv2d-531            [-1, 1, 32, 32]              10\n","          Conv2d-532            [-1, 1, 32, 32]              10\n","          Conv2d-533            [-1, 1, 32, 32]              10\n","          Conv2d-534            [-1, 1, 32, 32]              10\n","          Conv2d-535            [-1, 1, 32, 32]              10\n","          Conv2d-536            [-1, 1, 32, 32]              10\n","    PixelShuffle-537          [-1, 1, 256, 256]               0\n","          Conv2d-538            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-539            [-1, 1, 32, 32]               0\n","          Conv2d-540            [-1, 1, 32, 32]              10\n","          Conv2d-541            [-1, 1, 32, 32]              10\n","          Conv2d-542            [-1, 1, 32, 32]              10\n","          Conv2d-543            [-1, 1, 32, 32]              10\n","          Conv2d-544            [-1, 1, 32, 32]              10\n","          Conv2d-545            [-1, 1, 32, 32]              10\n","          Conv2d-546            [-1, 1, 32, 32]              10\n","          Conv2d-547            [-1, 1, 32, 32]              10\n","          Conv2d-548            [-1, 1, 32, 32]              10\n","          Conv2d-549            [-1, 1, 32, 32]              10\n","          Conv2d-550            [-1, 1, 32, 32]              10\n","          Conv2d-551            [-1, 1, 32, 32]              10\n","          Conv2d-552            [-1, 1, 32, 32]              10\n","          Conv2d-553            [-1, 1, 32, 32]              10\n","          Conv2d-554            [-1, 1, 32, 32]              10\n","          Conv2d-555            [-1, 1, 32, 32]              10\n","          Conv2d-556            [-1, 1, 32, 32]              10\n","          Conv2d-557            [-1, 1, 32, 32]              10\n","          Conv2d-558            [-1, 1, 32, 32]              10\n","          Conv2d-559            [-1, 1, 32, 32]              10\n","          Conv2d-560            [-1, 1, 32, 32]              10\n","          Conv2d-561            [-1, 1, 32, 32]              10\n","          Conv2d-562            [-1, 1, 32, 32]              10\n","          Conv2d-563            [-1, 1, 32, 32]              10\n","          Conv2d-564            [-1, 1, 32, 32]              10\n","          Conv2d-565            [-1, 1, 32, 32]              10\n","          Conv2d-566            [-1, 1, 32, 32]              10\n","          Conv2d-567            [-1, 1, 32, 32]              10\n","          Conv2d-568            [-1, 1, 32, 32]              10\n","          Conv2d-569            [-1, 1, 32, 32]              10\n","          Conv2d-570            [-1, 1, 32, 32]              10\n","          Conv2d-571            [-1, 1, 32, 32]              10\n","          Conv2d-572            [-1, 1, 32, 32]              10\n","          Conv2d-573            [-1, 1, 32, 32]              10\n","          Conv2d-574            [-1, 1, 32, 32]              10\n","          Conv2d-575            [-1, 1, 32, 32]              10\n","          Conv2d-576            [-1, 1, 32, 32]              10\n","          Conv2d-577            [-1, 1, 32, 32]              10\n","          Conv2d-578            [-1, 1, 32, 32]              10\n","          Conv2d-579            [-1, 1, 32, 32]              10\n","          Conv2d-580            [-1, 1, 32, 32]              10\n","          Conv2d-581            [-1, 1, 32, 32]              10\n","          Conv2d-582            [-1, 1, 32, 32]              10\n","          Conv2d-583            [-1, 1, 32, 32]              10\n","          Conv2d-584            [-1, 1, 32, 32]              10\n","          Conv2d-585            [-1, 1, 32, 32]              10\n","          Conv2d-586            [-1, 1, 32, 32]              10\n","          Conv2d-587            [-1, 1, 32, 32]              10\n","          Conv2d-588            [-1, 1, 32, 32]              10\n","          Conv2d-589            [-1, 1, 32, 32]              10\n","          Conv2d-590            [-1, 1, 32, 32]              10\n","          Conv2d-591            [-1, 1, 32, 32]              10\n","          Conv2d-592            [-1, 1, 32, 32]              10\n","          Conv2d-593            [-1, 1, 32, 32]              10\n","          Conv2d-594            [-1, 1, 32, 32]              10\n","          Conv2d-595            [-1, 1, 32, 32]              10\n","          Conv2d-596            [-1, 1, 32, 32]              10\n","          Conv2d-597            [-1, 1, 32, 32]              10\n","          Conv2d-598            [-1, 1, 32, 32]              10\n","          Conv2d-599            [-1, 1, 32, 32]              10\n","          Conv2d-600            [-1, 1, 32, 32]              10\n","          Conv2d-601            [-1, 1, 32, 32]              10\n","          Conv2d-602            [-1, 1, 32, 32]              10\n","          Conv2d-603            [-1, 1, 32, 32]              10\n","    PixelShuffle-604          [-1, 1, 256, 256]               0\n","          Conv2d-605            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-606            [-1, 1, 32, 32]               0\n","          Conv2d-607            [-1, 1, 32, 32]              10\n","          Conv2d-608            [-1, 1, 32, 32]              10\n","          Conv2d-609            [-1, 1, 32, 32]              10\n","          Conv2d-610            [-1, 1, 32, 32]              10\n","          Conv2d-611            [-1, 1, 32, 32]              10\n","          Conv2d-612            [-1, 1, 32, 32]              10\n","          Conv2d-613            [-1, 1, 32, 32]              10\n","          Conv2d-614            [-1, 1, 32, 32]              10\n","          Conv2d-615            [-1, 1, 32, 32]              10\n","          Conv2d-616            [-1, 1, 32, 32]              10\n","          Conv2d-617            [-1, 1, 32, 32]              10\n","          Conv2d-618            [-1, 1, 32, 32]              10\n","          Conv2d-619            [-1, 1, 32, 32]              10\n","          Conv2d-620            [-1, 1, 32, 32]              10\n","          Conv2d-621            [-1, 1, 32, 32]              10\n","          Conv2d-622            [-1, 1, 32, 32]              10\n","          Conv2d-623            [-1, 1, 32, 32]              10\n","          Conv2d-624            [-1, 1, 32, 32]              10\n","          Conv2d-625            [-1, 1, 32, 32]              10\n","          Conv2d-626            [-1, 1, 32, 32]              10\n","          Conv2d-627            [-1, 1, 32, 32]              10\n","          Conv2d-628            [-1, 1, 32, 32]              10\n","          Conv2d-629            [-1, 1, 32, 32]              10\n","          Conv2d-630            [-1, 1, 32, 32]              10\n","          Conv2d-631            [-1, 1, 32, 32]              10\n","          Conv2d-632            [-1, 1, 32, 32]              10\n","          Conv2d-633            [-1, 1, 32, 32]              10\n","          Conv2d-634            [-1, 1, 32, 32]              10\n","          Conv2d-635            [-1, 1, 32, 32]              10\n","          Conv2d-636            [-1, 1, 32, 32]              10\n","          Conv2d-637            [-1, 1, 32, 32]              10\n","          Conv2d-638            [-1, 1, 32, 32]              10\n","          Conv2d-639            [-1, 1, 32, 32]              10\n","          Conv2d-640            [-1, 1, 32, 32]              10\n","          Conv2d-641            [-1, 1, 32, 32]              10\n","          Conv2d-642            [-1, 1, 32, 32]              10\n","          Conv2d-643            [-1, 1, 32, 32]              10\n","          Conv2d-644            [-1, 1, 32, 32]              10\n","          Conv2d-645            [-1, 1, 32, 32]              10\n","          Conv2d-646            [-1, 1, 32, 32]              10\n","          Conv2d-647            [-1, 1, 32, 32]              10\n","          Conv2d-648            [-1, 1, 32, 32]              10\n","          Conv2d-649            [-1, 1, 32, 32]              10\n","          Conv2d-650            [-1, 1, 32, 32]              10\n","          Conv2d-651            [-1, 1, 32, 32]              10\n","          Conv2d-652            [-1, 1, 32, 32]              10\n","          Conv2d-653            [-1, 1, 32, 32]              10\n","          Conv2d-654            [-1, 1, 32, 32]              10\n","          Conv2d-655            [-1, 1, 32, 32]              10\n","          Conv2d-656            [-1, 1, 32, 32]              10\n","          Conv2d-657            [-1, 1, 32, 32]              10\n","          Conv2d-658            [-1, 1, 32, 32]              10\n","          Conv2d-659            [-1, 1, 32, 32]              10\n","          Conv2d-660            [-1, 1, 32, 32]              10\n","          Conv2d-661            [-1, 1, 32, 32]              10\n","          Conv2d-662            [-1, 1, 32, 32]              10\n","          Conv2d-663            [-1, 1, 32, 32]              10\n","          Conv2d-664            [-1, 1, 32, 32]              10\n","          Conv2d-665            [-1, 1, 32, 32]              10\n","          Conv2d-666            [-1, 1, 32, 32]              10\n","          Conv2d-667            [-1, 1, 32, 32]              10\n","          Conv2d-668            [-1, 1, 32, 32]              10\n","          Conv2d-669            [-1, 1, 32, 32]              10\n","          Conv2d-670            [-1, 1, 32, 32]              10\n","    PixelShuffle-671          [-1, 1, 256, 256]               0\n","          Conv2d-672            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-673            [-1, 1, 32, 32]               0\n","          Conv2d-674            [-1, 1, 32, 32]              10\n","          Conv2d-675            [-1, 1, 32, 32]              10\n","          Conv2d-676            [-1, 1, 32, 32]              10\n","          Conv2d-677            [-1, 1, 32, 32]              10\n","          Conv2d-678            [-1, 1, 32, 32]              10\n","          Conv2d-679            [-1, 1, 32, 32]              10\n","          Conv2d-680            [-1, 1, 32, 32]              10\n","          Conv2d-681            [-1, 1, 32, 32]              10\n","          Conv2d-682            [-1, 1, 32, 32]              10\n","          Conv2d-683            [-1, 1, 32, 32]              10\n","          Conv2d-684            [-1, 1, 32, 32]              10\n","          Conv2d-685            [-1, 1, 32, 32]              10\n","          Conv2d-686            [-1, 1, 32, 32]              10\n","          Conv2d-687            [-1, 1, 32, 32]              10\n","          Conv2d-688            [-1, 1, 32, 32]              10\n","          Conv2d-689            [-1, 1, 32, 32]              10\n","          Conv2d-690            [-1, 1, 32, 32]              10\n","          Conv2d-691            [-1, 1, 32, 32]              10\n","          Conv2d-692            [-1, 1, 32, 32]              10\n","          Conv2d-693            [-1, 1, 32, 32]              10\n","          Conv2d-694            [-1, 1, 32, 32]              10\n","          Conv2d-695            [-1, 1, 32, 32]              10\n","          Conv2d-696            [-1, 1, 32, 32]              10\n","          Conv2d-697            [-1, 1, 32, 32]              10\n","          Conv2d-698            [-1, 1, 32, 32]              10\n","          Conv2d-699            [-1, 1, 32, 32]              10\n","          Conv2d-700            [-1, 1, 32, 32]              10\n","          Conv2d-701            [-1, 1, 32, 32]              10\n","          Conv2d-702            [-1, 1, 32, 32]              10\n","          Conv2d-703            [-1, 1, 32, 32]              10\n","          Conv2d-704            [-1, 1, 32, 32]              10\n","          Conv2d-705            [-1, 1, 32, 32]              10\n","          Conv2d-706            [-1, 1, 32, 32]              10\n","          Conv2d-707            [-1, 1, 32, 32]              10\n","          Conv2d-708            [-1, 1, 32, 32]              10\n","          Conv2d-709            [-1, 1, 32, 32]              10\n","          Conv2d-710            [-1, 1, 32, 32]              10\n","          Conv2d-711            [-1, 1, 32, 32]              10\n","          Conv2d-712            [-1, 1, 32, 32]              10\n","          Conv2d-713            [-1, 1, 32, 32]              10\n","          Conv2d-714            [-1, 1, 32, 32]              10\n","          Conv2d-715            [-1, 1, 32, 32]              10\n","          Conv2d-716            [-1, 1, 32, 32]              10\n","          Conv2d-717            [-1, 1, 32, 32]              10\n","          Conv2d-718            [-1, 1, 32, 32]              10\n","          Conv2d-719            [-1, 1, 32, 32]              10\n","          Conv2d-720            [-1, 1, 32, 32]              10\n","          Conv2d-721            [-1, 1, 32, 32]              10\n","          Conv2d-722            [-1, 1, 32, 32]              10\n","          Conv2d-723            [-1, 1, 32, 32]              10\n","          Conv2d-724            [-1, 1, 32, 32]              10\n","          Conv2d-725            [-1, 1, 32, 32]              10\n","          Conv2d-726            [-1, 1, 32, 32]              10\n","          Conv2d-727            [-1, 1, 32, 32]              10\n","          Conv2d-728            [-1, 1, 32, 32]              10\n","          Conv2d-729            [-1, 1, 32, 32]              10\n","          Conv2d-730            [-1, 1, 32, 32]              10\n","          Conv2d-731            [-1, 1, 32, 32]              10\n","          Conv2d-732            [-1, 1, 32, 32]              10\n","          Conv2d-733            [-1, 1, 32, 32]              10\n","          Conv2d-734            [-1, 1, 32, 32]              10\n","          Conv2d-735            [-1, 1, 32, 32]              10\n","          Conv2d-736            [-1, 1, 32, 32]              10\n","          Conv2d-737            [-1, 1, 32, 32]              10\n","    PixelShuffle-738          [-1, 1, 256, 256]               0\n","          Conv2d-739            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-740            [-1, 1, 32, 32]               0\n","          Conv2d-741            [-1, 1, 32, 32]              10\n","          Conv2d-742            [-1, 1, 32, 32]              10\n","          Conv2d-743            [-1, 1, 32, 32]              10\n","          Conv2d-744            [-1, 1, 32, 32]              10\n","          Conv2d-745            [-1, 1, 32, 32]              10\n","          Conv2d-746            [-1, 1, 32, 32]              10\n","          Conv2d-747            [-1, 1, 32, 32]              10\n","          Conv2d-748            [-1, 1, 32, 32]              10\n","          Conv2d-749            [-1, 1, 32, 32]              10\n","          Conv2d-750            [-1, 1, 32, 32]              10\n","          Conv2d-751            [-1, 1, 32, 32]              10\n","          Conv2d-752            [-1, 1, 32, 32]              10\n","          Conv2d-753            [-1, 1, 32, 32]              10\n","          Conv2d-754            [-1, 1, 32, 32]              10\n","          Conv2d-755            [-1, 1, 32, 32]              10\n","          Conv2d-756            [-1, 1, 32, 32]              10\n","          Conv2d-757            [-1, 1, 32, 32]              10\n","          Conv2d-758            [-1, 1, 32, 32]              10\n","          Conv2d-759            [-1, 1, 32, 32]              10\n","          Conv2d-760            [-1, 1, 32, 32]              10\n","          Conv2d-761            [-1, 1, 32, 32]              10\n","          Conv2d-762            [-1, 1, 32, 32]              10\n","          Conv2d-763            [-1, 1, 32, 32]              10\n","          Conv2d-764            [-1, 1, 32, 32]              10\n","          Conv2d-765            [-1, 1, 32, 32]              10\n","          Conv2d-766            [-1, 1, 32, 32]              10\n","          Conv2d-767            [-1, 1, 32, 32]              10\n","          Conv2d-768            [-1, 1, 32, 32]              10\n","          Conv2d-769            [-1, 1, 32, 32]              10\n","          Conv2d-770            [-1, 1, 32, 32]              10\n","          Conv2d-771            [-1, 1, 32, 32]              10\n","          Conv2d-772            [-1, 1, 32, 32]              10\n","          Conv2d-773            [-1, 1, 32, 32]              10\n","          Conv2d-774            [-1, 1, 32, 32]              10\n","          Conv2d-775            [-1, 1, 32, 32]              10\n","          Conv2d-776            [-1, 1, 32, 32]              10\n","          Conv2d-777            [-1, 1, 32, 32]              10\n","          Conv2d-778            [-1, 1, 32, 32]              10\n","          Conv2d-779            [-1, 1, 32, 32]              10\n","          Conv2d-780            [-1, 1, 32, 32]              10\n","          Conv2d-781            [-1, 1, 32, 32]              10\n","          Conv2d-782            [-1, 1, 32, 32]              10\n","          Conv2d-783            [-1, 1, 32, 32]              10\n","          Conv2d-784            [-1, 1, 32, 32]              10\n","          Conv2d-785            [-1, 1, 32, 32]              10\n","          Conv2d-786            [-1, 1, 32, 32]              10\n","          Conv2d-787            [-1, 1, 32, 32]              10\n","          Conv2d-788            [-1, 1, 32, 32]              10\n","          Conv2d-789            [-1, 1, 32, 32]              10\n","          Conv2d-790            [-1, 1, 32, 32]              10\n","          Conv2d-791            [-1, 1, 32, 32]              10\n","          Conv2d-792            [-1, 1, 32, 32]              10\n","          Conv2d-793            [-1, 1, 32, 32]              10\n","          Conv2d-794            [-1, 1, 32, 32]              10\n","          Conv2d-795            [-1, 1, 32, 32]              10\n","          Conv2d-796            [-1, 1, 32, 32]              10\n","          Conv2d-797            [-1, 1, 32, 32]              10\n","          Conv2d-798            [-1, 1, 32, 32]              10\n","          Conv2d-799            [-1, 1, 32, 32]              10\n","          Conv2d-800            [-1, 1, 32, 32]              10\n","          Conv2d-801            [-1, 1, 32, 32]              10\n","          Conv2d-802            [-1, 1, 32, 32]              10\n","          Conv2d-803            [-1, 1, 32, 32]              10\n","          Conv2d-804            [-1, 1, 32, 32]              10\n","    PixelShuffle-805          [-1, 1, 256, 256]               0\n","          Conv2d-806            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-807            [-1, 1, 32, 32]               0\n","          Conv2d-808            [-1, 1, 32, 32]              10\n","          Conv2d-809            [-1, 1, 32, 32]              10\n","          Conv2d-810            [-1, 1, 32, 32]              10\n","          Conv2d-811            [-1, 1, 32, 32]              10\n","          Conv2d-812            [-1, 1, 32, 32]              10\n","          Conv2d-813            [-1, 1, 32, 32]              10\n","          Conv2d-814            [-1, 1, 32, 32]              10\n","          Conv2d-815            [-1, 1, 32, 32]              10\n","          Conv2d-816            [-1, 1, 32, 32]              10\n","          Conv2d-817            [-1, 1, 32, 32]              10\n","          Conv2d-818            [-1, 1, 32, 32]              10\n","          Conv2d-819            [-1, 1, 32, 32]              10\n","          Conv2d-820            [-1, 1, 32, 32]              10\n","          Conv2d-821            [-1, 1, 32, 32]              10\n","          Conv2d-822            [-1, 1, 32, 32]              10\n","          Conv2d-823            [-1, 1, 32, 32]              10\n","          Conv2d-824            [-1, 1, 32, 32]              10\n","          Conv2d-825            [-1, 1, 32, 32]              10\n","          Conv2d-826            [-1, 1, 32, 32]              10\n","          Conv2d-827            [-1, 1, 32, 32]              10\n","          Conv2d-828            [-1, 1, 32, 32]              10\n","          Conv2d-829            [-1, 1, 32, 32]              10\n","          Conv2d-830            [-1, 1, 32, 32]              10\n","          Conv2d-831            [-1, 1, 32, 32]              10\n","          Conv2d-832            [-1, 1, 32, 32]              10\n","          Conv2d-833            [-1, 1, 32, 32]              10\n","          Conv2d-834            [-1, 1, 32, 32]              10\n","          Conv2d-835            [-1, 1, 32, 32]              10\n","          Conv2d-836            [-1, 1, 32, 32]              10\n","          Conv2d-837            [-1, 1, 32, 32]              10\n","          Conv2d-838            [-1, 1, 32, 32]              10\n","          Conv2d-839            [-1, 1, 32, 32]              10\n","          Conv2d-840            [-1, 1, 32, 32]              10\n","          Conv2d-841            [-1, 1, 32, 32]              10\n","          Conv2d-842            [-1, 1, 32, 32]              10\n","          Conv2d-843            [-1, 1, 32, 32]              10\n","          Conv2d-844            [-1, 1, 32, 32]              10\n","          Conv2d-845            [-1, 1, 32, 32]              10\n","          Conv2d-846            [-1, 1, 32, 32]              10\n","          Conv2d-847            [-1, 1, 32, 32]              10\n","          Conv2d-848            [-1, 1, 32, 32]              10\n","          Conv2d-849            [-1, 1, 32, 32]              10\n","          Conv2d-850            [-1, 1, 32, 32]              10\n","          Conv2d-851            [-1, 1, 32, 32]              10\n","          Conv2d-852            [-1, 1, 32, 32]              10\n","          Conv2d-853            [-1, 1, 32, 32]              10\n","          Conv2d-854            [-1, 1, 32, 32]              10\n","          Conv2d-855            [-1, 1, 32, 32]              10\n","          Conv2d-856            [-1, 1, 32, 32]              10\n","          Conv2d-857            [-1, 1, 32, 32]              10\n","          Conv2d-858            [-1, 1, 32, 32]              10\n","          Conv2d-859            [-1, 1, 32, 32]              10\n","          Conv2d-860            [-1, 1, 32, 32]              10\n","          Conv2d-861            [-1, 1, 32, 32]              10\n","          Conv2d-862            [-1, 1, 32, 32]              10\n","          Conv2d-863            [-1, 1, 32, 32]              10\n","          Conv2d-864            [-1, 1, 32, 32]              10\n","          Conv2d-865            [-1, 1, 32, 32]              10\n","          Conv2d-866            [-1, 1, 32, 32]              10\n","          Conv2d-867            [-1, 1, 32, 32]              10\n","          Conv2d-868            [-1, 1, 32, 32]              10\n","          Conv2d-869            [-1, 1, 32, 32]              10\n","          Conv2d-870            [-1, 1, 32, 32]              10\n","          Conv2d-871            [-1, 1, 32, 32]              10\n","    PixelShuffle-872          [-1, 1, 256, 256]               0\n","          Conv2d-873            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-874            [-1, 1, 32, 32]               0\n","          Conv2d-875            [-1, 1, 32, 32]              10\n","          Conv2d-876            [-1, 1, 32, 32]              10\n","          Conv2d-877            [-1, 1, 32, 32]              10\n","          Conv2d-878            [-1, 1, 32, 32]              10\n","          Conv2d-879            [-1, 1, 32, 32]              10\n","          Conv2d-880            [-1, 1, 32, 32]              10\n","          Conv2d-881            [-1, 1, 32, 32]              10\n","          Conv2d-882            [-1, 1, 32, 32]              10\n","          Conv2d-883            [-1, 1, 32, 32]              10\n","          Conv2d-884            [-1, 1, 32, 32]              10\n","          Conv2d-885            [-1, 1, 32, 32]              10\n","          Conv2d-886            [-1, 1, 32, 32]              10\n","          Conv2d-887            [-1, 1, 32, 32]              10\n","          Conv2d-888            [-1, 1, 32, 32]              10\n","          Conv2d-889            [-1, 1, 32, 32]              10\n","          Conv2d-890            [-1, 1, 32, 32]              10\n","          Conv2d-891            [-1, 1, 32, 32]              10\n","          Conv2d-892            [-1, 1, 32, 32]              10\n","          Conv2d-893            [-1, 1, 32, 32]              10\n","          Conv2d-894            [-1, 1, 32, 32]              10\n","          Conv2d-895            [-1, 1, 32, 32]              10\n","          Conv2d-896            [-1, 1, 32, 32]              10\n","          Conv2d-897            [-1, 1, 32, 32]              10\n","          Conv2d-898            [-1, 1, 32, 32]              10\n","          Conv2d-899            [-1, 1, 32, 32]              10\n","          Conv2d-900            [-1, 1, 32, 32]              10\n","          Conv2d-901            [-1, 1, 32, 32]              10\n","          Conv2d-902            [-1, 1, 32, 32]              10\n","          Conv2d-903            [-1, 1, 32, 32]              10\n","          Conv2d-904            [-1, 1, 32, 32]              10\n","          Conv2d-905            [-1, 1, 32, 32]              10\n","          Conv2d-906            [-1, 1, 32, 32]              10\n","          Conv2d-907            [-1, 1, 32, 32]              10\n","          Conv2d-908            [-1, 1, 32, 32]              10\n","          Conv2d-909            [-1, 1, 32, 32]              10\n","          Conv2d-910            [-1, 1, 32, 32]              10\n","          Conv2d-911            [-1, 1, 32, 32]              10\n","          Conv2d-912            [-1, 1, 32, 32]              10\n","          Conv2d-913            [-1, 1, 32, 32]              10\n","          Conv2d-914            [-1, 1, 32, 32]              10\n","          Conv2d-915            [-1, 1, 32, 32]              10\n","          Conv2d-916            [-1, 1, 32, 32]              10\n","          Conv2d-917            [-1, 1, 32, 32]              10\n","          Conv2d-918            [-1, 1, 32, 32]              10\n","          Conv2d-919            [-1, 1, 32, 32]              10\n","          Conv2d-920            [-1, 1, 32, 32]              10\n","          Conv2d-921            [-1, 1, 32, 32]              10\n","          Conv2d-922            [-1, 1, 32, 32]              10\n","          Conv2d-923            [-1, 1, 32, 32]              10\n","          Conv2d-924            [-1, 1, 32, 32]              10\n","          Conv2d-925            [-1, 1, 32, 32]              10\n","          Conv2d-926            [-1, 1, 32, 32]              10\n","          Conv2d-927            [-1, 1, 32, 32]              10\n","          Conv2d-928            [-1, 1, 32, 32]              10\n","          Conv2d-929            [-1, 1, 32, 32]              10\n","          Conv2d-930            [-1, 1, 32, 32]              10\n","          Conv2d-931            [-1, 1, 32, 32]              10\n","          Conv2d-932            [-1, 1, 32, 32]              10\n","          Conv2d-933            [-1, 1, 32, 32]              10\n","          Conv2d-934            [-1, 1, 32, 32]              10\n","          Conv2d-935            [-1, 1, 32, 32]              10\n","          Conv2d-936            [-1, 1, 32, 32]              10\n","          Conv2d-937            [-1, 1, 32, 32]              10\n","          Conv2d-938            [-1, 1, 32, 32]              10\n","    PixelShuffle-939          [-1, 1, 256, 256]               0\n","          Conv2d-940            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-941            [-1, 1, 32, 32]               0\n","          Conv2d-942            [-1, 1, 32, 32]              10\n","          Conv2d-943            [-1, 1, 32, 32]              10\n","          Conv2d-944            [-1, 1, 32, 32]              10\n","          Conv2d-945            [-1, 1, 32, 32]              10\n","          Conv2d-946            [-1, 1, 32, 32]              10\n","          Conv2d-947            [-1, 1, 32, 32]              10\n","          Conv2d-948            [-1, 1, 32, 32]              10\n","          Conv2d-949            [-1, 1, 32, 32]              10\n","          Conv2d-950            [-1, 1, 32, 32]              10\n","          Conv2d-951            [-1, 1, 32, 32]              10\n","          Conv2d-952            [-1, 1, 32, 32]              10\n","          Conv2d-953            [-1, 1, 32, 32]              10\n","          Conv2d-954            [-1, 1, 32, 32]              10\n","          Conv2d-955            [-1, 1, 32, 32]              10\n","          Conv2d-956            [-1, 1, 32, 32]              10\n","          Conv2d-957            [-1, 1, 32, 32]              10\n","          Conv2d-958            [-1, 1, 32, 32]              10\n","          Conv2d-959            [-1, 1, 32, 32]              10\n","          Conv2d-960            [-1, 1, 32, 32]              10\n","          Conv2d-961            [-1, 1, 32, 32]              10\n","          Conv2d-962            [-1, 1, 32, 32]              10\n","          Conv2d-963            [-1, 1, 32, 32]              10\n","          Conv2d-964            [-1, 1, 32, 32]              10\n","          Conv2d-965            [-1, 1, 32, 32]              10\n","          Conv2d-966            [-1, 1, 32, 32]              10\n","          Conv2d-967            [-1, 1, 32, 32]              10\n","          Conv2d-968            [-1, 1, 32, 32]              10\n","          Conv2d-969            [-1, 1, 32, 32]              10\n","          Conv2d-970            [-1, 1, 32, 32]              10\n","          Conv2d-971            [-1, 1, 32, 32]              10\n","          Conv2d-972            [-1, 1, 32, 32]              10\n","          Conv2d-973            [-1, 1, 32, 32]              10\n","          Conv2d-974            [-1, 1, 32, 32]              10\n","          Conv2d-975            [-1, 1, 32, 32]              10\n","          Conv2d-976            [-1, 1, 32, 32]              10\n","          Conv2d-977            [-1, 1, 32, 32]              10\n","          Conv2d-978            [-1, 1, 32, 32]              10\n","          Conv2d-979            [-1, 1, 32, 32]              10\n","          Conv2d-980            [-1, 1, 32, 32]              10\n","          Conv2d-981            [-1, 1, 32, 32]              10\n","          Conv2d-982            [-1, 1, 32, 32]              10\n","          Conv2d-983            [-1, 1, 32, 32]              10\n","          Conv2d-984            [-1, 1, 32, 32]              10\n","          Conv2d-985            [-1, 1, 32, 32]              10\n","          Conv2d-986            [-1, 1, 32, 32]              10\n","          Conv2d-987            [-1, 1, 32, 32]              10\n","          Conv2d-988            [-1, 1, 32, 32]              10\n","          Conv2d-989            [-1, 1, 32, 32]              10\n","          Conv2d-990            [-1, 1, 32, 32]              10\n","          Conv2d-991            [-1, 1, 32, 32]              10\n","          Conv2d-992            [-1, 1, 32, 32]              10\n","          Conv2d-993            [-1, 1, 32, 32]              10\n","          Conv2d-994            [-1, 1, 32, 32]              10\n","          Conv2d-995            [-1, 1, 32, 32]              10\n","          Conv2d-996            [-1, 1, 32, 32]              10\n","          Conv2d-997            [-1, 1, 32, 32]              10\n","          Conv2d-998            [-1, 1, 32, 32]              10\n","          Conv2d-999            [-1, 1, 32, 32]              10\n","         Conv2d-1000            [-1, 1, 32, 32]              10\n","         Conv2d-1001            [-1, 1, 32, 32]              10\n","         Conv2d-1002            [-1, 1, 32, 32]              10\n","         Conv2d-1003            [-1, 1, 32, 32]              10\n","         Conv2d-1004            [-1, 1, 32, 32]              10\n","         Conv2d-1005            [-1, 1, 32, 32]              10\n","   PixelShuffle-1006          [-1, 1, 256, 256]               0\n","         Conv2d-1007            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-1008            [-1, 1, 32, 32]               0\n","         Conv2d-1009            [-1, 1, 32, 32]              10\n","         Conv2d-1010            [-1, 1, 32, 32]              10\n","         Conv2d-1011            [-1, 1, 32, 32]              10\n","         Conv2d-1012            [-1, 1, 32, 32]              10\n","         Conv2d-1013            [-1, 1, 32, 32]              10\n","         Conv2d-1014            [-1, 1, 32, 32]              10\n","         Conv2d-1015            [-1, 1, 32, 32]              10\n","         Conv2d-1016            [-1, 1, 32, 32]              10\n","         Conv2d-1017            [-1, 1, 32, 32]              10\n","         Conv2d-1018            [-1, 1, 32, 32]              10\n","         Conv2d-1019            [-1, 1, 32, 32]              10\n","         Conv2d-1020            [-1, 1, 32, 32]              10\n","         Conv2d-1021            [-1, 1, 32, 32]              10\n","         Conv2d-1022            [-1, 1, 32, 32]              10\n","         Conv2d-1023            [-1, 1, 32, 32]              10\n","         Conv2d-1024            [-1, 1, 32, 32]              10\n","         Conv2d-1025            [-1, 1, 32, 32]              10\n","         Conv2d-1026            [-1, 1, 32, 32]              10\n","         Conv2d-1027            [-1, 1, 32, 32]              10\n","         Conv2d-1028            [-1, 1, 32, 32]              10\n","         Conv2d-1029            [-1, 1, 32, 32]              10\n","         Conv2d-1030            [-1, 1, 32, 32]              10\n","         Conv2d-1031            [-1, 1, 32, 32]              10\n","         Conv2d-1032            [-1, 1, 32, 32]              10\n","         Conv2d-1033            [-1, 1, 32, 32]              10\n","         Conv2d-1034            [-1, 1, 32, 32]              10\n","         Conv2d-1035            [-1, 1, 32, 32]              10\n","         Conv2d-1036            [-1, 1, 32, 32]              10\n","         Conv2d-1037            [-1, 1, 32, 32]              10\n","         Conv2d-1038            [-1, 1, 32, 32]              10\n","         Conv2d-1039            [-1, 1, 32, 32]              10\n","         Conv2d-1040            [-1, 1, 32, 32]              10\n","         Conv2d-1041            [-1, 1, 32, 32]              10\n","         Conv2d-1042            [-1, 1, 32, 32]              10\n","         Conv2d-1043            [-1, 1, 32, 32]              10\n","         Conv2d-1044            [-1, 1, 32, 32]              10\n","         Conv2d-1045            [-1, 1, 32, 32]              10\n","         Conv2d-1046            [-1, 1, 32, 32]              10\n","         Conv2d-1047            [-1, 1, 32, 32]              10\n","         Conv2d-1048            [-1, 1, 32, 32]              10\n","         Conv2d-1049            [-1, 1, 32, 32]              10\n","         Conv2d-1050            [-1, 1, 32, 32]              10\n","         Conv2d-1051            [-1, 1, 32, 32]              10\n","         Conv2d-1052            [-1, 1, 32, 32]              10\n","         Conv2d-1053            [-1, 1, 32, 32]              10\n","         Conv2d-1054            [-1, 1, 32, 32]              10\n","         Conv2d-1055            [-1, 1, 32, 32]              10\n","         Conv2d-1056            [-1, 1, 32, 32]              10\n","         Conv2d-1057            [-1, 1, 32, 32]              10\n","         Conv2d-1058            [-1, 1, 32, 32]              10\n","         Conv2d-1059            [-1, 1, 32, 32]              10\n","         Conv2d-1060            [-1, 1, 32, 32]              10\n","         Conv2d-1061            [-1, 1, 32, 32]              10\n","         Conv2d-1062            [-1, 1, 32, 32]              10\n","         Conv2d-1063            [-1, 1, 32, 32]              10\n","         Conv2d-1064            [-1, 1, 32, 32]              10\n","         Conv2d-1065            [-1, 1, 32, 32]              10\n","         Conv2d-1066            [-1, 1, 32, 32]              10\n","         Conv2d-1067            [-1, 1, 32, 32]              10\n","         Conv2d-1068            [-1, 1, 32, 32]              10\n","         Conv2d-1069            [-1, 1, 32, 32]              10\n","         Conv2d-1070            [-1, 1, 32, 32]              10\n","         Conv2d-1071            [-1, 1, 32, 32]              10\n","         Conv2d-1072            [-1, 1, 32, 32]              10\n","   PixelShuffle-1073          [-1, 1, 256, 256]               0\n","         Conv2d-1074            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-1075            [-1, 1, 32, 32]               0\n","         Conv2d-1076            [-1, 1, 32, 32]              10\n","         Conv2d-1077            [-1, 1, 32, 32]              10\n","         Conv2d-1078            [-1, 1, 32, 32]              10\n","         Conv2d-1079            [-1, 1, 32, 32]              10\n","         Conv2d-1080            [-1, 1, 32, 32]              10\n","         Conv2d-1081            [-1, 1, 32, 32]              10\n","         Conv2d-1082            [-1, 1, 32, 32]              10\n","         Conv2d-1083            [-1, 1, 32, 32]              10\n","         Conv2d-1084            [-1, 1, 32, 32]              10\n","         Conv2d-1085            [-1, 1, 32, 32]              10\n","         Conv2d-1086            [-1, 1, 32, 32]              10\n","         Conv2d-1087            [-1, 1, 32, 32]              10\n","         Conv2d-1088            [-1, 1, 32, 32]              10\n","         Conv2d-1089            [-1, 1, 32, 32]              10\n","         Conv2d-1090            [-1, 1, 32, 32]              10\n","         Conv2d-1091            [-1, 1, 32, 32]              10\n","         Conv2d-1092            [-1, 1, 32, 32]              10\n","         Conv2d-1093            [-1, 1, 32, 32]              10\n","         Conv2d-1094            [-1, 1, 32, 32]              10\n","         Conv2d-1095            [-1, 1, 32, 32]              10\n","         Conv2d-1096            [-1, 1, 32, 32]              10\n","         Conv2d-1097            [-1, 1, 32, 32]              10\n","         Conv2d-1098            [-1, 1, 32, 32]              10\n","         Conv2d-1099            [-1, 1, 32, 32]              10\n","         Conv2d-1100            [-1, 1, 32, 32]              10\n","         Conv2d-1101            [-1, 1, 32, 32]              10\n","         Conv2d-1102            [-1, 1, 32, 32]              10\n","         Conv2d-1103            [-1, 1, 32, 32]              10\n","         Conv2d-1104            [-1, 1, 32, 32]              10\n","         Conv2d-1105            [-1, 1, 32, 32]              10\n","         Conv2d-1106            [-1, 1, 32, 32]              10\n","         Conv2d-1107            [-1, 1, 32, 32]              10\n","         Conv2d-1108            [-1, 1, 32, 32]              10\n","         Conv2d-1109            [-1, 1, 32, 32]              10\n","         Conv2d-1110            [-1, 1, 32, 32]              10\n","         Conv2d-1111            [-1, 1, 32, 32]              10\n","         Conv2d-1112            [-1, 1, 32, 32]              10\n","         Conv2d-1113            [-1, 1, 32, 32]              10\n","         Conv2d-1114            [-1, 1, 32, 32]              10\n","         Conv2d-1115            [-1, 1, 32, 32]              10\n","         Conv2d-1116            [-1, 1, 32, 32]              10\n","         Conv2d-1117            [-1, 1, 32, 32]              10\n","         Conv2d-1118            [-1, 1, 32, 32]              10\n","         Conv2d-1119            [-1, 1, 32, 32]              10\n","         Conv2d-1120            [-1, 1, 32, 32]              10\n","         Conv2d-1121            [-1, 1, 32, 32]              10\n","         Conv2d-1122            [-1, 1, 32, 32]              10\n","         Conv2d-1123            [-1, 1, 32, 32]              10\n","         Conv2d-1124            [-1, 1, 32, 32]              10\n","         Conv2d-1125            [-1, 1, 32, 32]              10\n","         Conv2d-1126            [-1, 1, 32, 32]              10\n","         Conv2d-1127            [-1, 1, 32, 32]              10\n","         Conv2d-1128            [-1, 1, 32, 32]              10\n","         Conv2d-1129            [-1, 1, 32, 32]              10\n","         Conv2d-1130            [-1, 1, 32, 32]              10\n","         Conv2d-1131            [-1, 1, 32, 32]              10\n","         Conv2d-1132            [-1, 1, 32, 32]              10\n","         Conv2d-1133            [-1, 1, 32, 32]              10\n","         Conv2d-1134            [-1, 1, 32, 32]              10\n","         Conv2d-1135            [-1, 1, 32, 32]              10\n","         Conv2d-1136            [-1, 1, 32, 32]              10\n","         Conv2d-1137            [-1, 1, 32, 32]              10\n","         Conv2d-1138            [-1, 1, 32, 32]              10\n","         Conv2d-1139            [-1, 1, 32, 32]              10\n","   PixelShuffle-1140          [-1, 1, 256, 256]               0\n","         Conv2d-1141            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-1142            [-1, 1, 32, 32]               0\n","         Conv2d-1143            [-1, 1, 32, 32]              10\n","         Conv2d-1144            [-1, 1, 32, 32]              10\n","         Conv2d-1145            [-1, 1, 32, 32]              10\n","         Conv2d-1146            [-1, 1, 32, 32]              10\n","         Conv2d-1147            [-1, 1, 32, 32]              10\n","         Conv2d-1148            [-1, 1, 32, 32]              10\n","         Conv2d-1149            [-1, 1, 32, 32]              10\n","         Conv2d-1150            [-1, 1, 32, 32]              10\n","         Conv2d-1151            [-1, 1, 32, 32]              10\n","         Conv2d-1152            [-1, 1, 32, 32]              10\n","         Conv2d-1153            [-1, 1, 32, 32]              10\n","         Conv2d-1154            [-1, 1, 32, 32]              10\n","         Conv2d-1155            [-1, 1, 32, 32]              10\n","         Conv2d-1156            [-1, 1, 32, 32]              10\n","         Conv2d-1157            [-1, 1, 32, 32]              10\n","         Conv2d-1158            [-1, 1, 32, 32]              10\n","         Conv2d-1159            [-1, 1, 32, 32]              10\n","         Conv2d-1160            [-1, 1, 32, 32]              10\n","         Conv2d-1161            [-1, 1, 32, 32]              10\n","         Conv2d-1162            [-1, 1, 32, 32]              10\n","         Conv2d-1163            [-1, 1, 32, 32]              10\n","         Conv2d-1164            [-1, 1, 32, 32]              10\n","         Conv2d-1165            [-1, 1, 32, 32]              10\n","         Conv2d-1166            [-1, 1, 32, 32]              10\n","         Conv2d-1167            [-1, 1, 32, 32]              10\n","         Conv2d-1168            [-1, 1, 32, 32]              10\n","         Conv2d-1169            [-1, 1, 32, 32]              10\n","         Conv2d-1170            [-1, 1, 32, 32]              10\n","         Conv2d-1171            [-1, 1, 32, 32]              10\n","         Conv2d-1172            [-1, 1, 32, 32]              10\n","         Conv2d-1173            [-1, 1, 32, 32]              10\n","         Conv2d-1174            [-1, 1, 32, 32]              10\n","         Conv2d-1175            [-1, 1, 32, 32]              10\n","         Conv2d-1176            [-1, 1, 32, 32]              10\n","         Conv2d-1177            [-1, 1, 32, 32]              10\n","         Conv2d-1178            [-1, 1, 32, 32]              10\n","         Conv2d-1179            [-1, 1, 32, 32]              10\n","         Conv2d-1180            [-1, 1, 32, 32]              10\n","         Conv2d-1181            [-1, 1, 32, 32]              10\n","         Conv2d-1182            [-1, 1, 32, 32]              10\n","         Conv2d-1183            [-1, 1, 32, 32]              10\n","         Conv2d-1184            [-1, 1, 32, 32]              10\n","         Conv2d-1185            [-1, 1, 32, 32]              10\n","         Conv2d-1186            [-1, 1, 32, 32]              10\n","         Conv2d-1187            [-1, 1, 32, 32]              10\n","         Conv2d-1188            [-1, 1, 32, 32]              10\n","         Conv2d-1189            [-1, 1, 32, 32]              10\n","         Conv2d-1190            [-1, 1, 32, 32]              10\n","         Conv2d-1191            [-1, 1, 32, 32]              10\n","         Conv2d-1192            [-1, 1, 32, 32]              10\n","         Conv2d-1193            [-1, 1, 32, 32]              10\n","         Conv2d-1194            [-1, 1, 32, 32]              10\n","         Conv2d-1195            [-1, 1, 32, 32]              10\n","         Conv2d-1196            [-1, 1, 32, 32]              10\n","         Conv2d-1197            [-1, 1, 32, 32]              10\n","         Conv2d-1198            [-1, 1, 32, 32]              10\n","         Conv2d-1199            [-1, 1, 32, 32]              10\n","         Conv2d-1200            [-1, 1, 32, 32]              10\n","         Conv2d-1201            [-1, 1, 32, 32]              10\n","         Conv2d-1202            [-1, 1, 32, 32]              10\n","         Conv2d-1203            [-1, 1, 32, 32]              10\n","         Conv2d-1204            [-1, 1, 32, 32]              10\n","         Conv2d-1205            [-1, 1, 32, 32]              10\n","         Conv2d-1206            [-1, 1, 32, 32]              10\n","   PixelShuffle-1207          [-1, 1, 256, 256]               0\n","         Conv2d-1208            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-1209            [-1, 1, 32, 32]               0\n","         Conv2d-1210            [-1, 1, 32, 32]              10\n","         Conv2d-1211            [-1, 1, 32, 32]              10\n","         Conv2d-1212            [-1, 1, 32, 32]              10\n","         Conv2d-1213            [-1, 1, 32, 32]              10\n","         Conv2d-1214            [-1, 1, 32, 32]              10\n","         Conv2d-1215            [-1, 1, 32, 32]              10\n","         Conv2d-1216            [-1, 1, 32, 32]              10\n","         Conv2d-1217            [-1, 1, 32, 32]              10\n","         Conv2d-1218            [-1, 1, 32, 32]              10\n","         Conv2d-1219            [-1, 1, 32, 32]              10\n","         Conv2d-1220            [-1, 1, 32, 32]              10\n","         Conv2d-1221            [-1, 1, 32, 32]              10\n","         Conv2d-1222            [-1, 1, 32, 32]              10\n","         Conv2d-1223            [-1, 1, 32, 32]              10\n","         Conv2d-1224            [-1, 1, 32, 32]              10\n","         Conv2d-1225            [-1, 1, 32, 32]              10\n","         Conv2d-1226            [-1, 1, 32, 32]              10\n","         Conv2d-1227            [-1, 1, 32, 32]              10\n","         Conv2d-1228            [-1, 1, 32, 32]              10\n","         Conv2d-1229            [-1, 1, 32, 32]              10\n","         Conv2d-1230            [-1, 1, 32, 32]              10\n","         Conv2d-1231            [-1, 1, 32, 32]              10\n","         Conv2d-1232            [-1, 1, 32, 32]              10\n","         Conv2d-1233            [-1, 1, 32, 32]              10\n","         Conv2d-1234            [-1, 1, 32, 32]              10\n","         Conv2d-1235            [-1, 1, 32, 32]              10\n","         Conv2d-1236            [-1, 1, 32, 32]              10\n","         Conv2d-1237            [-1, 1, 32, 32]              10\n","         Conv2d-1238            [-1, 1, 32, 32]              10\n","         Conv2d-1239            [-1, 1, 32, 32]              10\n","         Conv2d-1240            [-1, 1, 32, 32]              10\n","         Conv2d-1241            [-1, 1, 32, 32]              10\n","         Conv2d-1242            [-1, 1, 32, 32]              10\n","         Conv2d-1243            [-1, 1, 32, 32]              10\n","         Conv2d-1244            [-1, 1, 32, 32]              10\n","         Conv2d-1245            [-1, 1, 32, 32]              10\n","         Conv2d-1246            [-1, 1, 32, 32]              10\n","         Conv2d-1247            [-1, 1, 32, 32]              10\n","         Conv2d-1248            [-1, 1, 32, 32]              10\n","         Conv2d-1249            [-1, 1, 32, 32]              10\n","         Conv2d-1250            [-1, 1, 32, 32]              10\n","         Conv2d-1251            [-1, 1, 32, 32]              10\n","         Conv2d-1252            [-1, 1, 32, 32]              10\n","         Conv2d-1253            [-1, 1, 32, 32]              10\n","         Conv2d-1254            [-1, 1, 32, 32]              10\n","         Conv2d-1255            [-1, 1, 32, 32]              10\n","         Conv2d-1256            [-1, 1, 32, 32]              10\n","         Conv2d-1257            [-1, 1, 32, 32]              10\n","         Conv2d-1258            [-1, 1, 32, 32]              10\n","         Conv2d-1259            [-1, 1, 32, 32]              10\n","         Conv2d-1260            [-1, 1, 32, 32]              10\n","         Conv2d-1261            [-1, 1, 32, 32]              10\n","         Conv2d-1262            [-1, 1, 32, 32]              10\n","         Conv2d-1263            [-1, 1, 32, 32]              10\n","         Conv2d-1264            [-1, 1, 32, 32]              10\n","         Conv2d-1265            [-1, 1, 32, 32]              10\n","         Conv2d-1266            [-1, 1, 32, 32]              10\n","         Conv2d-1267            [-1, 1, 32, 32]              10\n","         Conv2d-1268            [-1, 1, 32, 32]              10\n","         Conv2d-1269            [-1, 1, 32, 32]              10\n","         Conv2d-1270            [-1, 1, 32, 32]              10\n","         Conv2d-1271            [-1, 1, 32, 32]              10\n","         Conv2d-1272            [-1, 1, 32, 32]              10\n","         Conv2d-1273            [-1, 1, 32, 32]              10\n","   PixelShuffle-1274          [-1, 1, 256, 256]               0\n","         Conv2d-1275            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-1276            [-1, 1, 32, 32]               0\n","         Conv2d-1277            [-1, 1, 32, 32]              10\n","         Conv2d-1278            [-1, 1, 32, 32]              10\n","         Conv2d-1279            [-1, 1, 32, 32]              10\n","         Conv2d-1280            [-1, 1, 32, 32]              10\n","         Conv2d-1281            [-1, 1, 32, 32]              10\n","         Conv2d-1282            [-1, 1, 32, 32]              10\n","         Conv2d-1283            [-1, 1, 32, 32]              10\n","         Conv2d-1284            [-1, 1, 32, 32]              10\n","         Conv2d-1285            [-1, 1, 32, 32]              10\n","         Conv2d-1286            [-1, 1, 32, 32]              10\n","         Conv2d-1287            [-1, 1, 32, 32]              10\n","         Conv2d-1288            [-1, 1, 32, 32]              10\n","         Conv2d-1289            [-1, 1, 32, 32]              10\n","         Conv2d-1290            [-1, 1, 32, 32]              10\n","         Conv2d-1291            [-1, 1, 32, 32]              10\n","         Conv2d-1292            [-1, 1, 32, 32]              10\n","         Conv2d-1293            [-1, 1, 32, 32]              10\n","         Conv2d-1294            [-1, 1, 32, 32]              10\n","         Conv2d-1295            [-1, 1, 32, 32]              10\n","         Conv2d-1296            [-1, 1, 32, 32]              10\n","         Conv2d-1297            [-1, 1, 32, 32]              10\n","         Conv2d-1298            [-1, 1, 32, 32]              10\n","         Conv2d-1299            [-1, 1, 32, 32]              10\n","         Conv2d-1300            [-1, 1, 32, 32]              10\n","         Conv2d-1301            [-1, 1, 32, 32]              10\n","         Conv2d-1302            [-1, 1, 32, 32]              10\n","         Conv2d-1303            [-1, 1, 32, 32]              10\n","         Conv2d-1304            [-1, 1, 32, 32]              10\n","         Conv2d-1305            [-1, 1, 32, 32]              10\n","         Conv2d-1306            [-1, 1, 32, 32]              10\n","         Conv2d-1307            [-1, 1, 32, 32]              10\n","         Conv2d-1308            [-1, 1, 32, 32]              10\n","         Conv2d-1309            [-1, 1, 32, 32]              10\n","         Conv2d-1310            [-1, 1, 32, 32]              10\n","         Conv2d-1311            [-1, 1, 32, 32]              10\n","         Conv2d-1312            [-1, 1, 32, 32]              10\n","         Conv2d-1313            [-1, 1, 32, 32]              10\n","         Conv2d-1314            [-1, 1, 32, 32]              10\n","         Conv2d-1315            [-1, 1, 32, 32]              10\n","         Conv2d-1316            [-1, 1, 32, 32]              10\n","         Conv2d-1317            [-1, 1, 32, 32]              10\n","         Conv2d-1318            [-1, 1, 32, 32]              10\n","         Conv2d-1319            [-1, 1, 32, 32]              10\n","         Conv2d-1320            [-1, 1, 32, 32]              10\n","         Conv2d-1321            [-1, 1, 32, 32]              10\n","         Conv2d-1322            [-1, 1, 32, 32]              10\n","         Conv2d-1323            [-1, 1, 32, 32]              10\n","         Conv2d-1324            [-1, 1, 32, 32]              10\n","         Conv2d-1325            [-1, 1, 32, 32]              10\n","         Conv2d-1326            [-1, 1, 32, 32]              10\n","         Conv2d-1327            [-1, 1, 32, 32]              10\n","         Conv2d-1328            [-1, 1, 32, 32]              10\n","         Conv2d-1329            [-1, 1, 32, 32]              10\n","         Conv2d-1330            [-1, 1, 32, 32]              10\n","         Conv2d-1331            [-1, 1, 32, 32]              10\n","         Conv2d-1332            [-1, 1, 32, 32]              10\n","         Conv2d-1333            [-1, 1, 32, 32]              10\n","         Conv2d-1334            [-1, 1, 32, 32]              10\n","         Conv2d-1335            [-1, 1, 32, 32]              10\n","         Conv2d-1336            [-1, 1, 32, 32]              10\n","         Conv2d-1337            [-1, 1, 32, 32]              10\n","         Conv2d-1338            [-1, 1, 32, 32]              10\n","         Conv2d-1339            [-1, 1, 32, 32]              10\n","         Conv2d-1340            [-1, 1, 32, 32]              10\n","   PixelShuffle-1341          [-1, 1, 256, 256]               0\n","         Conv2d-1342            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-1343            [-1, 1, 32, 32]               0\n","         Conv2d-1344            [-1, 1, 32, 32]              10\n","         Conv2d-1345            [-1, 1, 32, 32]              10\n","         Conv2d-1346            [-1, 1, 32, 32]              10\n","         Conv2d-1347            [-1, 1, 32, 32]              10\n","         Conv2d-1348            [-1, 1, 32, 32]              10\n","         Conv2d-1349            [-1, 1, 32, 32]              10\n","         Conv2d-1350            [-1, 1, 32, 32]              10\n","         Conv2d-1351            [-1, 1, 32, 32]              10\n","         Conv2d-1352            [-1, 1, 32, 32]              10\n","         Conv2d-1353            [-1, 1, 32, 32]              10\n","         Conv2d-1354            [-1, 1, 32, 32]              10\n","         Conv2d-1355            [-1, 1, 32, 32]              10\n","         Conv2d-1356            [-1, 1, 32, 32]              10\n","         Conv2d-1357            [-1, 1, 32, 32]              10\n","         Conv2d-1358            [-1, 1, 32, 32]              10\n","         Conv2d-1359            [-1, 1, 32, 32]              10\n","         Conv2d-1360            [-1, 1, 32, 32]              10\n","         Conv2d-1361            [-1, 1, 32, 32]              10\n","         Conv2d-1362            [-1, 1, 32, 32]              10\n","         Conv2d-1363            [-1, 1, 32, 32]              10\n","         Conv2d-1364            [-1, 1, 32, 32]              10\n","         Conv2d-1365            [-1, 1, 32, 32]              10\n","         Conv2d-1366            [-1, 1, 32, 32]              10\n","         Conv2d-1367            [-1, 1, 32, 32]              10\n","         Conv2d-1368            [-1, 1, 32, 32]              10\n","         Conv2d-1369            [-1, 1, 32, 32]              10\n","         Conv2d-1370            [-1, 1, 32, 32]              10\n","         Conv2d-1371            [-1, 1, 32, 32]              10\n","         Conv2d-1372            [-1, 1, 32, 32]              10\n","         Conv2d-1373            [-1, 1, 32, 32]              10\n","         Conv2d-1374            [-1, 1, 32, 32]              10\n","         Conv2d-1375            [-1, 1, 32, 32]              10\n","         Conv2d-1376            [-1, 1, 32, 32]              10\n","         Conv2d-1377            [-1, 1, 32, 32]              10\n","         Conv2d-1378            [-1, 1, 32, 32]              10\n","         Conv2d-1379            [-1, 1, 32, 32]              10\n","         Conv2d-1380            [-1, 1, 32, 32]              10\n","         Conv2d-1381            [-1, 1, 32, 32]              10\n","         Conv2d-1382            [-1, 1, 32, 32]              10\n","         Conv2d-1383            [-1, 1, 32, 32]              10\n","         Conv2d-1384            [-1, 1, 32, 32]              10\n","         Conv2d-1385            [-1, 1, 32, 32]              10\n","         Conv2d-1386            [-1, 1, 32, 32]              10\n","         Conv2d-1387            [-1, 1, 32, 32]              10\n","         Conv2d-1388            [-1, 1, 32, 32]              10\n","         Conv2d-1389            [-1, 1, 32, 32]              10\n","         Conv2d-1390            [-1, 1, 32, 32]              10\n","         Conv2d-1391            [-1, 1, 32, 32]              10\n","         Conv2d-1392            [-1, 1, 32, 32]              10\n","         Conv2d-1393            [-1, 1, 32, 32]              10\n","         Conv2d-1394            [-1, 1, 32, 32]              10\n","         Conv2d-1395            [-1, 1, 32, 32]              10\n","         Conv2d-1396            [-1, 1, 32, 32]              10\n","         Conv2d-1397            [-1, 1, 32, 32]              10\n","         Conv2d-1398            [-1, 1, 32, 32]              10\n","         Conv2d-1399            [-1, 1, 32, 32]              10\n","         Conv2d-1400            [-1, 1, 32, 32]              10\n","         Conv2d-1401            [-1, 1, 32, 32]              10\n","         Conv2d-1402            [-1, 1, 32, 32]              10\n","         Conv2d-1403            [-1, 1, 32, 32]              10\n","         Conv2d-1404            [-1, 1, 32, 32]              10\n","         Conv2d-1405            [-1, 1, 32, 32]              10\n","         Conv2d-1406            [-1, 1, 32, 32]              10\n","         Conv2d-1407            [-1, 1, 32, 32]              10\n","   PixelShuffle-1408          [-1, 1, 256, 256]               0\n","         Conv2d-1409            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-1410            [-1, 1, 32, 32]               0\n","         Conv2d-1411            [-1, 1, 32, 32]              10\n","         Conv2d-1412            [-1, 1, 32, 32]              10\n","         Conv2d-1413            [-1, 1, 32, 32]              10\n","         Conv2d-1414            [-1, 1, 32, 32]              10\n","         Conv2d-1415            [-1, 1, 32, 32]              10\n","         Conv2d-1416            [-1, 1, 32, 32]              10\n","         Conv2d-1417            [-1, 1, 32, 32]              10\n","         Conv2d-1418            [-1, 1, 32, 32]              10\n","         Conv2d-1419            [-1, 1, 32, 32]              10\n","         Conv2d-1420            [-1, 1, 32, 32]              10\n","         Conv2d-1421            [-1, 1, 32, 32]              10\n","         Conv2d-1422            [-1, 1, 32, 32]              10\n","         Conv2d-1423            [-1, 1, 32, 32]              10\n","         Conv2d-1424            [-1, 1, 32, 32]              10\n","         Conv2d-1425            [-1, 1, 32, 32]              10\n","         Conv2d-1426            [-1, 1, 32, 32]              10\n","         Conv2d-1427            [-1, 1, 32, 32]              10\n","         Conv2d-1428            [-1, 1, 32, 32]              10\n","         Conv2d-1429            [-1, 1, 32, 32]              10\n","         Conv2d-1430            [-1, 1, 32, 32]              10\n","         Conv2d-1431            [-1, 1, 32, 32]              10\n","         Conv2d-1432            [-1, 1, 32, 32]              10\n","         Conv2d-1433            [-1, 1, 32, 32]              10\n","         Conv2d-1434            [-1, 1, 32, 32]              10\n","         Conv2d-1435            [-1, 1, 32, 32]              10\n","         Conv2d-1436            [-1, 1, 32, 32]              10\n","         Conv2d-1437            [-1, 1, 32, 32]              10\n","         Conv2d-1438            [-1, 1, 32, 32]              10\n","         Conv2d-1439            [-1, 1, 32, 32]              10\n","         Conv2d-1440            [-1, 1, 32, 32]              10\n","         Conv2d-1441            [-1, 1, 32, 32]              10\n","         Conv2d-1442            [-1, 1, 32, 32]              10\n","         Conv2d-1443            [-1, 1, 32, 32]              10\n","         Conv2d-1444            [-1, 1, 32, 32]              10\n","         Conv2d-1445            [-1, 1, 32, 32]              10\n","         Conv2d-1446            [-1, 1, 32, 32]              10\n","         Conv2d-1447            [-1, 1, 32, 32]              10\n","         Conv2d-1448            [-1, 1, 32, 32]              10\n","         Conv2d-1449            [-1, 1, 32, 32]              10\n","         Conv2d-1450            [-1, 1, 32, 32]              10\n","         Conv2d-1451            [-1, 1, 32, 32]              10\n","         Conv2d-1452            [-1, 1, 32, 32]              10\n","         Conv2d-1453            [-1, 1, 32, 32]              10\n","         Conv2d-1454            [-1, 1, 32, 32]              10\n","         Conv2d-1455            [-1, 1, 32, 32]              10\n","         Conv2d-1456            [-1, 1, 32, 32]              10\n","         Conv2d-1457            [-1, 1, 32, 32]              10\n","         Conv2d-1458            [-1, 1, 32, 32]              10\n","         Conv2d-1459            [-1, 1, 32, 32]              10\n","         Conv2d-1460            [-1, 1, 32, 32]              10\n","         Conv2d-1461            [-1, 1, 32, 32]              10\n","         Conv2d-1462            [-1, 1, 32, 32]              10\n","         Conv2d-1463            [-1, 1, 32, 32]              10\n","         Conv2d-1464            [-1, 1, 32, 32]              10\n","         Conv2d-1465            [-1, 1, 32, 32]              10\n","         Conv2d-1466            [-1, 1, 32, 32]              10\n","         Conv2d-1467            [-1, 1, 32, 32]              10\n","         Conv2d-1468            [-1, 1, 32, 32]              10\n","         Conv2d-1469            [-1, 1, 32, 32]              10\n","         Conv2d-1470            [-1, 1, 32, 32]              10\n","         Conv2d-1471            [-1, 1, 32, 32]              10\n","         Conv2d-1472            [-1, 1, 32, 32]              10\n","         Conv2d-1473            [-1, 1, 32, 32]              10\n","         Conv2d-1474            [-1, 1, 32, 32]              10\n","   PixelShuffle-1475          [-1, 1, 256, 256]               0\n","         Conv2d-1476            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-1477            [-1, 1, 32, 32]               0\n","         Conv2d-1478            [-1, 1, 32, 32]              10\n","         Conv2d-1479            [-1, 1, 32, 32]              10\n","         Conv2d-1480            [-1, 1, 32, 32]              10\n","         Conv2d-1481            [-1, 1, 32, 32]              10\n","         Conv2d-1482            [-1, 1, 32, 32]              10\n","         Conv2d-1483            [-1, 1, 32, 32]              10\n","         Conv2d-1484            [-1, 1, 32, 32]              10\n","         Conv2d-1485            [-1, 1, 32, 32]              10\n","         Conv2d-1486            [-1, 1, 32, 32]              10\n","         Conv2d-1487            [-1, 1, 32, 32]              10\n","         Conv2d-1488            [-1, 1, 32, 32]              10\n","         Conv2d-1489            [-1, 1, 32, 32]              10\n","         Conv2d-1490            [-1, 1, 32, 32]              10\n","         Conv2d-1491            [-1, 1, 32, 32]              10\n","         Conv2d-1492            [-1, 1, 32, 32]              10\n","         Conv2d-1493            [-1, 1, 32, 32]              10\n","         Conv2d-1494            [-1, 1, 32, 32]              10\n","         Conv2d-1495            [-1, 1, 32, 32]              10\n","         Conv2d-1496            [-1, 1, 32, 32]              10\n","         Conv2d-1497            [-1, 1, 32, 32]              10\n","         Conv2d-1498            [-1, 1, 32, 32]              10\n","         Conv2d-1499            [-1, 1, 32, 32]              10\n","         Conv2d-1500            [-1, 1, 32, 32]              10\n","         Conv2d-1501            [-1, 1, 32, 32]              10\n","         Conv2d-1502            [-1, 1, 32, 32]              10\n","         Conv2d-1503            [-1, 1, 32, 32]              10\n","         Conv2d-1504            [-1, 1, 32, 32]              10\n","         Conv2d-1505            [-1, 1, 32, 32]              10\n","         Conv2d-1506            [-1, 1, 32, 32]              10\n","         Conv2d-1507            [-1, 1, 32, 32]              10\n","         Conv2d-1508            [-1, 1, 32, 32]              10\n","         Conv2d-1509            [-1, 1, 32, 32]              10\n","         Conv2d-1510            [-1, 1, 32, 32]              10\n","         Conv2d-1511            [-1, 1, 32, 32]              10\n","         Conv2d-1512            [-1, 1, 32, 32]              10\n","         Conv2d-1513            [-1, 1, 32, 32]              10\n","         Conv2d-1514            [-1, 1, 32, 32]              10\n","         Conv2d-1515            [-1, 1, 32, 32]              10\n","         Conv2d-1516            [-1, 1, 32, 32]              10\n","         Conv2d-1517            [-1, 1, 32, 32]              10\n","         Conv2d-1518            [-1, 1, 32, 32]              10\n","         Conv2d-1519            [-1, 1, 32, 32]              10\n","         Conv2d-1520            [-1, 1, 32, 32]              10\n","         Conv2d-1521            [-1, 1, 32, 32]              10\n","         Conv2d-1522            [-1, 1, 32, 32]              10\n","         Conv2d-1523            [-1, 1, 32, 32]              10\n","         Conv2d-1524            [-1, 1, 32, 32]              10\n","         Conv2d-1525            [-1, 1, 32, 32]              10\n","         Conv2d-1526            [-1, 1, 32, 32]              10\n","         Conv2d-1527            [-1, 1, 32, 32]              10\n","         Conv2d-1528            [-1, 1, 32, 32]              10\n","         Conv2d-1529            [-1, 1, 32, 32]              10\n","         Conv2d-1530            [-1, 1, 32, 32]              10\n","         Conv2d-1531            [-1, 1, 32, 32]              10\n","         Conv2d-1532            [-1, 1, 32, 32]              10\n","         Conv2d-1533            [-1, 1, 32, 32]              10\n","         Conv2d-1534            [-1, 1, 32, 32]              10\n","         Conv2d-1535            [-1, 1, 32, 32]              10\n","         Conv2d-1536            [-1, 1, 32, 32]              10\n","         Conv2d-1537            [-1, 1, 32, 32]              10\n","         Conv2d-1538            [-1, 1, 32, 32]              10\n","         Conv2d-1539            [-1, 1, 32, 32]              10\n","         Conv2d-1540            [-1, 1, 32, 32]              10\n","         Conv2d-1541            [-1, 1, 32, 32]              10\n","   PixelShuffle-1542          [-1, 1, 256, 256]               0\n","         Conv2d-1543            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-1544            [-1, 1, 32, 32]               0\n","         Conv2d-1545            [-1, 1, 32, 32]              10\n","         Conv2d-1546            [-1, 1, 32, 32]              10\n","         Conv2d-1547            [-1, 1, 32, 32]              10\n","         Conv2d-1548            [-1, 1, 32, 32]              10\n","         Conv2d-1549            [-1, 1, 32, 32]              10\n","         Conv2d-1550            [-1, 1, 32, 32]              10\n","         Conv2d-1551            [-1, 1, 32, 32]              10\n","         Conv2d-1552            [-1, 1, 32, 32]              10\n","         Conv2d-1553            [-1, 1, 32, 32]              10\n","         Conv2d-1554            [-1, 1, 32, 32]              10\n","         Conv2d-1555            [-1, 1, 32, 32]              10\n","         Conv2d-1556            [-1, 1, 32, 32]              10\n","         Conv2d-1557            [-1, 1, 32, 32]              10\n","         Conv2d-1558            [-1, 1, 32, 32]              10\n","         Conv2d-1559            [-1, 1, 32, 32]              10\n","         Conv2d-1560            [-1, 1, 32, 32]              10\n","         Conv2d-1561            [-1, 1, 32, 32]              10\n","         Conv2d-1562            [-1, 1, 32, 32]              10\n","         Conv2d-1563            [-1, 1, 32, 32]              10\n","         Conv2d-1564            [-1, 1, 32, 32]              10\n","         Conv2d-1565            [-1, 1, 32, 32]              10\n","         Conv2d-1566            [-1, 1, 32, 32]              10\n","         Conv2d-1567            [-1, 1, 32, 32]              10\n","         Conv2d-1568            [-1, 1, 32, 32]              10\n","         Conv2d-1569            [-1, 1, 32, 32]              10\n","         Conv2d-1570            [-1, 1, 32, 32]              10\n","         Conv2d-1571            [-1, 1, 32, 32]              10\n","         Conv2d-1572            [-1, 1, 32, 32]              10\n","         Conv2d-1573            [-1, 1, 32, 32]              10\n","         Conv2d-1574            [-1, 1, 32, 32]              10\n","         Conv2d-1575            [-1, 1, 32, 32]              10\n","         Conv2d-1576            [-1, 1, 32, 32]              10\n","         Conv2d-1577            [-1, 1, 32, 32]              10\n","         Conv2d-1578            [-1, 1, 32, 32]              10\n","         Conv2d-1579            [-1, 1, 32, 32]              10\n","         Conv2d-1580            [-1, 1, 32, 32]              10\n","         Conv2d-1581            [-1, 1, 32, 32]              10\n","         Conv2d-1582            [-1, 1, 32, 32]              10\n","         Conv2d-1583            [-1, 1, 32, 32]              10\n","         Conv2d-1584            [-1, 1, 32, 32]              10\n","         Conv2d-1585            [-1, 1, 32, 32]              10\n","         Conv2d-1586            [-1, 1, 32, 32]              10\n","         Conv2d-1587            [-1, 1, 32, 32]              10\n","         Conv2d-1588            [-1, 1, 32, 32]              10\n","         Conv2d-1589            [-1, 1, 32, 32]              10\n","         Conv2d-1590            [-1, 1, 32, 32]              10\n","         Conv2d-1591            [-1, 1, 32, 32]              10\n","         Conv2d-1592            [-1, 1, 32, 32]              10\n","         Conv2d-1593            [-1, 1, 32, 32]              10\n","         Conv2d-1594            [-1, 1, 32, 32]              10\n","         Conv2d-1595            [-1, 1, 32, 32]              10\n","         Conv2d-1596            [-1, 1, 32, 32]              10\n","         Conv2d-1597            [-1, 1, 32, 32]              10\n","         Conv2d-1598            [-1, 1, 32, 32]              10\n","         Conv2d-1599            [-1, 1, 32, 32]              10\n","         Conv2d-1600            [-1, 1, 32, 32]              10\n","         Conv2d-1601            [-1, 1, 32, 32]              10\n","         Conv2d-1602            [-1, 1, 32, 32]              10\n","         Conv2d-1603            [-1, 1, 32, 32]              10\n","         Conv2d-1604            [-1, 1, 32, 32]              10\n","         Conv2d-1605            [-1, 1, 32, 32]              10\n","         Conv2d-1606            [-1, 1, 32, 32]              10\n","         Conv2d-1607            [-1, 1, 32, 32]              10\n","         Conv2d-1608            [-1, 1, 32, 32]              10\n","   PixelShuffle-1609          [-1, 1, 256, 256]               0\n","         Conv2d-1610            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-1611            [-1, 1, 32, 32]               0\n","         Conv2d-1612            [-1, 1, 32, 32]              10\n","         Conv2d-1613            [-1, 1, 32, 32]              10\n","         Conv2d-1614            [-1, 1, 32, 32]              10\n","         Conv2d-1615            [-1, 1, 32, 32]              10\n","         Conv2d-1616            [-1, 1, 32, 32]              10\n","         Conv2d-1617            [-1, 1, 32, 32]              10\n","         Conv2d-1618            [-1, 1, 32, 32]              10\n","         Conv2d-1619            [-1, 1, 32, 32]              10\n","         Conv2d-1620            [-1, 1, 32, 32]              10\n","         Conv2d-1621            [-1, 1, 32, 32]              10\n","         Conv2d-1622            [-1, 1, 32, 32]              10\n","         Conv2d-1623            [-1, 1, 32, 32]              10\n","         Conv2d-1624            [-1, 1, 32, 32]              10\n","         Conv2d-1625            [-1, 1, 32, 32]              10\n","         Conv2d-1626            [-1, 1, 32, 32]              10\n","         Conv2d-1627            [-1, 1, 32, 32]              10\n","         Conv2d-1628            [-1, 1, 32, 32]              10\n","         Conv2d-1629            [-1, 1, 32, 32]              10\n","         Conv2d-1630            [-1, 1, 32, 32]              10\n","         Conv2d-1631            [-1, 1, 32, 32]              10\n","         Conv2d-1632            [-1, 1, 32, 32]              10\n","         Conv2d-1633            [-1, 1, 32, 32]              10\n","         Conv2d-1634            [-1, 1, 32, 32]              10\n","         Conv2d-1635            [-1, 1, 32, 32]              10\n","         Conv2d-1636            [-1, 1, 32, 32]              10\n","         Conv2d-1637            [-1, 1, 32, 32]              10\n","         Conv2d-1638            [-1, 1, 32, 32]              10\n","         Conv2d-1639            [-1, 1, 32, 32]              10\n","         Conv2d-1640            [-1, 1, 32, 32]              10\n","         Conv2d-1641            [-1, 1, 32, 32]              10\n","         Conv2d-1642            [-1, 1, 32, 32]              10\n","         Conv2d-1643            [-1, 1, 32, 32]              10\n","         Conv2d-1644            [-1, 1, 32, 32]              10\n","         Conv2d-1645            [-1, 1, 32, 32]              10\n","         Conv2d-1646            [-1, 1, 32, 32]              10\n","         Conv2d-1647            [-1, 1, 32, 32]              10\n","         Conv2d-1648            [-1, 1, 32, 32]              10\n","         Conv2d-1649            [-1, 1, 32, 32]              10\n","         Conv2d-1650            [-1, 1, 32, 32]              10\n","         Conv2d-1651            [-1, 1, 32, 32]              10\n","         Conv2d-1652            [-1, 1, 32, 32]              10\n","         Conv2d-1653            [-1, 1, 32, 32]              10\n","         Conv2d-1654            [-1, 1, 32, 32]              10\n","         Conv2d-1655            [-1, 1, 32, 32]              10\n","         Conv2d-1656            [-1, 1, 32, 32]              10\n","         Conv2d-1657            [-1, 1, 32, 32]              10\n","         Conv2d-1658            [-1, 1, 32, 32]              10\n","         Conv2d-1659            [-1, 1, 32, 32]              10\n","         Conv2d-1660            [-1, 1, 32, 32]              10\n","         Conv2d-1661            [-1, 1, 32, 32]              10\n","         Conv2d-1662            [-1, 1, 32, 32]              10\n","         Conv2d-1663            [-1, 1, 32, 32]              10\n","         Conv2d-1664            [-1, 1, 32, 32]              10\n","         Conv2d-1665            [-1, 1, 32, 32]              10\n","         Conv2d-1666            [-1, 1, 32, 32]              10\n","         Conv2d-1667            [-1, 1, 32, 32]              10\n","         Conv2d-1668            [-1, 1, 32, 32]              10\n","         Conv2d-1669            [-1, 1, 32, 32]              10\n","         Conv2d-1670            [-1, 1, 32, 32]              10\n","         Conv2d-1671            [-1, 1, 32, 32]              10\n","         Conv2d-1672            [-1, 1, 32, 32]              10\n","         Conv2d-1673            [-1, 1, 32, 32]              10\n","         Conv2d-1674            [-1, 1, 32, 32]              10\n","         Conv2d-1675            [-1, 1, 32, 32]              10\n","   PixelShuffle-1676          [-1, 1, 256, 256]               0\n","         Conv2d-1677            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-1678            [-1, 1, 32, 32]               0\n","         Conv2d-1679            [-1, 1, 32, 32]              10\n","         Conv2d-1680            [-1, 1, 32, 32]              10\n","         Conv2d-1681            [-1, 1, 32, 32]              10\n","         Conv2d-1682            [-1, 1, 32, 32]              10\n","         Conv2d-1683            [-1, 1, 32, 32]              10\n","         Conv2d-1684            [-1, 1, 32, 32]              10\n","         Conv2d-1685            [-1, 1, 32, 32]              10\n","         Conv2d-1686            [-1, 1, 32, 32]              10\n","         Conv2d-1687            [-1, 1, 32, 32]              10\n","         Conv2d-1688            [-1, 1, 32, 32]              10\n","         Conv2d-1689            [-1, 1, 32, 32]              10\n","         Conv2d-1690            [-1, 1, 32, 32]              10\n","         Conv2d-1691            [-1, 1, 32, 32]              10\n","         Conv2d-1692            [-1, 1, 32, 32]              10\n","         Conv2d-1693            [-1, 1, 32, 32]              10\n","         Conv2d-1694            [-1, 1, 32, 32]              10\n","         Conv2d-1695            [-1, 1, 32, 32]              10\n","         Conv2d-1696            [-1, 1, 32, 32]              10\n","         Conv2d-1697            [-1, 1, 32, 32]              10\n","         Conv2d-1698            [-1, 1, 32, 32]              10\n","         Conv2d-1699            [-1, 1, 32, 32]              10\n","         Conv2d-1700            [-1, 1, 32, 32]              10\n","         Conv2d-1701            [-1, 1, 32, 32]              10\n","         Conv2d-1702            [-1, 1, 32, 32]              10\n","         Conv2d-1703            [-1, 1, 32, 32]              10\n","         Conv2d-1704            [-1, 1, 32, 32]              10\n","         Conv2d-1705            [-1, 1, 32, 32]              10\n","         Conv2d-1706            [-1, 1, 32, 32]              10\n","         Conv2d-1707            [-1, 1, 32, 32]              10\n","         Conv2d-1708            [-1, 1, 32, 32]              10\n","         Conv2d-1709            [-1, 1, 32, 32]              10\n","         Conv2d-1710            [-1, 1, 32, 32]              10\n","         Conv2d-1711            [-1, 1, 32, 32]              10\n","         Conv2d-1712            [-1, 1, 32, 32]              10\n","         Conv2d-1713            [-1, 1, 32, 32]              10\n","         Conv2d-1714            [-1, 1, 32, 32]              10\n","         Conv2d-1715            [-1, 1, 32, 32]              10\n","         Conv2d-1716            [-1, 1, 32, 32]              10\n","         Conv2d-1717            [-1, 1, 32, 32]              10\n","         Conv2d-1718            [-1, 1, 32, 32]              10\n","         Conv2d-1719            [-1, 1, 32, 32]              10\n","         Conv2d-1720            [-1, 1, 32, 32]              10\n","         Conv2d-1721            [-1, 1, 32, 32]              10\n","         Conv2d-1722            [-1, 1, 32, 32]              10\n","         Conv2d-1723            [-1, 1, 32, 32]              10\n","         Conv2d-1724            [-1, 1, 32, 32]              10\n","         Conv2d-1725            [-1, 1, 32, 32]              10\n","         Conv2d-1726            [-1, 1, 32, 32]              10\n","         Conv2d-1727            [-1, 1, 32, 32]              10\n","         Conv2d-1728            [-1, 1, 32, 32]              10\n","         Conv2d-1729            [-1, 1, 32, 32]              10\n","         Conv2d-1730            [-1, 1, 32, 32]              10\n","         Conv2d-1731            [-1, 1, 32, 32]              10\n","         Conv2d-1732            [-1, 1, 32, 32]              10\n","         Conv2d-1733            [-1, 1, 32, 32]              10\n","         Conv2d-1734            [-1, 1, 32, 32]              10\n","         Conv2d-1735            [-1, 1, 32, 32]              10\n","         Conv2d-1736            [-1, 1, 32, 32]              10\n","         Conv2d-1737            [-1, 1, 32, 32]              10\n","         Conv2d-1738            [-1, 1, 32, 32]              10\n","         Conv2d-1739            [-1, 1, 32, 32]              10\n","         Conv2d-1740            [-1, 1, 32, 32]              10\n","         Conv2d-1741            [-1, 1, 32, 32]              10\n","         Conv2d-1742            [-1, 1, 32, 32]              10\n","   PixelShuffle-1743          [-1, 1, 256, 256]               0\n","         Conv2d-1744            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-1745            [-1, 1, 32, 32]               0\n","         Conv2d-1746            [-1, 1, 32, 32]              10\n","         Conv2d-1747            [-1, 1, 32, 32]              10\n","         Conv2d-1748            [-1, 1, 32, 32]              10\n","         Conv2d-1749            [-1, 1, 32, 32]              10\n","         Conv2d-1750            [-1, 1, 32, 32]              10\n","         Conv2d-1751            [-1, 1, 32, 32]              10\n","         Conv2d-1752            [-1, 1, 32, 32]              10\n","         Conv2d-1753            [-1, 1, 32, 32]              10\n","         Conv2d-1754            [-1, 1, 32, 32]              10\n","         Conv2d-1755            [-1, 1, 32, 32]              10\n","         Conv2d-1756            [-1, 1, 32, 32]              10\n","         Conv2d-1757            [-1, 1, 32, 32]              10\n","         Conv2d-1758            [-1, 1, 32, 32]              10\n","         Conv2d-1759            [-1, 1, 32, 32]              10\n","         Conv2d-1760            [-1, 1, 32, 32]              10\n","         Conv2d-1761            [-1, 1, 32, 32]              10\n","         Conv2d-1762            [-1, 1, 32, 32]              10\n","         Conv2d-1763            [-1, 1, 32, 32]              10\n","         Conv2d-1764            [-1, 1, 32, 32]              10\n","         Conv2d-1765            [-1, 1, 32, 32]              10\n","         Conv2d-1766            [-1, 1, 32, 32]              10\n","         Conv2d-1767            [-1, 1, 32, 32]              10\n","         Conv2d-1768            [-1, 1, 32, 32]              10\n","         Conv2d-1769            [-1, 1, 32, 32]              10\n","         Conv2d-1770            [-1, 1, 32, 32]              10\n","         Conv2d-1771            [-1, 1, 32, 32]              10\n","         Conv2d-1772            [-1, 1, 32, 32]              10\n","         Conv2d-1773            [-1, 1, 32, 32]              10\n","         Conv2d-1774            [-1, 1, 32, 32]              10\n","         Conv2d-1775            [-1, 1, 32, 32]              10\n","         Conv2d-1776            [-1, 1, 32, 32]              10\n","         Conv2d-1777            [-1, 1, 32, 32]              10\n","         Conv2d-1778            [-1, 1, 32, 32]              10\n","         Conv2d-1779            [-1, 1, 32, 32]              10\n","         Conv2d-1780            [-1, 1, 32, 32]              10\n","         Conv2d-1781            [-1, 1, 32, 32]              10\n","         Conv2d-1782            [-1, 1, 32, 32]              10\n","         Conv2d-1783            [-1, 1, 32, 32]              10\n","         Conv2d-1784            [-1, 1, 32, 32]              10\n","         Conv2d-1785            [-1, 1, 32, 32]              10\n","         Conv2d-1786            [-1, 1, 32, 32]              10\n","         Conv2d-1787            [-1, 1, 32, 32]              10\n","         Conv2d-1788            [-1, 1, 32, 32]              10\n","         Conv2d-1789            [-1, 1, 32, 32]              10\n","         Conv2d-1790            [-1, 1, 32, 32]              10\n","         Conv2d-1791            [-1, 1, 32, 32]              10\n","         Conv2d-1792            [-1, 1, 32, 32]              10\n","         Conv2d-1793            [-1, 1, 32, 32]              10\n","         Conv2d-1794            [-1, 1, 32, 32]              10\n","         Conv2d-1795            [-1, 1, 32, 32]              10\n","         Conv2d-1796            [-1, 1, 32, 32]              10\n","         Conv2d-1797            [-1, 1, 32, 32]              10\n","         Conv2d-1798            [-1, 1, 32, 32]              10\n","         Conv2d-1799            [-1, 1, 32, 32]              10\n","         Conv2d-1800            [-1, 1, 32, 32]              10\n","         Conv2d-1801            [-1, 1, 32, 32]              10\n","         Conv2d-1802            [-1, 1, 32, 32]              10\n","         Conv2d-1803            [-1, 1, 32, 32]              10\n","         Conv2d-1804            [-1, 1, 32, 32]              10\n","         Conv2d-1805            [-1, 1, 32, 32]              10\n","         Conv2d-1806            [-1, 1, 32, 32]              10\n","         Conv2d-1807            [-1, 1, 32, 32]              10\n","         Conv2d-1808            [-1, 1, 32, 32]              10\n","         Conv2d-1809            [-1, 1, 32, 32]              10\n","   PixelShuffle-1810          [-1, 1, 256, 256]               0\n","         Conv2d-1811            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-1812            [-1, 1, 32, 32]               0\n","         Conv2d-1813            [-1, 1, 32, 32]              10\n","         Conv2d-1814            [-1, 1, 32, 32]              10\n","         Conv2d-1815            [-1, 1, 32, 32]              10\n","         Conv2d-1816            [-1, 1, 32, 32]              10\n","         Conv2d-1817            [-1, 1, 32, 32]              10\n","         Conv2d-1818            [-1, 1, 32, 32]              10\n","         Conv2d-1819            [-1, 1, 32, 32]              10\n","         Conv2d-1820            [-1, 1, 32, 32]              10\n","         Conv2d-1821            [-1, 1, 32, 32]              10\n","         Conv2d-1822            [-1, 1, 32, 32]              10\n","         Conv2d-1823            [-1, 1, 32, 32]              10\n","         Conv2d-1824            [-1, 1, 32, 32]              10\n","         Conv2d-1825            [-1, 1, 32, 32]              10\n","         Conv2d-1826            [-1, 1, 32, 32]              10\n","         Conv2d-1827            [-1, 1, 32, 32]              10\n","         Conv2d-1828            [-1, 1, 32, 32]              10\n","         Conv2d-1829            [-1, 1, 32, 32]              10\n","         Conv2d-1830            [-1, 1, 32, 32]              10\n","         Conv2d-1831            [-1, 1, 32, 32]              10\n","         Conv2d-1832            [-1, 1, 32, 32]              10\n","         Conv2d-1833            [-1, 1, 32, 32]              10\n","         Conv2d-1834            [-1, 1, 32, 32]              10\n","         Conv2d-1835            [-1, 1, 32, 32]              10\n","         Conv2d-1836            [-1, 1, 32, 32]              10\n","         Conv2d-1837            [-1, 1, 32, 32]              10\n","         Conv2d-1838            [-1, 1, 32, 32]              10\n","         Conv2d-1839            [-1, 1, 32, 32]              10\n","         Conv2d-1840            [-1, 1, 32, 32]              10\n","         Conv2d-1841            [-1, 1, 32, 32]              10\n","         Conv2d-1842            [-1, 1, 32, 32]              10\n","         Conv2d-1843            [-1, 1, 32, 32]              10\n","         Conv2d-1844            [-1, 1, 32, 32]              10\n","         Conv2d-1845            [-1, 1, 32, 32]              10\n","         Conv2d-1846            [-1, 1, 32, 32]              10\n","         Conv2d-1847            [-1, 1, 32, 32]              10\n","         Conv2d-1848            [-1, 1, 32, 32]              10\n","         Conv2d-1849            [-1, 1, 32, 32]              10\n","         Conv2d-1850            [-1, 1, 32, 32]              10\n","         Conv2d-1851            [-1, 1, 32, 32]              10\n","         Conv2d-1852            [-1, 1, 32, 32]              10\n","         Conv2d-1853            [-1, 1, 32, 32]              10\n","         Conv2d-1854            [-1, 1, 32, 32]              10\n","         Conv2d-1855            [-1, 1, 32, 32]              10\n","         Conv2d-1856            [-1, 1, 32, 32]              10\n","         Conv2d-1857            [-1, 1, 32, 32]              10\n","         Conv2d-1858            [-1, 1, 32, 32]              10\n","         Conv2d-1859            [-1, 1, 32, 32]              10\n","         Conv2d-1860            [-1, 1, 32, 32]              10\n","         Conv2d-1861            [-1, 1, 32, 32]              10\n","         Conv2d-1862            [-1, 1, 32, 32]              10\n","         Conv2d-1863            [-1, 1, 32, 32]              10\n","         Conv2d-1864            [-1, 1, 32, 32]              10\n","         Conv2d-1865            [-1, 1, 32, 32]              10\n","         Conv2d-1866            [-1, 1, 32, 32]              10\n","         Conv2d-1867            [-1, 1, 32, 32]              10\n","         Conv2d-1868            [-1, 1, 32, 32]              10\n","         Conv2d-1869            [-1, 1, 32, 32]              10\n","         Conv2d-1870            [-1, 1, 32, 32]              10\n","         Conv2d-1871            [-1, 1, 32, 32]              10\n","         Conv2d-1872            [-1, 1, 32, 32]              10\n","         Conv2d-1873            [-1, 1, 32, 32]              10\n","         Conv2d-1874            [-1, 1, 32, 32]              10\n","         Conv2d-1875            [-1, 1, 32, 32]              10\n","         Conv2d-1876            [-1, 1, 32, 32]              10\n","   PixelShuffle-1877          [-1, 1, 256, 256]               0\n","         Conv2d-1878            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-1879            [-1, 1, 32, 32]               0\n","         Conv2d-1880            [-1, 1, 32, 32]              10\n","         Conv2d-1881            [-1, 1, 32, 32]              10\n","         Conv2d-1882            [-1, 1, 32, 32]              10\n","         Conv2d-1883            [-1, 1, 32, 32]              10\n","         Conv2d-1884            [-1, 1, 32, 32]              10\n","         Conv2d-1885            [-1, 1, 32, 32]              10\n","         Conv2d-1886            [-1, 1, 32, 32]              10\n","         Conv2d-1887            [-1, 1, 32, 32]              10\n","         Conv2d-1888            [-1, 1, 32, 32]              10\n","         Conv2d-1889            [-1, 1, 32, 32]              10\n","         Conv2d-1890            [-1, 1, 32, 32]              10\n","         Conv2d-1891            [-1, 1, 32, 32]              10\n","         Conv2d-1892            [-1, 1, 32, 32]              10\n","         Conv2d-1893            [-1, 1, 32, 32]              10\n","         Conv2d-1894            [-1, 1, 32, 32]              10\n","         Conv2d-1895            [-1, 1, 32, 32]              10\n","         Conv2d-1896            [-1, 1, 32, 32]              10\n","         Conv2d-1897            [-1, 1, 32, 32]              10\n","         Conv2d-1898            [-1, 1, 32, 32]              10\n","         Conv2d-1899            [-1, 1, 32, 32]              10\n","         Conv2d-1900            [-1, 1, 32, 32]              10\n","         Conv2d-1901            [-1, 1, 32, 32]              10\n","         Conv2d-1902            [-1, 1, 32, 32]              10\n","         Conv2d-1903            [-1, 1, 32, 32]              10\n","         Conv2d-1904            [-1, 1, 32, 32]              10\n","         Conv2d-1905            [-1, 1, 32, 32]              10\n","         Conv2d-1906            [-1, 1, 32, 32]              10\n","         Conv2d-1907            [-1, 1, 32, 32]              10\n","         Conv2d-1908            [-1, 1, 32, 32]              10\n","         Conv2d-1909            [-1, 1, 32, 32]              10\n","         Conv2d-1910            [-1, 1, 32, 32]              10\n","         Conv2d-1911            [-1, 1, 32, 32]              10\n","         Conv2d-1912            [-1, 1, 32, 32]              10\n","         Conv2d-1913            [-1, 1, 32, 32]              10\n","         Conv2d-1914            [-1, 1, 32, 32]              10\n","         Conv2d-1915            [-1, 1, 32, 32]              10\n","         Conv2d-1916            [-1, 1, 32, 32]              10\n","         Conv2d-1917            [-1, 1, 32, 32]              10\n","         Conv2d-1918            [-1, 1, 32, 32]              10\n","         Conv2d-1919            [-1, 1, 32, 32]              10\n","         Conv2d-1920            [-1, 1, 32, 32]              10\n","         Conv2d-1921            [-1, 1, 32, 32]              10\n","         Conv2d-1922            [-1, 1, 32, 32]              10\n","         Conv2d-1923            [-1, 1, 32, 32]              10\n","         Conv2d-1924            [-1, 1, 32, 32]              10\n","         Conv2d-1925            [-1, 1, 32, 32]              10\n","         Conv2d-1926            [-1, 1, 32, 32]              10\n","         Conv2d-1927            [-1, 1, 32, 32]              10\n","         Conv2d-1928            [-1, 1, 32, 32]              10\n","         Conv2d-1929            [-1, 1, 32, 32]              10\n","         Conv2d-1930            [-1, 1, 32, 32]              10\n","         Conv2d-1931            [-1, 1, 32, 32]              10\n","         Conv2d-1932            [-1, 1, 32, 32]              10\n","         Conv2d-1933            [-1, 1, 32, 32]              10\n","         Conv2d-1934            [-1, 1, 32, 32]              10\n","         Conv2d-1935            [-1, 1, 32, 32]              10\n","         Conv2d-1936            [-1, 1, 32, 32]              10\n","         Conv2d-1937            [-1, 1, 32, 32]              10\n","         Conv2d-1938            [-1, 1, 32, 32]              10\n","         Conv2d-1939            [-1, 1, 32, 32]              10\n","         Conv2d-1940            [-1, 1, 32, 32]              10\n","         Conv2d-1941            [-1, 1, 32, 32]              10\n","         Conv2d-1942            [-1, 1, 32, 32]              10\n","         Conv2d-1943            [-1, 1, 32, 32]              10\n","   PixelShuffle-1944          [-1, 1, 256, 256]               0\n","         Conv2d-1945            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-1946            [-1, 1, 32, 32]               0\n","         Conv2d-1947            [-1, 1, 32, 32]              10\n","         Conv2d-1948            [-1, 1, 32, 32]              10\n","         Conv2d-1949            [-1, 1, 32, 32]              10\n","         Conv2d-1950            [-1, 1, 32, 32]              10\n","         Conv2d-1951            [-1, 1, 32, 32]              10\n","         Conv2d-1952            [-1, 1, 32, 32]              10\n","         Conv2d-1953            [-1, 1, 32, 32]              10\n","         Conv2d-1954            [-1, 1, 32, 32]              10\n","         Conv2d-1955            [-1, 1, 32, 32]              10\n","         Conv2d-1956            [-1, 1, 32, 32]              10\n","         Conv2d-1957            [-1, 1, 32, 32]              10\n","         Conv2d-1958            [-1, 1, 32, 32]              10\n","         Conv2d-1959            [-1, 1, 32, 32]              10\n","         Conv2d-1960            [-1, 1, 32, 32]              10\n","         Conv2d-1961            [-1, 1, 32, 32]              10\n","         Conv2d-1962            [-1, 1, 32, 32]              10\n","         Conv2d-1963            [-1, 1, 32, 32]              10\n","         Conv2d-1964            [-1, 1, 32, 32]              10\n","         Conv2d-1965            [-1, 1, 32, 32]              10\n","         Conv2d-1966            [-1, 1, 32, 32]              10\n","         Conv2d-1967            [-1, 1, 32, 32]              10\n","         Conv2d-1968            [-1, 1, 32, 32]              10\n","         Conv2d-1969            [-1, 1, 32, 32]              10\n","         Conv2d-1970            [-1, 1, 32, 32]              10\n","         Conv2d-1971            [-1, 1, 32, 32]              10\n","         Conv2d-1972            [-1, 1, 32, 32]              10\n","         Conv2d-1973            [-1, 1, 32, 32]              10\n","         Conv2d-1974            [-1, 1, 32, 32]              10\n","         Conv2d-1975            [-1, 1, 32, 32]              10\n","         Conv2d-1976            [-1, 1, 32, 32]              10\n","         Conv2d-1977            [-1, 1, 32, 32]              10\n","         Conv2d-1978            [-1, 1, 32, 32]              10\n","         Conv2d-1979            [-1, 1, 32, 32]              10\n","         Conv2d-1980            [-1, 1, 32, 32]              10\n","         Conv2d-1981            [-1, 1, 32, 32]              10\n","         Conv2d-1982            [-1, 1, 32, 32]              10\n","         Conv2d-1983            [-1, 1, 32, 32]              10\n","         Conv2d-1984            [-1, 1, 32, 32]              10\n","         Conv2d-1985            [-1, 1, 32, 32]              10\n","         Conv2d-1986            [-1, 1, 32, 32]              10\n","         Conv2d-1987            [-1, 1, 32, 32]              10\n","         Conv2d-1988            [-1, 1, 32, 32]              10\n","         Conv2d-1989            [-1, 1, 32, 32]              10\n","         Conv2d-1990            [-1, 1, 32, 32]              10\n","         Conv2d-1991            [-1, 1, 32, 32]              10\n","         Conv2d-1992            [-1, 1, 32, 32]              10\n","         Conv2d-1993            [-1, 1, 32, 32]              10\n","         Conv2d-1994            [-1, 1, 32, 32]              10\n","         Conv2d-1995            [-1, 1, 32, 32]              10\n","         Conv2d-1996            [-1, 1, 32, 32]              10\n","         Conv2d-1997            [-1, 1, 32, 32]              10\n","         Conv2d-1998            [-1, 1, 32, 32]              10\n","         Conv2d-1999            [-1, 1, 32, 32]              10\n","         Conv2d-2000            [-1, 1, 32, 32]              10\n","         Conv2d-2001            [-1, 1, 32, 32]              10\n","         Conv2d-2002            [-1, 1, 32, 32]              10\n","         Conv2d-2003            [-1, 1, 32, 32]              10\n","         Conv2d-2004            [-1, 1, 32, 32]              10\n","         Conv2d-2005            [-1, 1, 32, 32]              10\n","         Conv2d-2006            [-1, 1, 32, 32]              10\n","         Conv2d-2007            [-1, 1, 32, 32]              10\n","         Conv2d-2008            [-1, 1, 32, 32]              10\n","         Conv2d-2009            [-1, 1, 32, 32]              10\n","         Conv2d-2010            [-1, 1, 32, 32]              10\n","   PixelShuffle-2011          [-1, 1, 256, 256]               0\n","         Conv2d-2012            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-2013            [-1, 1, 32, 32]               0\n","         Conv2d-2014            [-1, 1, 32, 32]              10\n","         Conv2d-2015            [-1, 1, 32, 32]              10\n","         Conv2d-2016            [-1, 1, 32, 32]              10\n","         Conv2d-2017            [-1, 1, 32, 32]              10\n","         Conv2d-2018            [-1, 1, 32, 32]              10\n","         Conv2d-2019            [-1, 1, 32, 32]              10\n","         Conv2d-2020            [-1, 1, 32, 32]              10\n","         Conv2d-2021            [-1, 1, 32, 32]              10\n","         Conv2d-2022            [-1, 1, 32, 32]              10\n","         Conv2d-2023            [-1, 1, 32, 32]              10\n","         Conv2d-2024            [-1, 1, 32, 32]              10\n","         Conv2d-2025            [-1, 1, 32, 32]              10\n","         Conv2d-2026            [-1, 1, 32, 32]              10\n","         Conv2d-2027            [-1, 1, 32, 32]              10\n","         Conv2d-2028            [-1, 1, 32, 32]              10\n","         Conv2d-2029            [-1, 1, 32, 32]              10\n","         Conv2d-2030            [-1, 1, 32, 32]              10\n","         Conv2d-2031            [-1, 1, 32, 32]              10\n","         Conv2d-2032            [-1, 1, 32, 32]              10\n","         Conv2d-2033            [-1, 1, 32, 32]              10\n","         Conv2d-2034            [-1, 1, 32, 32]              10\n","         Conv2d-2035            [-1, 1, 32, 32]              10\n","         Conv2d-2036            [-1, 1, 32, 32]              10\n","         Conv2d-2037            [-1, 1, 32, 32]              10\n","         Conv2d-2038            [-1, 1, 32, 32]              10\n","         Conv2d-2039            [-1, 1, 32, 32]              10\n","         Conv2d-2040            [-1, 1, 32, 32]              10\n","         Conv2d-2041            [-1, 1, 32, 32]              10\n","         Conv2d-2042            [-1, 1, 32, 32]              10\n","         Conv2d-2043            [-1, 1, 32, 32]              10\n","         Conv2d-2044            [-1, 1, 32, 32]              10\n","         Conv2d-2045            [-1, 1, 32, 32]              10\n","         Conv2d-2046            [-1, 1, 32, 32]              10\n","         Conv2d-2047            [-1, 1, 32, 32]              10\n","         Conv2d-2048            [-1, 1, 32, 32]              10\n","         Conv2d-2049            [-1, 1, 32, 32]              10\n","         Conv2d-2050            [-1, 1, 32, 32]              10\n","         Conv2d-2051            [-1, 1, 32, 32]              10\n","         Conv2d-2052            [-1, 1, 32, 32]              10\n","         Conv2d-2053            [-1, 1, 32, 32]              10\n","         Conv2d-2054            [-1, 1, 32, 32]              10\n","         Conv2d-2055            [-1, 1, 32, 32]              10\n","         Conv2d-2056            [-1, 1, 32, 32]              10\n","         Conv2d-2057            [-1, 1, 32, 32]              10\n","         Conv2d-2058            [-1, 1, 32, 32]              10\n","         Conv2d-2059            [-1, 1, 32, 32]              10\n","         Conv2d-2060            [-1, 1, 32, 32]              10\n","         Conv2d-2061            [-1, 1, 32, 32]              10\n","         Conv2d-2062            [-1, 1, 32, 32]              10\n","         Conv2d-2063            [-1, 1, 32, 32]              10\n","         Conv2d-2064            [-1, 1, 32, 32]              10\n","         Conv2d-2065            [-1, 1, 32, 32]              10\n","         Conv2d-2066            [-1, 1, 32, 32]              10\n","         Conv2d-2067            [-1, 1, 32, 32]              10\n","         Conv2d-2068            [-1, 1, 32, 32]              10\n","         Conv2d-2069            [-1, 1, 32, 32]              10\n","         Conv2d-2070            [-1, 1, 32, 32]              10\n","         Conv2d-2071            [-1, 1, 32, 32]              10\n","         Conv2d-2072            [-1, 1, 32, 32]              10\n","         Conv2d-2073            [-1, 1, 32, 32]              10\n","         Conv2d-2074            [-1, 1, 32, 32]              10\n","         Conv2d-2075            [-1, 1, 32, 32]              10\n","         Conv2d-2076            [-1, 1, 32, 32]              10\n","         Conv2d-2077            [-1, 1, 32, 32]              10\n","   PixelShuffle-2078          [-1, 1, 256, 256]               0\n","         Conv2d-2079            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-2080            [-1, 1, 32, 32]               0\n","         Conv2d-2081            [-1, 1, 32, 32]              10\n","         Conv2d-2082            [-1, 1, 32, 32]              10\n","         Conv2d-2083            [-1, 1, 32, 32]              10\n","         Conv2d-2084            [-1, 1, 32, 32]              10\n","         Conv2d-2085            [-1, 1, 32, 32]              10\n","         Conv2d-2086            [-1, 1, 32, 32]              10\n","         Conv2d-2087            [-1, 1, 32, 32]              10\n","         Conv2d-2088            [-1, 1, 32, 32]              10\n","         Conv2d-2089            [-1, 1, 32, 32]              10\n","         Conv2d-2090            [-1, 1, 32, 32]              10\n","         Conv2d-2091            [-1, 1, 32, 32]              10\n","         Conv2d-2092            [-1, 1, 32, 32]              10\n","         Conv2d-2093            [-1, 1, 32, 32]              10\n","         Conv2d-2094            [-1, 1, 32, 32]              10\n","         Conv2d-2095            [-1, 1, 32, 32]              10\n","         Conv2d-2096            [-1, 1, 32, 32]              10\n","         Conv2d-2097            [-1, 1, 32, 32]              10\n","         Conv2d-2098            [-1, 1, 32, 32]              10\n","         Conv2d-2099            [-1, 1, 32, 32]              10\n","         Conv2d-2100            [-1, 1, 32, 32]              10\n","         Conv2d-2101            [-1, 1, 32, 32]              10\n","         Conv2d-2102            [-1, 1, 32, 32]              10\n","         Conv2d-2103            [-1, 1, 32, 32]              10\n","         Conv2d-2104            [-1, 1, 32, 32]              10\n","         Conv2d-2105            [-1, 1, 32, 32]              10\n","         Conv2d-2106            [-1, 1, 32, 32]              10\n","         Conv2d-2107            [-1, 1, 32, 32]              10\n","         Conv2d-2108            [-1, 1, 32, 32]              10\n","         Conv2d-2109            [-1, 1, 32, 32]              10\n","         Conv2d-2110            [-1, 1, 32, 32]              10\n","         Conv2d-2111            [-1, 1, 32, 32]              10\n","         Conv2d-2112            [-1, 1, 32, 32]              10\n","         Conv2d-2113            [-1, 1, 32, 32]              10\n","         Conv2d-2114            [-1, 1, 32, 32]              10\n","         Conv2d-2115            [-1, 1, 32, 32]              10\n","         Conv2d-2116            [-1, 1, 32, 32]              10\n","         Conv2d-2117            [-1, 1, 32, 32]              10\n","         Conv2d-2118            [-1, 1, 32, 32]              10\n","         Conv2d-2119            [-1, 1, 32, 32]              10\n","         Conv2d-2120            [-1, 1, 32, 32]              10\n","         Conv2d-2121            [-1, 1, 32, 32]              10\n","         Conv2d-2122            [-1, 1, 32, 32]              10\n","         Conv2d-2123            [-1, 1, 32, 32]              10\n","         Conv2d-2124            [-1, 1, 32, 32]              10\n","         Conv2d-2125            [-1, 1, 32, 32]              10\n","         Conv2d-2126            [-1, 1, 32, 32]              10\n","         Conv2d-2127            [-1, 1, 32, 32]              10\n","         Conv2d-2128            [-1, 1, 32, 32]              10\n","         Conv2d-2129            [-1, 1, 32, 32]              10\n","         Conv2d-2130            [-1, 1, 32, 32]              10\n","         Conv2d-2131            [-1, 1, 32, 32]              10\n","         Conv2d-2132            [-1, 1, 32, 32]              10\n","         Conv2d-2133            [-1, 1, 32, 32]              10\n","         Conv2d-2134            [-1, 1, 32, 32]              10\n","         Conv2d-2135            [-1, 1, 32, 32]              10\n","         Conv2d-2136            [-1, 1, 32, 32]              10\n","         Conv2d-2137            [-1, 1, 32, 32]              10\n","         Conv2d-2138            [-1, 1, 32, 32]              10\n","         Conv2d-2139            [-1, 1, 32, 32]              10\n","         Conv2d-2140            [-1, 1, 32, 32]              10\n","         Conv2d-2141            [-1, 1, 32, 32]              10\n","         Conv2d-2142            [-1, 1, 32, 32]              10\n","         Conv2d-2143            [-1, 1, 32, 32]              10\n","         Conv2d-2144            [-1, 1, 32, 32]              10\n","   PixelShuffle-2145          [-1, 1, 256, 256]               0\n","         Conv2d-2146            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-2147            [-1, 1, 32, 32]               0\n","     WCNN_block-2148           [-1, 32, 32, 32]               0\n","           ReLU-2149           [-1, 32, 32, 32]               0\n","         Conv2d-2150            [-1, 3, 32, 32]           2,403\n","      ConvBlock-2151            [-1, 3, 32, 32]               0\n","           WCNN-2152            [-1, 3, 32, 32]               0\n","================================================================\n","Total params: 40,579\n","Trainable params: 40,579\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.01\n","Forward/backward pass size (MB): 34.57\n","Params size (MB): 0.15\n","Estimated Total Size (MB): 34.74\n","----------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EQghodZmvqRp","executionInfo":{"status":"ok","timestamp":1620788053122,"user_tz":-540,"elapsed":1095,"user":{"displayName":"김정기","photoUrl":"","userId":"02654207523640478753"}},"outputId":"c5e78a94-b220-44d4-ceaa-a162ca410017"},"source":["# 데이터 전처리 & 사용자 정의 data\n","\n","from __future__ import print_function\n","import argparse\n","\n","import os\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision.transforms import *\n","import torch\n","import math\n","from os.path import join\n","import torch.utils.data as data\n","import numpy as np\n","from os import listdir\n","from os.path import join\n","from PIL import Image, ImageOps, ImageFilter\n","import random\n","from random import randrange\n","from math import sqrt\n","\n","'''\n","1. filename 에 .png, .jpg, .jpeg 중 하나라도 있으면 True 를 반환하는 함수\n","'''\n","def is_image_file(filename):\n","    return any(filename.endswith(extension) for extension in [\".png\", \".jpg\", \".jpeg\"])\n","\n","'''\n","2. PIL 을 이용하여 filepath에서 이미지를 불러오고 RGB 로 convert 하여 반환하는 함수\n","'''\n","def load_img(filepath):\n","    img = Image.open(filepath).convert('RGB')\n","    return img\n","\n","'''\n","3. PIL 을 이용하여 이미지를 Bicubic 으로 scale 만큼 High Resolution 으로 만드는 함수\n","'''\n","def rescale_img(img_in, scale):\n","    size_in = img_in.size\n","    # size_in = img_in 의 (width, height) tuple\n","    new_size_in = tuple([int(x * scale) for x in size_in])\n","    # new_size_in = (width * scale, height * scale)\n","    img_in = img_in.resize(new_size_in, resample=Image.BICUBIC)\n","    return img_in\n","\n","'''\n","4. img_tar = load_img 함수를 이용하여 index 번째 image 를 RGB 로 불러온 이미지 \n","   img_in = target 으로 불러온 이미지를 Bicubic 으로 downscale 한 이미지 -> (사용할 일 없음)\n","   img_bic = rescale_img 함수로 input 을 다시 같은 비율로 upscale 한 이미지\n","\n","   training 에는 img_tar, img_bic 을 사용할 것이고, 이들 이미지 임의의 영역을\n","   upscale_factor*n x upscale_factor*n 크기로 잘라 이미지 크기를 같게 만들어 줌\n","   \n","   잘린 이미지는 같은 random point 에서 시작하여 잘리므로 이미지가 나타내는 임의의 영역이 같음\n","'''\n","def get_patch(img_in, img_tar, img_bic, patch_size, scale, ix=-1, iy=-1):\n","    (ih, iw) = img_in.size\n","    (th, tw) = (scale * ih, scale * iw)\n","\n","    patch_mult = scale #if len(scale) > 1 else 1\n","    tp = patch_mult * patch_size\n","    # tp = upscale_factor*n (n = patch_size)\n","    ip = tp // scale\n","    # ip = n (n = patch_size)\n","    \n","    if ix == -1:\n","        ix = random.randrange(0, iw - ip + 1)\n","    if iy == -1:\n","        iy = random.randrange(0, ih - ip + 1)\n","\n","    (tx, ty) = (scale * ix, scale * iy)\n","\n","    img_in = img_in.crop((iy,ix,iy + ip, ix + ip))\n","    # 원본이미지 임의의 영역을 n x n 크기로 자름\n","    img_tar = img_tar.crop((ty,tx,ty + tp, tx + tp))\n","    # downscale 한 이미지 임의의 영역을 upscale_factor*n x upscale_factor*n 크기로 자름\n","    img_bic = img_bic.crop((ty,tx,ty + tp, tx + tp))\n","    # upscale 한 이미지 임의의 영역을 upscale_factor*n x upscale_factor*n 크기로 자름            \n","    info_patch = {\n","        'ix': ix, 'iy': iy, 'ip': ip, 'tx': tx, 'ty': ty, 'tp': tp}\n","    # info_patch 에는 어떤 크기로 crop 했는지에 대한 정보가 있음\n","    return img_in, img_tar, img_bic, info_patch\n","\n","'''\n","5. 이미지데이터 증강(augmentation)\n","'''\n","def augment(img_in, img_tar, img_bic, flip_h=True, rot=True):\n","    info_aug = {'flip_h': False, 'flip_v': False, 'trans': False}\n","    \n","    if random.random() < 0.5 and flip_h:\n","        img_in = ImageOps.flip(img_in)\n","        img_tar = ImageOps.flip(img_tar)\n","        img_bic = ImageOps.flip(img_bic)\n","        info_aug['flip_h'] = True\n","    # 50%의 확률로, flip_h = True 면 img_in, img_tar, img_bic 을 모두 flip\n","\n","    if rot:\n","        if random.random() < 0.5:\n","            img_in = ImageOps.mirror(img_in)\n","            img_tar = ImageOps.mirror(img_tar)\n","            img_bic = ImageOps.mirror(img_bic)\n","            info_aug['flip_v'] = True\n","        if random.random() < 0.5:\n","            img_in = img_in.rotate(180)\n","            img_tar = img_tar.rotate(180)\n","            img_bic = img_bic.rotate(180)\n","            info_aug['trans'] = True\n","    # 50%의 확률로, rot = True 면 img_in, img_tar, img_bic 을 모두 mirror & 180도 rotate\n","    \n","    return img_in, img_tar, img_bic, info_aug\n","    # info_aug = 출력된 이미지에 어떤 preprocessing 을 했는지 알려줌\n","    \n","'''\n","6. PIL 이미지나 ndarray 이미지를 Tensor로 바꾸어주는 함수\n","   -> ToTensor 함수 사용시 이미지 pixel 값은 0~255 에서 0~1 로 바뀜\n","'''\n","def transform():\n","    return Compose([ToTensor(),])\n","\n","'''\n","7.사용자 정의 data 로드 - Training Data \n","'''        \n","class DatasetFromFolder(data.Dataset):\n","    '''\n","    def __init__(self, index) 에서는 필요한 변수를 선언 하고 'data 경로' 를 load 한다\n","    '''\n","    def __init__(self, image_dir, patch_size, upscale_factor, data_augmentation, transform=None):\n","        super(DatasetFromFolder, self).__init__()\n","        self.image_filenames = [join(image_dir, x) for x in listdir(image_dir) if is_image_file(x)]\n","        # self.image_filenames = image_dir 에 있는 모든 이미지의 경로 list\n","        self.patch_size = patch_size\n","        self.upscale_factor = upscale_factor\n","        self.transform = transform\n","        self.data_augmentation = data_augmentation\n","    '''\n","    def __getitem__(self, index) 에서는 index 번째 data를 return 하도록 코드를 짠다\n","    '''\n","    def __getitem__(self, index):\n","        target = load_img(self.image_filenames[index])\n","        # target = load_img 함수를 이용하여 index 번째 image 를 RGB 로 불러온 이미지\n","        input = target.resize((int(target.size[0]/self.upscale_factor),int(target.size[1]/self.upscale_factor)), Image.BICUBIC) \n","        # input = target 으로 불러온 이미지를 Bicubic 으로 downscale 한 이미지\n","        bicubic = rescale_img(input, self.upscale_factor)\n","        # bicubic = rescale_img 함수로 input 을 다시 같은 비율로 upscale 한 이미지\n","        \n","        input, target, bicubic, _ = get_patch(input,target,bicubic,self.patch_size, self.upscale_factor)\n","        # input, target, bicubic 이미지를 (upscale_factor*patch_size x upscale_factor*patch_size) 로 crop\n","        \n","        if self.data_augmentation:\n","            input, target, bicubic, _ = augment(input, target, bicubic)\n","        # data_augmentation = True 라면, 세 이미지를 augment 함수로 증강, img_aug 는 필요 없음\n","        \n","        if self.transform:\n","            input = self.transform(input)\n","            bicubic = self.transform(bicubic)\n","            target = self.transform(target)\n","        # self.transform = True 라면, 세 이미지를 PIL image 에서 Tensor로 바꾸어 줌\n","        return input, target, bicubic\n","    '''\n","    def __len__(self) 에서는 data의 len을 return 하도록 코드를 짠다\n","    '''\n","    def __len__(self):\n","        return len(self.image_filenames)\n","    \n","'''\n","8.사용자 정의 data 로드 - Test Data \n","   -> file 이름까지 사용자 정의 데이터화 시킴\n","   -> get_patch 함수를 사용하지 않기 때문에, SRCNN 의 입력으로 (원본 이미지 xscale) 된 이미지가 들어감\n","'''\n","class DatasetFromFolderEval(data.Dataset):\n","    def __init__(self, lr_dir, upscale_factor, transform=None):\n","        super(DatasetFromFolderEval, self).__init__()\n","        self.image_filenames = [join(lr_dir, x) for x in listdir(lr_dir) if is_image_file(x)]\n","        self.upscale_factor = upscale_factor\n","        self.transform = transform\n","\n","    def __getitem__(self, index):\n","        target = load_img(self.image_filenames[index])\n","        # target = load_img 함수를 이용하여 index 번째 image 를 RGB 로 불러온 이미지\n","        _, file = os.path.split(self.image_filenames[index])\n","        # file = 이미지 경로 list 에서 file 이름만 잘라 냄\n","\n","        input = target.resize((int(target.size[0]/self.upscale_factor),int(target.size[1]/self.upscale_factor)), Image.BICUBIC) \n","        # input = target 으로 불러온 이미지를 Bicubic 으로 downscale 한 이미지\n","        bicubic = rescale_img(input, self.upscale_factor)\n","        # bicubic = rescale_img 함수로 input 을 다시 같은 비율로 upscale 한 이미지\n","        \n","        if self.transform:\n","            input = self.transform(input)\n","            bicubic = self.transform(bicubic)\n","            target = self.transform(target)\n","         # self.transform = True 라면, 세 이미지를 PIL image 에서 Tensor로 바꾸어 줌\n","        \n","        return input, bicubic, target, file\n","        # file 이름까지 return\n","      \n","    def __len__(self):\n","        return len(self.image_filenames)\n","'''\n","9. Training Data 불러오기\n","'''\n","def get_training_set(data_dir, hr, upscale_factor, patch_size, data_augmentation):\n","    hr_dir = join(data_dir, hr)\n","    return DatasetFromFolder(hr_dir,patch_size, upscale_factor, data_augmentation,\n","                             transform=transform())\n","'''\n","10. Test Data 불러오기\n","'''\n","def get_eval_set(lr_dir, upscale_factor):\n","    return DatasetFromFolderEval(lr_dir, upscale_factor,\n","                             transform=transform())\n","\n","print('finish')\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["finish\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LCAb64GCKdZ_","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1620771442242,"user_tz":-540,"elapsed":15986914,"user":{"displayName":"김정기","photoUrl":"","userId":"02654207523640478753"}},"outputId":"2decd93c-47da-46cc-a2a1-73e541ad91ff"},"source":["# Data Load & Model Load & Optimizer \n","# Training\n","\n","from __future__ import print_function\n","import argparse\n","from math import log10\n","\n","import os\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.backends.cudnn as cudnn\n","from torch.autograd import Variable\n","from torch.utils.data import DataLoader\n","import pdb\n","import socket\n","import time\n","import easydict\n","\n","from torch.utils.tensorboard import SummaryWriter\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","opt = easydict.EasyDict({ \n","    \"batchSize\": 32,           # batch size - 한번에 training할 patch의 숫자\n","    \"lr\": 0.01,                # learning rate\n","    \"upscale_factor\": 2,       # Upscale 정도\n","    \"patch_size\": 32,         # 입력 이미지 크기\n","\n","    \"start_epoch\": 1,           \n","    \"nEpochs\": 100,            # epoch 횟수\n","    \"snapshots\": 10,           # weight 저장 주기\n","   \n","    \"data_dir\":\"/content/gdrive/MyDrive/졸업논문/data_800개/train\", # dataset이 저장된 위치\n","    \"hr_train_dataset\": \"DIV2K_train_HR\", # training에 사용할 dataset 종류\n","\n","    \"model_type\": \"WCNN\",         # 모델이름\n","    \"save_folder\": \"/content/gdrive/MyDrive/졸업논문/졸업논문/scale=2/weights_scale=2/\", # weight 저장 위치\n","\n","    \"pretrained_sr\": None, # pretrained model 경로\n","    \"pretrained\": False,\n","    \"data_augmentation\": False,\n","    \"gpu_mode\": True,\n","    \"threads\": 1, \n","    \"gpus\": 1 # 사용할 gpu 번호\n","    })\n","\n","'''\n","1. Training Data 로드\n","'''\n","print('===> Loading datasets')\n","train_set = get_training_set(opt.data_dir, opt.hr_train_dataset, opt.upscale_factor, opt.patch_size, opt.data_augmentation)\n","training_data_loader = DataLoader(dataset=train_set, num_workers=opt.threads, batch_size=opt.batchSize, shuffle=True)\n","\n","'''\n","2. WCNN 빌드 및 가중치 초기화 (가중치 초기화는 빌드와 동시에 수행)\n","'''\n","print('===> Building model ', opt.model_type)\n","model = WCNN()\n","print('===> Weight Initialization ')\n","\n","'''\n","3. Optimizer & Criterion 정의 \n","  -> MSE loss 사용\n","  -> Optimizer는 Adam 사용\n","'''\n","criterion = nn.MSELoss() \n","optimizer = optimizer = optim.Adam(model.parameters(), lr=opt.lr, betas=(0.9, 0.999), eps=1e-8)\n","# betas = SGD + Momentum 에서 momentum값, 0.9에서 시작하여 0.999로 증가\n","\n","'''\n","4. GPU 설정 및 parameter print\n","'''\n","gpus_list = range(opt.gpus)\n","cudnn.benchmark = True\n","print(opt)\n","\n","cuda = opt.gpu_mode\n","if cuda and not torch.cuda.is_available():\n","    raise Exception(\"No GPU found, please run without --cuda\")\n","\n","'''\n","5. GPU 사용 여부 및 pretrained model 설정\n","'''\n","if cuda:\n","    model = model.cuda(gpus_list[0])\n","    model = torch.nn.DataParallel(model, device_ids=gpus_list)\n","    criterion = criterion.cuda(gpus_list[0])\n","    \n","if opt.pretrained:\n","    model_name = os.path.join(opt.pretrained_sr)\n","    checkpoint = torch.load(model_name)\n","\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","    loss = checkpoint['loss']\n","    opt.start_epoch = checkpoint['epoch']\n","    print('Pre-trained SR model is loaded.')\n","    # pretrained model 불러오기\n","\n","'''\n","6. 한번의 epoch 에서 수행하는 과정 정의 및 Tensorboard\n","'''\n","%load_ext tensorboard\n","\n","%tensorboard tensorboard --logdir=/content/gdrive/My Drive/졸업논문/졸업논문/scale=2/logs_scale=2/ --port=6006\n","\n","writer = SummaryWriter('/content/gdrive/My Drive/졸업논문/졸업논문/scale=2/logs_scale=2/')\n","# log 를 저장할 위치 지정\n","\n","loss_list = []\n","\n","def train(epoch):\n","    epoch_loss = 0\n","    model.train()\n","    # model.train() 을 호출하여 학습 모드로 전환\n","    '''\n","    이때, 각 이미지는 'mini batch' 갯수만큼 가져온다!\n","    이때, autograd.Variable 을 사용하는 이유는 batch_data 라는 list 에 있는 input, target, blur_img 를 Tensor로 불러오기 위해\n","    '''\n","    for batch_idx, batch_data in enumerate(training_data_loader, start=1):\n","    # batch_data = (input[batch_idx], target[batch_idx], blur_img[batch_idx])\n","    # batch_idx = 세개의 mini-batch의 출력 이미지 set의 index\n","    # enumerate({list}, number) 로 사용하면 interation 이 0 이 아니라 number 부터 시작 함\n","        _, target, bicubic = Variable(batch_data[0]), Variable(batch_data[1]), Variable(batch_data[2])\n","        # autograd.Variable({tensor}) 라고 쓰면, {tensor} 를 불러옴 \n","        if cuda:\n","            # input = input.cuda(gpus_list[0])\n","            target = target.cuda(gpus_list[0])\n","            bicubic = bicubic.cuda(gpus_list[0])\n","\n","        optimizer.zero_grad()\n","        # gradient 를 0으로 초기화\n","        t0 = time.time()\n","        prediction = model(bicubic)\n","\n","        loss = criterion(prediction, target)\n","        epoch_loss += loss.data\n","        # 해당 mini-batch 에서 loss function 값\n","        loss.backward()\n","        # loss 를 가지고 gradient 계산\n","        optimizer.step()\n","        # 각 layer들의 weights 갱신\n","        t1 = time.time()\n","\n","        print(\"===> Epoch[{}]({}/{}): Loss: {:.4f} || Timer: {:.4f} sec.\".format(epoch, batch_idx, len(training_data_loader), loss.data, (t1 - t0)))\n","        # t1-t0 = 한 mini-batch 연산에 걸린 시간\n","\n","    print(\"===> Epoch {} Complete: Avg. Loss: {:.4f}\".format(epoch, epoch_loss / len(training_data_loader)))\n","    \n","    '''\n","    Model 의 Checkpoint 저장하기 for test(evaluation)\n","    '''\n","    if (epoch) % (opt.snapshots) == 0:\n","      model_out_path = opt.save_folder+\"WCNN_epoch_{}.pth\".format(epoch)\n","      torch.save({'epoch' : epoch,\n","              'model_state_dict' : model.state_dict(),\n","                'loss' : loss.data}, model_out_path)\n","      print(\"Checkpoint saved to {}\".format(model_out_path))\n","\n","    '''\n","    Tensorboard 에 매 epoch 마다 loss 저장하기\n","    '''\n","    writer.add_scalar('Epoch Loss', epoch_loss / len(training_data_loader), epoch )\n","    # 그래프의 가로축 = epoch, 세로 축 = epoch_loss / len(training_data_loader)\n","\n","    loss_list.append(epoch_loss / len(training_data_loader))\n","\n","if __name__ == '__main__':\n","    for epoch in range(opt.start_epoch, opt.nEpochs + 1):\n","        train(epoch)\n","\n","writer.close()\n","# writer 가 더이상 필요하지 않으므로 닫아준다\n","\n","print('Finished Training')\n"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","===> Loading datasets\n","===> Building model  WCNN\n","===> Weight Initialization \n","{'batchSize': 32, 'lr': 0.01, 'upscale_factor': 2, 'patch_size': 32, 'start_epoch': 1, 'nEpochs': 100, 'snapshots': 10, 'data_dir': '/content/gdrive/My Drive/졸업논문/data_800개/train', 'hr_train_dataset': 'DIV2K_train_HR', 'model_type': 'WCNN', 'save_folder': '/content/gdrive/My Drive/졸업논문/졸업논문/scale=2/weights_scale=2/', 'pretrained_sr': None, 'pretrained': False, 'data_augmentation': False, 'gpu_mode': True, 'threads': 1, 'gpus': 1}\n","The tensorboard extension is already loaded. To reload it, use:\n","  %reload_ext tensorboard\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/plain":["ERROR: Failed to launch TensorBoard (exited with 2).\n","Contents of stderr:\n","2021-05-11 17:50:57.220039: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","usage: tensorboard [-h] [--helpfull] {serve,dev} ...\n","tensorboard: error: invalid choice: 'tensorboard' (choose from 'serve', 'dev')"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["===> Epoch[1](1/25): Loss: 1.2969 || Timer: 1.9596 sec.\n","===> Epoch[1](2/25): Loss: 37.0427 || Timer: 1.9443 sec.\n","===> Epoch[1](3/25): Loss: 1.6949 || Timer: 1.9334 sec.\n","===> Epoch[1](4/25): Loss: 0.3055 || Timer: 1.9285 sec.\n","===> Epoch[1](5/25): Loss: 0.2307 || Timer: 1.9357 sec.\n","===> Epoch[1](6/25): Loss: 0.6782 || Timer: 1.9281 sec.\n","===> Epoch[1](7/25): Loss: 0.2793 || Timer: 1.9340 sec.\n","===> Epoch[1](8/25): Loss: 0.1549 || Timer: 1.9283 sec.\n","===> Epoch[1](9/25): Loss: 0.2099 || Timer: 1.9387 sec.\n","===> Epoch[1](10/25): Loss: 0.1953 || Timer: 1.9405 sec.\n","===> Epoch[1](11/25): Loss: 0.1372 || Timer: 1.9352 sec.\n","===> Epoch[1](12/25): Loss: 0.1218 || Timer: 1.9292 sec.\n","===> Epoch[1](13/25): Loss: 0.1917 || Timer: 1.9342 sec.\n","===> Epoch[1](14/25): Loss: 0.1297 || Timer: 1.9303 sec.\n","===> Epoch[1](15/25): Loss: 0.0563 || Timer: 1.9350 sec.\n","===> Epoch[1](16/25): Loss: 0.0968 || Timer: 1.9286 sec.\n","===> Epoch[1](17/25): Loss: 0.0822 || Timer: 1.9346 sec.\n","===> Epoch[1](18/25): Loss: 0.0775 || Timer: 1.9449 sec.\n","===> Epoch[1](19/25): Loss: 0.0817 || Timer: 1.9350 sec.\n","===> Epoch[1](20/25): Loss: 0.0748 || Timer: 1.9285 sec.\n","===> Epoch[1](21/25): Loss: 0.0648 || Timer: 1.9346 sec.\n","===> Epoch[1](22/25): Loss: 0.0619 || Timer: 1.9304 sec.\n","===> Epoch[1](23/25): Loss: 0.0646 || Timer: 1.9327 sec.\n","===> Epoch[1](24/25): Loss: 0.0589 || Timer: 1.9307 sec.\n","===> Epoch[1](25/25): Loss: 0.0385 || Timer: 1.9477 sec.\n","===> Epoch 1 Complete: Avg. Loss: 1.7371\n","===> Epoch[2](1/25): Loss: 0.0431 || Timer: 1.9449 sec.\n","===> Epoch[2](2/25): Loss: 0.0370 || Timer: 1.9297 sec.\n","===> Epoch[2](3/25): Loss: 0.0392 || Timer: 1.9324 sec.\n","===> Epoch[2](4/25): Loss: 0.0291 || Timer: 1.9297 sec.\n","===> Epoch[2](5/25): Loss: 0.0350 || Timer: 1.9321 sec.\n","===> Epoch[2](6/25): Loss: 0.0319 || Timer: 1.9300 sec.\n","===> Epoch[2](7/25): Loss: 0.0406 || Timer: 1.9499 sec.\n","===> Epoch[2](8/25): Loss: 0.0275 || Timer: 1.9308 sec.\n","===> Epoch[2](9/25): Loss: 0.0275 || Timer: 1.9323 sec.\n","===> Epoch[2](10/25): Loss: 0.0351 || Timer: 1.9317 sec.\n","===> Epoch[2](11/25): Loss: 0.0333 || Timer: 1.9337 sec.\n","===> Epoch[2](12/25): Loss: 0.0369 || Timer: 1.9325 sec.\n","===> Epoch[2](13/25): Loss: 0.0253 || Timer: 1.9337 sec.\n","===> Epoch[2](14/25): Loss: 0.0245 || Timer: 1.9436 sec.\n","===> Epoch[2](15/25): Loss: 0.0278 || Timer: 1.9301 sec.\n","===> Epoch[2](16/25): Loss: 0.0295 || Timer: 1.9289 sec.\n","===> Epoch[2](17/25): Loss: 0.0268 || Timer: 1.9343 sec.\n","===> Epoch[2](18/25): Loss: 0.0237 || Timer: 1.9301 sec.\n","===> Epoch[2](19/25): Loss: 0.0241 || Timer: 1.9319 sec.\n","===> Epoch[2](20/25): Loss: 0.0247 || Timer: 1.9288 sec.\n","===> Epoch[2](21/25): Loss: 0.0257 || Timer: 1.9317 sec.\n","===> Epoch[2](22/25): Loss: 0.0222 || Timer: 1.9473 sec.\n","===> Epoch[2](23/25): Loss: 0.0296 || Timer: 1.9320 sec.\n","===> Epoch[2](24/25): Loss: 0.0194 || Timer: 1.9284 sec.\n","===> Epoch[2](25/25): Loss: 0.0226 || Timer: 1.9297 sec.\n","===> Epoch 2 Complete: Avg. Loss: 0.0297\n","===> Epoch[3](1/25): Loss: 0.0231 || Timer: 1.9372 sec.\n","===> Epoch[3](2/25): Loss: 0.0188 || Timer: 1.9358 sec.\n","===> Epoch[3](3/25): Loss: 0.0169 || Timer: 1.9280 sec.\n","===> Epoch[3](4/25): Loss: 0.0220 || Timer: 1.9547 sec.\n","===> Epoch[3](5/25): Loss: 0.0212 || Timer: 1.9290 sec.\n","===> Epoch[3](6/25): Loss: 0.0251 || Timer: 1.9354 sec.\n","===> Epoch[3](7/25): Loss: 0.0169 || Timer: 1.9274 sec.\n","===> Epoch[3](8/25): Loss: 0.0195 || Timer: 1.9352 sec.\n","===> Epoch[3](9/25): Loss: 0.0171 || Timer: 1.9304 sec.\n","===> Epoch[3](10/25): Loss: 0.0199 || Timer: 1.9342 sec.\n","===> Epoch[3](11/25): Loss: 0.0195 || Timer: 1.9422 sec.\n","===> Epoch[3](12/25): Loss: 0.0203 || Timer: 1.9338 sec.\n","===> Epoch[3](13/25): Loss: 0.0157 || Timer: 1.9297 sec.\n","===> Epoch[3](14/25): Loss: 0.0127 || Timer: 1.9351 sec.\n","===> Epoch[3](15/25): Loss: 0.0163 || Timer: 1.9288 sec.\n","===> Epoch[3](16/25): Loss: 0.0144 || Timer: 1.9340 sec.\n","===> Epoch[3](17/25): Loss: 0.0143 || Timer: 1.9312 sec.\n","===> Epoch[3](18/25): Loss: 0.0235 || Timer: 1.9342 sec.\n","===> Epoch[3](19/25): Loss: 0.0122 || Timer: 1.9431 sec.\n","===> Epoch[3](20/25): Loss: 0.0164 || Timer: 1.9356 sec.\n","===> Epoch[3](21/25): Loss: 0.0166 || Timer: 1.9281 sec.\n","===> Epoch[3](22/25): Loss: 0.0109 || Timer: 1.9344 sec.\n","===> Epoch[3](23/25): Loss: 0.0106 || Timer: 1.9302 sec.\n","===> Epoch[3](24/25): Loss: 0.0123 || Timer: 1.9355 sec.\n","===> Epoch[3](25/25): Loss: 0.0164 || Timer: 1.9288 sec.\n","===> Epoch 3 Complete: Avg. Loss: 0.0173\n","===> Epoch[4](1/25): Loss: 0.0176 || Timer: 1.9487 sec.\n","===> Epoch[4](2/25): Loss: 0.0219 || Timer: 1.9380 sec.\n","===> Epoch[4](3/25): Loss: 0.0189 || Timer: 1.9316 sec.\n","===> Epoch[4](4/25): Loss: 0.0158 || Timer: 1.9329 sec.\n","===> Epoch[4](5/25): Loss: 0.0107 || Timer: 1.9299 sec.\n","===> Epoch[4](6/25): Loss: 0.0112 || Timer: 1.9322 sec.\n","===> Epoch[4](7/25): Loss: 0.0118 || Timer: 1.9308 sec.\n","===> Epoch[4](8/25): Loss: 0.0174 || Timer: 1.9474 sec.\n","===> Epoch[4](9/25): Loss: 0.0074 || Timer: 1.9312 sec.\n","===> Epoch[4](10/25): Loss: 0.0136 || Timer: 1.9333 sec.\n","===> Epoch[4](11/25): Loss: 0.0167 || Timer: 1.9302 sec.\n","===> Epoch[4](12/25): Loss: 0.0181 || Timer: 1.9306 sec.\n","===> Epoch[4](13/25): Loss: 0.0102 || Timer: 1.9288 sec.\n","===> Epoch[4](14/25): Loss: 0.0118 || Timer: 1.9330 sec.\n","===> Epoch[4](15/25): Loss: 0.0092 || Timer: 1.9287 sec.\n","===> Epoch[4](16/25): Loss: 0.0115 || Timer: 1.9471 sec.\n","===> Epoch[4](17/25): Loss: 0.0100 || Timer: 1.9291 sec.\n","===> Epoch[4](18/25): Loss: 0.0107 || Timer: 1.9354 sec.\n","===> Epoch[4](19/25): Loss: 0.0093 || Timer: 1.9284 sec.\n","===> Epoch[4](20/25): Loss: 0.0118 || Timer: 1.9332 sec.\n","===> Epoch[4](21/25): Loss: 0.0107 || Timer: 1.9287 sec.\n","===> Epoch[4](22/25): Loss: 0.0101 || Timer: 1.9325 sec.\n","===> Epoch[4](23/25): Loss: 0.0113 || Timer: 1.9449 sec.\n","===> Epoch[4](24/25): Loss: 0.0137 || Timer: 1.9319 sec.\n","===> Epoch[4](25/25): Loss: 0.0108 || Timer: 1.9293 sec.\n","===> Epoch 4 Complete: Avg. Loss: 0.0129\n","===> Epoch[5](1/25): Loss: 0.0112 || Timer: 1.9547 sec.\n","===> Epoch[5](2/25): Loss: 0.0094 || Timer: 1.9286 sec.\n","===> Epoch[5](3/25): Loss: 0.0083 || Timer: 1.9336 sec.\n","===> Epoch[5](4/25): Loss: 0.0100 || Timer: 1.9280 sec.\n","===> Epoch[5](5/25): Loss: 0.0133 || Timer: 1.9515 sec.\n","===> Epoch[5](6/25): Loss: 0.0080 || Timer: 1.9294 sec.\n","===> Epoch[5](7/25): Loss: 0.0107 || Timer: 1.9327 sec.\n","===> Epoch[5](8/25): Loss: 0.0111 || Timer: 1.9294 sec.\n","===> Epoch[5](9/25): Loss: 0.0062 || Timer: 1.9355 sec.\n","===> Epoch[5](10/25): Loss: 0.0085 || Timer: 1.9299 sec.\n","===> Epoch[5](11/25): Loss: 0.0071 || Timer: 1.9351 sec.\n","===> Epoch[5](12/25): Loss: 0.0089 || Timer: 1.9275 sec.\n","===> Epoch[5](13/25): Loss: 0.0097 || Timer: 1.9459 sec.\n","===> Epoch[5](14/25): Loss: 0.0077 || Timer: 1.9314 sec.\n","===> Epoch[5](15/25): Loss: 0.0075 || Timer: 1.9316 sec.\n","===> Epoch[5](16/25): Loss: 0.0080 || Timer: 1.9263 sec.\n","===> Epoch[5](17/25): Loss: 0.0089 || Timer: 1.9345 sec.\n","===> Epoch[5](18/25): Loss: 0.0094 || Timer: 1.9283 sec.\n","===> Epoch[5](19/25): Loss: 0.0074 || Timer: 1.9339 sec.\n","===> Epoch[5](20/25): Loss: 0.0089 || Timer: 1.9296 sec.\n","===> Epoch[5](21/25): Loss: 0.0062 || Timer: 1.9440 sec.\n","===> Epoch[5](22/25): Loss: 0.0073 || Timer: 1.9271 sec.\n","===> Epoch[5](23/25): Loss: 0.0093 || Timer: 1.9361 sec.\n","===> Epoch[5](24/25): Loss: 0.0069 || Timer: 1.9321 sec.\n","===> Epoch[5](25/25): Loss: 0.0093 || Timer: 1.9361 sec.\n","===> Epoch 5 Complete: Avg. Loss: 0.0088\n","===> Epoch[6](1/25): Loss: 0.0064 || Timer: 1.9451 sec.\n","===> Epoch[6](2/25): Loss: 0.0065 || Timer: 1.9299 sec.\n","===> Epoch[6](3/25): Loss: 0.0052 || Timer: 1.9416 sec.\n","===> Epoch[6](4/25): Loss: 0.0056 || Timer: 1.9319 sec.\n","===> Epoch[6](5/25): Loss: 0.0053 || Timer: 1.9313 sec.\n","===> Epoch[6](6/25): Loss: 0.0070 || Timer: 1.9302 sec.\n","===> Epoch[6](7/25): Loss: 0.0068 || Timer: 1.9340 sec.\n","===> Epoch[6](8/25): Loss: 0.0069 || Timer: 1.9296 sec.\n","===> Epoch[6](9/25): Loss: 0.0053 || Timer: 1.9305 sec.\n","===> Epoch[6](10/25): Loss: 0.0061 || Timer: 1.9412 sec.\n","===> Epoch[6](11/25): Loss: 0.0066 || Timer: 1.9312 sec.\n","===> Epoch[6](12/25): Loss: 0.0064 || Timer: 1.9283 sec.\n","===> Epoch[6](13/25): Loss: 0.0054 || Timer: 1.9315 sec.\n","===> Epoch[6](14/25): Loss: 0.0073 || Timer: 1.9295 sec.\n","===> Epoch[6](15/25): Loss: 0.0054 || Timer: 1.9318 sec.\n","===> Epoch[6](16/25): Loss: 0.0056 || Timer: 1.9294 sec.\n","===> Epoch[6](17/25): Loss: 0.0062 || Timer: 1.9476 sec.\n","===> Epoch[6](18/25): Loss: 0.0054 || Timer: 1.9283 sec.\n","===> Epoch[6](19/25): Loss: 0.0053 || Timer: 1.9306 sec.\n","===> Epoch[6](20/25): Loss: 0.0059 || Timer: 1.9297 sec.\n","===> Epoch[6](21/25): Loss: 0.0076 || Timer: 1.9366 sec.\n","===> Epoch[6](22/25): Loss: 0.0052 || Timer: 1.9305 sec.\n","===> Epoch[6](23/25): Loss: 0.0077 || Timer: 1.9334 sec.\n","===> Epoch[6](24/25): Loss: 0.0057 || Timer: 1.9317 sec.\n","===> Epoch[6](25/25): Loss: 0.0054 || Timer: 1.9479 sec.\n","===> Epoch 6 Complete: Avg. Loss: 0.0061\n","===> Epoch[7](1/25): Loss: 0.0078 || Timer: 1.9423 sec.\n","===> Epoch[7](2/25): Loss: 0.0054 || Timer: 1.9337 sec.\n","===> Epoch[7](3/25): Loss: 0.0068 || Timer: 1.9286 sec.\n","===> Epoch[7](4/25): Loss: 0.0056 || Timer: 1.9362 sec.\n","===> Epoch[7](5/25): Loss: 0.0062 || Timer: 1.9286 sec.\n","===> Epoch[7](6/25): Loss: 0.0065 || Timer: 1.9347 sec.\n","===> Epoch[7](7/25): Loss: 0.0046 || Timer: 1.9495 sec.\n","===> Epoch[7](8/25): Loss: 0.0058 || Timer: 1.9340 sec.\n","===> Epoch[7](9/25): Loss: 0.0056 || Timer: 1.9276 sec.\n","===> Epoch[7](10/25): Loss: 0.0063 || Timer: 1.9325 sec.\n","===> Epoch[7](11/25): Loss: 0.0048 || Timer: 1.9288 sec.\n","===> Epoch[7](12/25): Loss: 0.0051 || Timer: 1.9339 sec.\n","===> Epoch[7](13/25): Loss: 0.0081 || Timer: 1.9289 sec.\n","===> Epoch[7](14/25): Loss: 0.0055 || Timer: 1.9501 sec.\n","===> Epoch[7](15/25): Loss: 0.0053 || Timer: 1.9297 sec.\n","===> Epoch[7](16/25): Loss: 0.0056 || Timer: 1.9353 sec.\n","===> Epoch[7](17/25): Loss: 0.0079 || Timer: 1.9283 sec.\n","===> Epoch[7](18/25): Loss: 0.0069 || Timer: 1.9348 sec.\n","===> Epoch[7](19/25): Loss: 0.0049 || Timer: 1.9274 sec.\n","===> Epoch[7](20/25): Loss: 0.0054 || Timer: 1.9348 sec.\n","===> Epoch[7](21/25): Loss: 0.0058 || Timer: 1.9296 sec.\n","===> Epoch[7](22/25): Loss: 0.0044 || Timer: 1.9548 sec.\n","===> Epoch[7](23/25): Loss: 0.0032 || Timer: 1.9345 sec.\n","===> Epoch[7](24/25): Loss: 0.0029 || Timer: 1.9342 sec.\n","===> Epoch[7](25/25): Loss: 0.0048 || Timer: 1.9294 sec.\n","===> Epoch 7 Complete: Avg. Loss: 0.0056\n","===> Epoch[8](1/25): Loss: 0.0051 || Timer: 1.9461 sec.\n","===> Epoch[8](2/25): Loss: 0.0046 || Timer: 1.9331 sec.\n","===> Epoch[8](3/25): Loss: 0.0041 || Timer: 1.9287 sec.\n","===> Epoch[8](4/25): Loss: 0.0052 || Timer: 1.9456 sec.\n","===> Epoch[8](5/25): Loss: 0.0036 || Timer: 1.9305 sec.\n","===> Epoch[8](6/25): Loss: 0.0064 || Timer: 1.9303 sec.\n","===> Epoch[8](7/25): Loss: 0.0061 || Timer: 1.9280 sec.\n","===> Epoch[8](8/25): Loss: 0.0057 || Timer: 1.9327 sec.\n","===> Epoch[8](9/25): Loss: 0.0042 || Timer: 1.9292 sec.\n","===> Epoch[8](10/25): Loss: 0.0046 || Timer: 1.9332 sec.\n","===> Epoch[8](11/25): Loss: 0.0046 || Timer: 1.9490 sec.\n","===> Epoch[8](12/25): Loss: 0.0069 || Timer: 1.9328 sec.\n","===> Epoch[8](13/25): Loss: 0.0048 || Timer: 1.9294 sec.\n","===> Epoch[8](14/25): Loss: 0.0044 || Timer: 1.9320 sec.\n","===> Epoch[8](15/25): Loss: 0.0038 || Timer: 1.9299 sec.\n","===> Epoch[8](16/25): Loss: 0.0039 || Timer: 1.9322 sec.\n","===> Epoch[8](17/25): Loss: 0.0022 || Timer: 1.9296 sec.\n","===> Epoch[8](18/25): Loss: 0.0059 || Timer: 1.9338 sec.\n","===> Epoch[8](19/25): Loss: 0.0044 || Timer: 1.9483 sec.\n","===> Epoch[8](20/25): Loss: 0.0027 || Timer: 1.9306 sec.\n","===> Epoch[8](21/25): Loss: 0.0039 || Timer: 1.9289 sec.\n","===> Epoch[8](22/25): Loss: 0.0046 || Timer: 1.9360 sec.\n","===> Epoch[8](23/25): Loss: 0.0041 || Timer: 1.9286 sec.\n","===> Epoch[8](24/25): Loss: 0.0044 || Timer: 1.9333 sec.\n","===> Epoch[8](25/25): Loss: 0.0064 || Timer: 1.9306 sec.\n","===> Epoch 8 Complete: Avg. Loss: 0.0047\n","===> Epoch[9](1/25): Loss: 0.0045 || Timer: 1.9499 sec.\n","===> Epoch[9](2/25): Loss: 0.0046 || Timer: 1.9325 sec.\n","===> Epoch[9](3/25): Loss: 0.0063 || Timer: 1.9341 sec.\n","===> Epoch[9](4/25): Loss: 0.0049 || Timer: 1.9285 sec.\n","===> Epoch[9](5/25): Loss: 0.0028 || Timer: 1.9341 sec.\n","===> Epoch[9](6/25): Loss: 0.0049 || Timer: 1.9291 sec.\n","===> Epoch[9](7/25): Loss: 0.0040 || Timer: 1.9328 sec.\n","===> Epoch[9](8/25): Loss: 0.0050 || Timer: 1.9275 sec.\n","===> Epoch[9](9/25): Loss: 0.0034 || Timer: 1.9506 sec.\n","===> Epoch[9](10/25): Loss: 0.0046 || Timer: 1.9288 sec.\n","===> Epoch[9](11/25): Loss: 0.0033 || Timer: 1.9353 sec.\n","===> Epoch[9](12/25): Loss: 0.0031 || Timer: 1.9288 sec.\n","===> Epoch[9](13/25): Loss: 0.0041 || Timer: 1.9350 sec.\n","===> Epoch[9](14/25): Loss: 0.0041 || Timer: 1.9293 sec.\n","===> Epoch[9](15/25): Loss: 0.0047 || Timer: 1.9344 sec.\n","===> Epoch[9](16/25): Loss: 0.0056 || Timer: 1.9490 sec.\n","===> Epoch[9](17/25): Loss: 0.0049 || Timer: 1.9338 sec.\n","===> Epoch[9](18/25): Loss: 0.0047 || Timer: 1.9292 sec.\n","===> Epoch[9](19/25): Loss: 0.0045 || Timer: 1.9336 sec.\n","===> Epoch[9](20/25): Loss: 0.0039 || Timer: 1.9296 sec.\n","===> Epoch[9](21/25): Loss: 0.0036 || Timer: 1.9332 sec.\n","===> Epoch[9](22/25): Loss: 0.0032 || Timer: 1.9280 sec.\n","===> Epoch[9](23/25): Loss: 0.0044 || Timer: 1.9355 sec.\n","===> Epoch[9](24/25): Loss: 0.0038 || Timer: 1.9539 sec.\n","===> Epoch[9](25/25): Loss: 0.0050 || Timer: 1.9339 sec.\n","===> Epoch 9 Complete: Avg. Loss: 0.0043\n","===> Epoch[10](1/25): Loss: 0.0049 || Timer: 1.9534 sec.\n","===> Epoch[10](2/25): Loss: 0.0043 || Timer: 1.9355 sec.\n","===> Epoch[10](3/25): Loss: 0.0051 || Timer: 1.9327 sec.\n","===> Epoch[10](4/25): Loss: 0.0052 || Timer: 1.9286 sec.\n","===> Epoch[10](5/25): Loss: 0.0067 || Timer: 1.9318 sec.\n","===> Epoch[10](6/25): Loss: 0.0049 || Timer: 1.9417 sec.\n","===> Epoch[10](7/25): Loss: 0.0029 || Timer: 1.9318 sec.\n","===> Epoch[10](8/25): Loss: 0.0042 || Timer: 1.9298 sec.\n","===> Epoch[10](9/25): Loss: 0.0059 || Timer: 1.9373 sec.\n","===> Epoch[10](10/25): Loss: 0.0039 || Timer: 1.9315 sec.\n","===> Epoch[10](11/25): Loss: 0.0047 || Timer: 1.9341 sec.\n","===> Epoch[10](12/25): Loss: 0.0027 || Timer: 1.9309 sec.\n","===> Epoch[10](13/25): Loss: 0.0040 || Timer: 1.9318 sec.\n","===> Epoch[10](14/25): Loss: 0.0034 || Timer: 1.9526 sec.\n","===> Epoch[10](15/25): Loss: 0.0044 || Timer: 1.9332 sec.\n","===> Epoch[10](16/25): Loss: 0.0027 || Timer: 1.9296 sec.\n","===> Epoch[10](17/25): Loss: 0.0036 || Timer: 1.9304 sec.\n","===> Epoch[10](18/25): Loss: 0.0052 || Timer: 1.9299 sec.\n","===> Epoch[10](19/25): Loss: 0.0039 || Timer: 1.9319 sec.\n","===> Epoch[10](20/25): Loss: 0.0031 || Timer: 1.9293 sec.\n","===> Epoch[10](21/25): Loss: 0.0031 || Timer: 1.9490 sec.\n","===> Epoch[10](22/25): Loss: 0.0041 || Timer: 1.9283 sec.\n","===> Epoch[10](23/25): Loss: 0.0042 || Timer: 1.9319 sec.\n","===> Epoch[10](24/25): Loss: 0.0048 || Timer: 1.9292 sec.\n","===> Epoch[10](25/25): Loss: 0.0039 || Timer: 1.9311 sec.\n","===> Epoch 10 Complete: Avg. Loss: 0.0042\n","Checkpoint saved to /content/gdrive/My Drive/졸업논문/졸업논문/scale=2/weights_scale=2/WCNN_epoch_10.pth\n","===> Epoch[11](1/25): Loss: 0.0041 || Timer: 1.9363 sec.\n","===> Epoch[11](2/25): Loss: 0.0037 || Timer: 1.9339 sec.\n","===> Epoch[11](3/25): Loss: 0.0053 || Timer: 1.9519 sec.\n","===> Epoch[11](4/25): Loss: 0.0048 || Timer: 1.9353 sec.\n","===> Epoch[11](5/25): Loss: 0.0025 || Timer: 1.9296 sec.\n","===> Epoch[11](6/25): Loss: 0.0029 || Timer: 1.9337 sec.\n","===> Epoch[11](7/25): Loss: 0.0036 || Timer: 1.9291 sec.\n","===> Epoch[11](8/25): Loss: 0.0056 || Timer: 1.9336 sec.\n","===> Epoch[11](9/25): Loss: 0.0030 || Timer: 1.9285 sec.\n","===> Epoch[11](10/25): Loss: 0.0027 || Timer: 1.9348 sec.\n","===> Epoch[11](11/25): Loss: 0.0056 || Timer: 1.9381 sec.\n","===> Epoch[11](12/25): Loss: 0.0034 || Timer: 1.9352 sec.\n","===> Epoch[11](13/25): Loss: 0.0036 || Timer: 1.9300 sec.\n","===> Epoch[11](14/25): Loss: 0.0027 || Timer: 1.9346 sec.\n","===> Epoch[11](15/25): Loss: 0.0041 || Timer: 1.9309 sec.\n","===> Epoch[11](16/25): Loss: 0.0044 || Timer: 1.9352 sec.\n","===> Epoch[11](17/25): Loss: 0.0044 || Timer: 1.9286 sec.\n","===> Epoch[11](18/25): Loss: 0.0041 || Timer: 1.9448 sec.\n","===> Epoch[11](19/25): Loss: 0.0027 || Timer: 1.9304 sec.\n","===> Epoch[11](20/25): Loss: 0.0037 || Timer: 1.9349 sec.\n","===> Epoch[11](21/25): Loss: 0.0026 || Timer: 1.9320 sec.\n","===> Epoch[11](22/25): Loss: 0.0038 || Timer: 1.9364 sec.\n","===> Epoch[11](23/25): Loss: 0.0035 || Timer: 1.9274 sec.\n","===> Epoch[11](24/25): Loss: 0.0046 || Timer: 1.9341 sec.\n","===> Epoch[11](25/25): Loss: 0.0043 || Timer: 1.9515 sec.\n","===> Epoch 11 Complete: Avg. Loss: 0.0038\n","===> Epoch[12](1/25): Loss: 0.0039 || Timer: 1.9448 sec.\n","===> Epoch[12](2/25): Loss: 0.0033 || Timer: 1.9376 sec.\n","===> Epoch[12](3/25): Loss: 0.0022 || Timer: 1.9320 sec.\n","===> Epoch[12](4/25): Loss: 0.0028 || Timer: 1.9322 sec.\n","===> Epoch[12](5/25): Loss: 0.0019 || Timer: 1.9299 sec.\n","===> Epoch[12](6/25): Loss: 0.0033 || Timer: 1.9323 sec.\n","===> Epoch[12](7/25): Loss: 0.0038 || Timer: 1.9439 sec.\n","===> Epoch[12](8/25): Loss: 0.0033 || Timer: 1.9318 sec.\n","===> Epoch[12](9/25): Loss: 0.0049 || Timer: 1.9313 sec.\n","===> Epoch[12](10/25): Loss: 0.0029 || Timer: 1.9319 sec.\n","===> Epoch[12](11/25): Loss: 0.0030 || Timer: 1.9299 sec.\n","===> Epoch[12](12/25): Loss: 0.0040 || Timer: 1.9307 sec.\n","===> Epoch[12](13/25): Loss: 0.0022 || Timer: 1.9299 sec.\n","===> Epoch[12](14/25): Loss: 0.0032 || Timer: 1.9471 sec.\n","===> Epoch[12](15/25): Loss: 0.0024 || Timer: 1.9303 sec.\n","===> Epoch[12](16/25): Loss: 0.0031 || Timer: 1.9330 sec.\n","===> Epoch[12](17/25): Loss: 0.0038 || Timer: 1.9296 sec.\n","===> Epoch[12](18/25): Loss: 0.0035 || Timer: 1.9327 sec.\n","===> Epoch[12](19/25): Loss: 0.0037 || Timer: 1.9284 sec.\n","===> Epoch[12](20/25): Loss: 0.0037 || Timer: 1.9310 sec.\n","===> Epoch[12](21/25): Loss: 0.0035 || Timer: 1.9307 sec.\n","===> Epoch[12](22/25): Loss: 0.0036 || Timer: 1.9470 sec.\n","===> Epoch[12](23/25): Loss: 0.0040 || Timer: 1.9300 sec.\n","===> Epoch[12](24/25): Loss: 0.0041 || Timer: 1.9370 sec.\n","===> Epoch[12](25/25): Loss: 0.0024 || Timer: 1.9304 sec.\n","===> Epoch 12 Complete: Avg. Loss: 0.0033\n","===> Epoch[13](1/25): Loss: 0.0032 || Timer: 1.9461 sec.\n","===> Epoch[13](2/25): Loss: 0.0030 || Timer: 1.9294 sec.\n","===> Epoch[13](3/25): Loss: 0.0031 || Timer: 1.9334 sec.\n","===> Epoch[13](4/25): Loss: 0.0029 || Timer: 1.9465 sec.\n","===> Epoch[13](5/25): Loss: 0.0033 || Timer: 1.9343 sec.\n","===> Epoch[13](6/25): Loss: 0.0042 || Timer: 1.9290 sec.\n","===> Epoch[13](7/25): Loss: 0.0028 || Timer: 1.9340 sec.\n","===> Epoch[13](8/25): Loss: 0.0062 || Timer: 1.9315 sec.\n","===> Epoch[13](9/25): Loss: 0.0023 || Timer: 1.9363 sec.\n","===> Epoch[13](10/25): Loss: 0.0037 || Timer: 1.9282 sec.\n","===> Epoch[13](11/25): Loss: 0.0032 || Timer: 1.9520 sec.\n","===> Epoch[13](12/25): Loss: 0.0033 || Timer: 1.9275 sec.\n","===> Epoch[13](13/25): Loss: 0.0033 || Timer: 1.9346 sec.\n","===> Epoch[13](14/25): Loss: 0.0033 || Timer: 1.9294 sec.\n","===> Epoch[13](15/25): Loss: 0.0034 || Timer: 1.9330 sec.\n","===> Epoch[13](16/25): Loss: 0.0043 || Timer: 1.9291 sec.\n","===> Epoch[13](17/25): Loss: 0.0035 || Timer: 1.9350 sec.\n","===> Epoch[13](18/25): Loss: 0.0030 || Timer: 1.9444 sec.\n","===> Epoch[13](19/25): Loss: 0.0033 || Timer: 1.9343 sec.\n","===> Epoch[13](20/25): Loss: 0.0029 || Timer: 1.9275 sec.\n","===> Epoch[13](21/25): Loss: 0.0039 || Timer: 1.9345 sec.\n","===> Epoch[13](22/25): Loss: 0.0042 || Timer: 1.9297 sec.\n","===> Epoch[13](23/25): Loss: 0.0034 || Timer: 1.9470 sec.\n","===> Epoch[13](24/25): Loss: 0.0041 || Timer: 1.9296 sec.\n","===> Epoch[13](25/25): Loss: 0.0048 || Timer: 1.9350 sec.\n","===> Epoch 13 Complete: Avg. Loss: 0.0035\n","===> Epoch[14](1/25): Loss: 0.0135 || Timer: 1.9634 sec.\n","===> Epoch[14](2/25): Loss: 0.0359 || Timer: 1.9303 sec.\n","===> Epoch[14](3/25): Loss: 0.0116 || Timer: 1.9320 sec.\n","===> Epoch[14](4/25): Loss: 0.0160 || Timer: 1.9278 sec.\n","===> Epoch[14](5/25): Loss: 0.0100 || Timer: 1.9342 sec.\n","===> Epoch[14](6/25): Loss: 0.0267 || Timer: 1.9326 sec.\n","===> Epoch[14](7/25): Loss: 0.0165 || Timer: 1.9321 sec.\n","===> Epoch[14](8/25): Loss: 0.0078 || Timer: 1.9410 sec.\n","===> Epoch[14](9/25): Loss: 0.0169 || Timer: 1.9332 sec.\n","===> Epoch[14](10/25): Loss: 0.0160 || Timer: 1.9306 sec.\n","===> Epoch[14](11/25): Loss: 0.0085 || Timer: 1.9327 sec.\n","===> Epoch[14](12/25): Loss: 0.0108 || Timer: 1.9299 sec.\n","===> Epoch[14](13/25): Loss: 0.0133 || Timer: 1.9316 sec.\n","===> Epoch[14](14/25): Loss: 0.0153 || Timer: 1.9299 sec.\n","===> Epoch[14](15/25): Loss: 0.0088 || Timer: 1.9340 sec.\n","===> Epoch[14](16/25): Loss: 0.0142 || Timer: 1.9402 sec.\n","===> Epoch[14](17/25): Loss: 0.0137 || Timer: 1.9302 sec.\n","===> Epoch[14](18/25): Loss: 0.0126 || Timer: 1.9286 sec.\n","===> Epoch[14](19/25): Loss: 0.0131 || Timer: 1.9316 sec.\n","===> Epoch[14](20/25): Loss: 0.0126 || Timer: 1.9308 sec.\n","===> Epoch[14](21/25): Loss: 0.0151 || Timer: 1.9323 sec.\n","===> Epoch[14](22/25): Loss: 0.0109 || Timer: 1.9275 sec.\n","===> Epoch[14](23/25): Loss: 0.0058 || Timer: 1.9500 sec.\n","===> Epoch[14](24/25): Loss: 0.0100 || Timer: 1.9298 sec.\n","===> Epoch[14](25/25): Loss: 0.0070 || Timer: 1.9313 sec.\n","===> Epoch 14 Complete: Avg. Loss: 0.0137\n","===> Epoch[15](1/25): Loss: 0.0095 || Timer: 1.9367 sec.\n","===> Epoch[15](2/25): Loss: 0.0049 || Timer: 1.9344 sec.\n","===> Epoch[15](3/25): Loss: 0.0101 || Timer: 1.9294 sec.\n","===> Epoch[15](4/25): Loss: 0.0091 || Timer: 1.9350 sec.\n","===> Epoch[15](5/25): Loss: 0.0063 || Timer: 1.9396 sec.\n","===> Epoch[15](6/25): Loss: 0.0051 || Timer: 1.9364 sec.\n","===> Epoch[15](7/25): Loss: 0.0061 || Timer: 1.9279 sec.\n","===> Epoch[15](8/25): Loss: 0.0068 || Timer: 1.9348 sec.\n","===> Epoch[15](9/25): Loss: 0.0027 || Timer: 1.9286 sec.\n","===> Epoch[15](10/25): Loss: 0.0049 || Timer: 1.9341 sec.\n","===> Epoch[15](11/25): Loss: 0.0061 || Timer: 1.9277 sec.\n","===> Epoch[15](12/25): Loss: 0.0043 || Timer: 1.9566 sec.\n","===> Epoch[15](13/25): Loss: 0.0041 || Timer: 1.9284 sec.\n","===> Epoch[15](14/25): Loss: 0.0054 || Timer: 1.9332 sec.\n","===> Epoch[15](15/25): Loss: 0.0032 || Timer: 1.9299 sec.\n","===> Epoch[15](16/25): Loss: 0.0032 || Timer: 1.9349 sec.\n","===> Epoch[15](17/25): Loss: 0.0033 || Timer: 1.9299 sec.\n","===> Epoch[15](18/25): Loss: 0.0043 || Timer: 1.9338 sec.\n","===> Epoch[15](19/25): Loss: 0.0039 || Timer: 1.9303 sec.\n","===> Epoch[15](20/25): Loss: 0.0038 || Timer: 1.9502 sec.\n","===> Epoch[15](21/25): Loss: 0.0040 || Timer: 1.9294 sec.\n","===> Epoch[15](22/25): Loss: 0.0037 || Timer: 1.9347 sec.\n","===> Epoch[15](23/25): Loss: 0.0035 || Timer: 1.9285 sec.\n","===> Epoch[15](24/25): Loss: 0.0044 || Timer: 1.9344 sec.\n","===> Epoch[15](25/25): Loss: 0.0045 || Timer: 1.9290 sec.\n","===> Epoch 15 Complete: Avg. Loss: 0.0051\n","===> Epoch[16](1/25): Loss: 0.0033 || Timer: 1.9406 sec.\n","===> Epoch[16](2/25): Loss: 0.0037 || Timer: 1.9458 sec.\n","===> Epoch[16](3/25): Loss: 0.0034 || Timer: 1.9302 sec.\n","===> Epoch[16](4/25): Loss: 0.0035 || Timer: 1.9327 sec.\n","===> Epoch[16](5/25): Loss: 0.0028 || Timer: 1.9317 sec.\n","===> Epoch[16](6/25): Loss: 0.0031 || Timer: 1.9333 sec.\n","===> Epoch[16](7/25): Loss: 0.0059 || Timer: 1.9299 sec.\n","===> Epoch[16](8/25): Loss: 0.0027 || Timer: 1.9335 sec.\n","===> Epoch[16](9/25): Loss: 0.0026 || Timer: 1.9282 sec.\n","===> Epoch[16](10/25): Loss: 0.0015 || Timer: 1.9527 sec.\n","===> Epoch[16](11/25): Loss: 0.0034 || Timer: 1.9295 sec.\n","===> Epoch[16](12/25): Loss: 0.0026 || Timer: 1.9313 sec.\n","===> Epoch[16](13/25): Loss: 0.0030 || Timer: 1.9313 sec.\n","===> Epoch[16](14/25): Loss: 0.0031 || Timer: 1.9315 sec.\n","===> Epoch[16](15/25): Loss: 0.0025 || Timer: 1.9331 sec.\n","===> Epoch[16](16/25): Loss: 0.0022 || Timer: 1.9324 sec.\n","===> Epoch[16](17/25): Loss: 0.0018 || Timer: 1.9515 sec.\n","===> Epoch[16](18/25): Loss: 0.0025 || Timer: 1.9323 sec.\n","===> Epoch[16](19/25): Loss: 0.0042 || Timer: 1.9297 sec.\n","===> Epoch[16](20/25): Loss: 0.0024 || Timer: 1.9320 sec.\n","===> Epoch[16](21/25): Loss: 0.0035 || Timer: 1.9298 sec.\n","===> Epoch[16](22/25): Loss: 0.0033 || Timer: 1.9318 sec.\n","===> Epoch[16](23/25): Loss: 0.0037 || Timer: 1.9308 sec.\n","===> Epoch[16](24/25): Loss: 0.0027 || Timer: 1.9304 sec.\n","===> Epoch[16](25/25): Loss: 0.0049 || Timer: 1.9471 sec.\n","===> Epoch 16 Complete: Avg. Loss: 0.0031\n","===> Epoch[17](1/25): Loss: 0.0026 || Timer: 1.9459 sec.\n","===> Epoch[17](2/25): Loss: 0.0039 || Timer: 1.9284 sec.\n","===> Epoch[17](3/25): Loss: 0.0042 || Timer: 1.9348 sec.\n","===> Epoch[17](4/25): Loss: 0.0029 || Timer: 1.9289 sec.\n","===> Epoch[17](5/25): Loss: 0.0026 || Timer: 1.9320 sec.\n","===> Epoch[17](6/25): Loss: 0.0030 || Timer: 1.9317 sec.\n","===> Epoch[17](7/25): Loss: 0.0027 || Timer: 1.9514 sec.\n","===> Epoch[17](8/25): Loss: 0.0028 || Timer: 1.9295 sec.\n","===> Epoch[17](9/25): Loss: 0.0025 || Timer: 1.9347 sec.\n","===> Epoch[17](10/25): Loss: 0.0029 || Timer: 1.9283 sec.\n","===> Epoch[17](11/25): Loss: 0.0025 || Timer: 1.9349 sec.\n","===> Epoch[17](12/25): Loss: 0.0026 || Timer: 1.9292 sec.\n","===> Epoch[17](13/25): Loss: 0.0047 || Timer: 1.9333 sec.\n","===> Epoch[17](14/25): Loss: 0.0028 || Timer: 1.9287 sec.\n","===> Epoch[17](15/25): Loss: 0.0036 || Timer: 1.9503 sec.\n","===> Epoch[17](16/25): Loss: 0.0027 || Timer: 1.9295 sec.\n","===> Epoch[17](17/25): Loss: 0.0033 || Timer: 1.9350 sec.\n","===> Epoch[17](18/25): Loss: 0.0038 || Timer: 1.9275 sec.\n","===> Epoch[17](19/25): Loss: 0.0037 || Timer: 1.9368 sec.\n","===> Epoch[17](20/25): Loss: 0.0027 || Timer: 1.9285 sec.\n","===> Epoch[17](21/25): Loss: 0.0025 || Timer: 1.9339 sec.\n","===> Epoch[17](22/25): Loss: 0.0026 || Timer: 1.9302 sec.\n","===> Epoch[17](23/25): Loss: 0.0040 || Timer: 1.9520 sec.\n","===> Epoch[17](24/25): Loss: 0.0023 || Timer: 1.9299 sec.\n","===> Epoch[17](25/25): Loss: 0.0026 || Timer: 1.9361 sec.\n","===> Epoch 17 Complete: Avg. Loss: 0.0031\n","===> Epoch[18](1/25): Loss: 0.0021 || Timer: 1.9436 sec.\n","===> Epoch[18](2/25): Loss: 0.0034 || Timer: 1.9298 sec.\n","===> Epoch[18](3/25): Loss: 0.0028 || Timer: 1.9325 sec.\n","===> Epoch[18](4/25): Loss: 0.0040 || Timer: 1.9311 sec.\n","===> Epoch[18](5/25): Loss: 0.0030 || Timer: 1.9500 sec.\n","===> Epoch[18](6/25): Loss: 0.0023 || Timer: 1.9277 sec.\n","===> Epoch[18](7/25): Loss: 0.0025 || Timer: 1.9330 sec.\n","===> Epoch[18](8/25): Loss: 0.0025 || Timer: 1.9295 sec.\n","===> Epoch[18](9/25): Loss: 0.0023 || Timer: 1.9376 sec.\n","===> Epoch[18](10/25): Loss: 0.0032 || Timer: 1.9306 sec.\n","===> Epoch[18](11/25): Loss: 0.0028 || Timer: 1.9307 sec.\n","===> Epoch[18](12/25): Loss: 0.0037 || Timer: 1.9528 sec.\n","===> Epoch[18](13/25): Loss: 0.0038 || Timer: 1.9306 sec.\n","===> Epoch[18](14/25): Loss: 0.0045 || Timer: 1.9298 sec.\n","===> Epoch[18](15/25): Loss: 0.0026 || Timer: 1.9337 sec.\n","===> Epoch[18](16/25): Loss: 0.0032 || Timer: 1.9290 sec.\n","===> Epoch[18](17/25): Loss: 0.0030 || Timer: 1.9318 sec.\n","===> Epoch[18](18/25): Loss: 0.0026 || Timer: 1.9285 sec.\n","===> Epoch[18](19/25): Loss: 0.0019 || Timer: 1.9465 sec.\n","===> Epoch[18](20/25): Loss: 0.0025 || Timer: 1.9302 sec.\n","===> Epoch[18](21/25): Loss: 0.0019 || Timer: 1.9331 sec.\n","===> Epoch[18](22/25): Loss: 0.0019 || Timer: 1.9304 sec.\n","===> Epoch[18](23/25): Loss: 0.0023 || Timer: 1.9310 sec.\n","===> Epoch[18](24/25): Loss: 0.0022 || Timer: 1.9302 sec.\n","===> Epoch[18](25/25): Loss: 0.0019 || Timer: 1.9322 sec.\n","===> Epoch 18 Complete: Avg. Loss: 0.0027\n","===> Epoch[19](1/25): Loss: 0.0025 || Timer: 1.9511 sec.\n","===> Epoch[19](2/25): Loss: 0.0033 || Timer: 1.9331 sec.\n","===> Epoch[19](3/25): Loss: 0.0023 || Timer: 1.9284 sec.\n","===> Epoch[19](4/25): Loss: 0.0033 || Timer: 1.9358 sec.\n","===> Epoch[19](5/25): Loss: 0.0023 || Timer: 1.9294 sec.\n","===> Epoch[19](6/25): Loss: 0.0024 || Timer: 1.9350 sec.\n","===> Epoch[19](7/25): Loss: 0.0023 || Timer: 1.9287 sec.\n","===> Epoch[19](8/25): Loss: 0.0031 || Timer: 1.9540 sec.\n","===> Epoch[19](9/25): Loss: 0.0027 || Timer: 1.9289 sec.\n","===> Epoch[19](10/25): Loss: 0.0020 || Timer: 1.9338 sec.\n","===> Epoch[19](11/25): Loss: 0.0026 || Timer: 1.9290 sec.\n","===> Epoch[19](12/25): Loss: 0.0022 || Timer: 1.9349 sec.\n","===> Epoch[19](13/25): Loss: 0.0021 || Timer: 1.9289 sec.\n","===> Epoch[19](14/25): Loss: 0.0031 || Timer: 1.9358 sec.\n","===> Epoch[19](15/25): Loss: 0.0031 || Timer: 1.9295 sec.\n","===> Epoch[19](16/25): Loss: 0.0032 || Timer: 1.9510 sec.\n","===> Epoch[19](17/25): Loss: 0.0017 || Timer: 1.9292 sec.\n","===> Epoch[19](18/25): Loss: 0.0030 || Timer: 1.9391 sec.\n","===> Epoch[19](19/25): Loss: 0.0038 || Timer: 1.9289 sec.\n","===> Epoch[19](20/25): Loss: 0.0023 || Timer: 1.9345 sec.\n","===> Epoch[19](21/25): Loss: 0.0019 || Timer: 1.9287 sec.\n","===> Epoch[19](22/25): Loss: 0.0034 || Timer: 1.9367 sec.\n","===> Epoch[19](23/25): Loss: 0.0030 || Timer: 1.9409 sec.\n","===> Epoch[19](24/25): Loss: 0.0020 || Timer: 1.9349 sec.\n","===> Epoch[19](25/25): Loss: 0.0036 || Timer: 1.9294 sec.\n","===> Epoch 19 Complete: Avg. Loss: 0.0027\n","===> Epoch[20](1/25): Loss: 0.0033 || Timer: 1.9557 sec.\n","===> Epoch[20](2/25): Loss: 0.0017 || Timer: 1.9348 sec.\n","===> Epoch[20](3/25): Loss: 0.0031 || Timer: 1.9292 sec.\n","===> Epoch[20](4/25): Loss: 0.0029 || Timer: 1.9315 sec.\n","===> Epoch[20](5/25): Loss: 0.0020 || Timer: 1.9504 sec.\n","===> Epoch[20](6/25): Loss: 0.0025 || Timer: 1.9321 sec.\n","===> Epoch[20](7/25): Loss: 0.0017 || Timer: 1.9309 sec.\n","===> Epoch[20](8/25): Loss: 0.0034 || Timer: 1.9333 sec.\n","===> Epoch[20](9/25): Loss: 0.0025 || Timer: 1.9352 sec.\n","===> Epoch[20](10/25): Loss: 0.0023 || Timer: 1.9352 sec.\n","===> Epoch[20](11/25): Loss: 0.0030 || Timer: 1.9293 sec.\n","===> Epoch[20](12/25): Loss: 0.0023 || Timer: 1.9330 sec.\n","===> Epoch[20](13/25): Loss: 0.0022 || Timer: 1.9477 sec.\n","===> Epoch[20](14/25): Loss: 0.0027 || Timer: 1.9323 sec.\n","===> Epoch[20](15/25): Loss: 0.0022 || Timer: 1.9297 sec.\n","===> Epoch[20](16/25): Loss: 0.0024 || Timer: 1.9360 sec.\n","===> Epoch[20](17/25): Loss: 0.0031 || Timer: 1.9304 sec.\n","===> Epoch[20](18/25): Loss: 0.0020 || Timer: 1.9340 sec.\n","===> Epoch[20](19/25): Loss: 0.0027 || Timer: 1.9300 sec.\n","===> Epoch[20](20/25): Loss: 0.0017 || Timer: 1.9332 sec.\n","===> Epoch[20](21/25): Loss: 0.0022 || Timer: 1.9429 sec.\n","===> Epoch[20](22/25): Loss: 0.0031 || Timer: 1.9346 sec.\n","===> Epoch[20](23/25): Loss: 0.0027 || Timer: 1.9307 sec.\n","===> Epoch[20](24/25): Loss: 0.0022 || Timer: 1.9325 sec.\n","===> Epoch[20](25/25): Loss: 0.0027 || Timer: 1.9307 sec.\n","===> Epoch 20 Complete: Avg. Loss: 0.0025\n","Checkpoint saved to /content/gdrive/My Drive/졸업논문/졸업논문/scale=2/weights_scale=2/WCNN_epoch_20.pth\n","===> Epoch[21](1/25): Loss: 0.0032 || Timer: 1.9464 sec.\n","===> Epoch[21](2/25): Loss: 0.0026 || Timer: 1.9317 sec.\n","===> Epoch[21](3/25): Loss: 0.0022 || Timer: 1.9580 sec.\n","===> Epoch[21](4/25): Loss: 0.0028 || Timer: 1.9301 sec.\n","===> Epoch[21](5/25): Loss: 0.0026 || Timer: 1.9359 sec.\n","===> Epoch[21](6/25): Loss: 0.0034 || Timer: 1.9303 sec.\n","===> Epoch[21](7/25): Loss: 0.0017 || Timer: 1.9336 sec.\n","===> Epoch[21](8/25): Loss: 0.0024 || Timer: 1.9286 sec.\n","===> Epoch[21](9/25): Loss: 0.0024 || Timer: 1.9365 sec.\n","===> Epoch[21](10/25): Loss: 0.0027 || Timer: 1.9291 sec.\n","===> Epoch[21](11/25): Loss: 0.0021 || Timer: 1.9484 sec.\n","===> Epoch[21](12/25): Loss: 0.0023 || Timer: 1.9274 sec.\n","===> Epoch[21](13/25): Loss: 0.0017 || Timer: 1.9336 sec.\n","===> Epoch[21](14/25): Loss: 0.0016 || Timer: 1.9296 sec.\n","===> Epoch[21](15/25): Loss: 0.0031 || Timer: 1.9350 sec.\n","===> Epoch[21](16/25): Loss: 0.0023 || Timer: 1.9294 sec.\n","===> Epoch[21](17/25): Loss: 0.0029 || Timer: 1.9357 sec.\n","===> Epoch[21](18/25): Loss: 0.0027 || Timer: 1.9419 sec.\n","===> Epoch[21](19/25): Loss: 0.0032 || Timer: 1.9354 sec.\n","===> Epoch[21](20/25): Loss: 0.0023 || Timer: 1.9297 sec.\n","===> Epoch[21](21/25): Loss: 0.0024 || Timer: 1.9377 sec.\n","===> Epoch[21](22/25): Loss: 0.0039 || Timer: 1.9298 sec.\n","===> Epoch[21](23/25): Loss: 0.0026 || Timer: 1.9342 sec.\n","===> Epoch[21](24/25): Loss: 0.0027 || Timer: 1.9280 sec.\n","===> Epoch[21](25/25): Loss: 0.0035 || Timer: 1.9350 sec.\n","===> Epoch 21 Complete: Avg. Loss: 0.0026\n","===> Epoch[22](1/25): Loss: 0.0024 || Timer: 1.9517 sec.\n","===> Epoch[22](2/25): Loss: 0.0027 || Timer: 1.9297 sec.\n","===> Epoch[22](3/25): Loss: 0.0022 || Timer: 1.9320 sec.\n","===> Epoch[22](4/25): Loss: 0.0029 || Timer: 1.9303 sec.\n","===> Epoch[22](5/25): Loss: 0.0020 || Timer: 1.9335 sec.\n","===> Epoch[22](6/25): Loss: 0.0019 || Timer: 1.9289 sec.\n","===> Epoch[22](7/25): Loss: 0.0033 || Timer: 1.9323 sec.\n","===> Epoch[22](8/25): Loss: 0.0029 || Timer: 1.9472 sec.\n","===> Epoch[22](9/25): Loss: 0.0022 || Timer: 1.9334 sec.\n","===> Epoch[22](10/25): Loss: 0.0027 || Timer: 1.9310 sec.\n","===> Epoch[22](11/25): Loss: 0.0024 || Timer: 1.9324 sec.\n","===> Epoch[22](12/25): Loss: 0.0027 || Timer: 1.9304 sec.\n","===> Epoch[22](13/25): Loss: 0.0024 || Timer: 1.9326 sec.\n","===> Epoch[22](14/25): Loss: 0.0024 || Timer: 1.9344 sec.\n","===> Epoch[22](15/25): Loss: 0.0025 || Timer: 1.9318 sec.\n","===> Epoch[22](16/25): Loss: 0.0029 || Timer: 1.9526 sec.\n","===> Epoch[22](17/25): Loss: 0.0042 || Timer: 1.9317 sec.\n","===> Epoch[22](18/25): Loss: 0.0097 || Timer: 1.9318 sec.\n","===> Epoch[22](19/25): Loss: 0.0107 || Timer: 1.9332 sec.\n","===> Epoch[22](20/25): Loss: 0.0026 || Timer: 1.9289 sec.\n","===> Epoch[22](21/25): Loss: 0.0115 || Timer: 1.9337 sec.\n","===> Epoch[22](22/25): Loss: 0.0088 || Timer: 1.9299 sec.\n","===> Epoch[22](23/25): Loss: 0.0021 || Timer: 1.9317 sec.\n","===> Epoch[22](24/25): Loss: 0.0071 || Timer: 1.9464 sec.\n","===> Epoch[22](25/25): Loss: 0.0038 || Timer: 1.9329 sec.\n","===> Epoch 22 Complete: Avg. Loss: 0.0041\n","===> Epoch[23](1/25): Loss: 0.0050 || Timer: 1.9402 sec.\n","===> Epoch[23](2/25): Loss: 0.0033 || Timer: 1.9366 sec.\n","===> Epoch[23](3/25): Loss: 0.0045 || Timer: 1.9290 sec.\n","===> Epoch[23](4/25): Loss: 0.0034 || Timer: 1.9351 sec.\n","===> Epoch[23](5/25): Loss: 0.0043 || Timer: 1.9290 sec.\n","===> Epoch[23](6/25): Loss: 0.0056 || Timer: 1.9477 sec.\n","===> Epoch[23](7/25): Loss: 0.0046 || Timer: 1.9284 sec.\n","===> Epoch[23](8/25): Loss: 0.0044 || Timer: 1.9350 sec.\n","===> Epoch[23](9/25): Loss: 0.0031 || Timer: 1.9284 sec.\n","===> Epoch[23](10/25): Loss: 0.0033 || Timer: 1.9351 sec.\n","===> Epoch[23](11/25): Loss: 0.0029 || Timer: 1.9284 sec.\n","===> Epoch[23](12/25): Loss: 0.0032 || Timer: 1.9356 sec.\n","===> Epoch[23](13/25): Loss: 0.0049 || Timer: 1.9294 sec.\n","===> Epoch[23](14/25): Loss: 0.0024 || Timer: 1.9581 sec.\n","===> Epoch[23](15/25): Loss: 0.0027 || Timer: 1.9284 sec.\n","===> Epoch[23](16/25): Loss: 0.0024 || Timer: 1.9341 sec.\n","===> Epoch[23](17/25): Loss: 0.0040 || Timer: 1.9280 sec.\n","===> Epoch[23](18/25): Loss: 0.0021 || Timer: 1.9352 sec.\n","===> Epoch[23](19/25): Loss: 0.0023 || Timer: 1.9298 sec.\n","===> Epoch[23](20/25): Loss: 0.0045 || Timer: 1.9364 sec.\n","===> Epoch[23](21/25): Loss: 0.0034 || Timer: 1.9295 sec.\n","===> Epoch[23](22/25): Loss: 0.0027 || Timer: 1.9507 sec.\n","===> Epoch[23](23/25): Loss: 0.0043 || Timer: 1.9301 sec.\n","===> Epoch[23](24/25): Loss: 0.0021 || Timer: 1.9359 sec.\n","===> Epoch[23](25/25): Loss: 0.0015 || Timer: 1.9288 sec.\n","===> Epoch 23 Complete: Avg. Loss: 0.0035\n","===> Epoch[24](1/25): Loss: 0.0018 || Timer: 1.9404 sec.\n","===> Epoch[24](2/25): Loss: 0.0028 || Timer: 1.9317 sec.\n","===> Epoch[24](3/25): Loss: 0.0018 || Timer: 1.9296 sec.\n","===> Epoch[24](4/25): Loss: 0.0029 || Timer: 1.9557 sec.\n","===> Epoch[24](5/25): Loss: 0.0032 || Timer: 1.9315 sec.\n","===> Epoch[24](6/25): Loss: 0.0029 || Timer: 1.9341 sec.\n","===> Epoch[24](7/25): Loss: 0.0028 || Timer: 1.9297 sec.\n","===> Epoch[24](8/25): Loss: 0.0024 || Timer: 1.9333 sec.\n","===> Epoch[24](9/25): Loss: 0.0031 || Timer: 1.9287 sec.\n","===> Epoch[24](10/25): Loss: 0.0018 || Timer: 1.9315 sec.\n","===> Epoch[24](11/25): Loss: 0.0019 || Timer: 1.9322 sec.\n","===> Epoch[24](12/25): Loss: 0.0025 || Timer: 1.9560 sec.\n","===> Epoch[24](13/25): Loss: 0.0023 || Timer: 1.9349 sec.\n","===> Epoch[24](14/25): Loss: 0.0030 || Timer: 1.9327 sec.\n","===> Epoch[24](15/25): Loss: 0.0022 || Timer: 1.9319 sec.\n","===> Epoch[24](16/25): Loss: 0.0024 || Timer: 1.9328 sec.\n","===> Epoch[24](17/25): Loss: 0.0019 || Timer: 1.9318 sec.\n","===> Epoch[24](18/25): Loss: 0.0025 || Timer: 1.9350 sec.\n","===> Epoch[24](19/25): Loss: 0.0018 || Timer: 1.9310 sec.\n","===> Epoch[24](20/25): Loss: 0.0027 || Timer: 1.9468 sec.\n","===> Epoch[24](21/25): Loss: 0.0021 || Timer: 1.9301 sec.\n","===> Epoch[24](22/25): Loss: 0.0020 || Timer: 1.9337 sec.\n","===> Epoch[24](23/25): Loss: 0.0045 || Timer: 1.9321 sec.\n","===> Epoch[24](24/25): Loss: 0.0026 || Timer: 1.9344 sec.\n","===> Epoch[24](25/25): Loss: 0.0025 || Timer: 1.9307 sec.\n","===> Epoch 24 Complete: Avg. Loss: 0.0025\n","===> Epoch[25](1/25): Loss: 0.0032 || Timer: 1.9451 sec.\n","===> Epoch[25](2/25): Loss: 0.0026 || Timer: 1.9527 sec.\n","===> Epoch[25](3/25): Loss: 0.0027 || Timer: 1.9354 sec.\n","===> Epoch[25](4/25): Loss: 0.0031 || Timer: 1.9285 sec.\n","===> Epoch[25](5/25): Loss: 0.0016 || Timer: 1.9353 sec.\n","===> Epoch[25](6/25): Loss: 0.0022 || Timer: 1.9292 sec.\n","===> Epoch[25](7/25): Loss: 0.0015 || Timer: 1.9345 sec.\n","===> Epoch[25](8/25): Loss: 0.0029 || Timer: 1.9295 sec.\n","===> Epoch[25](9/25): Loss: 0.0028 || Timer: 1.9343 sec.\n","===> Epoch[25](10/25): Loss: 0.0030 || Timer: 1.9536 sec.\n","===> Epoch[25](11/25): Loss: 0.0034 || Timer: 1.9350 sec.\n","===> Epoch[25](12/25): Loss: 0.0018 || Timer: 1.9295 sec.\n","===> Epoch[25](13/25): Loss: 0.0035 || Timer: 1.9342 sec.\n","===> Epoch[25](14/25): Loss: 0.0026 || Timer: 1.9279 sec.\n","===> Epoch[25](15/25): Loss: 0.0024 || Timer: 1.9343 sec.\n","===> Epoch[25](16/25): Loss: 0.0026 || Timer: 1.9294 sec.\n","===> Epoch[25](17/25): Loss: 0.0023 || Timer: 1.9337 sec.\n","===> Epoch[25](18/25): Loss: 0.0022 || Timer: 1.9431 sec.\n","===> Epoch[25](19/25): Loss: 0.0027 || Timer: 1.9324 sec.\n","===> Epoch[25](20/25): Loss: 0.0021 || Timer: 1.9293 sec.\n","===> Epoch[25](21/25): Loss: 0.0016 || Timer: 1.9334 sec.\n","===> Epoch[25](22/25): Loss: 0.0019 || Timer: 1.9280 sec.\n","===> Epoch[25](23/25): Loss: 0.0031 || Timer: 1.9323 sec.\n","===> Epoch[25](24/25): Loss: 0.0023 || Timer: 1.9280 sec.\n","===> Epoch[25](25/25): Loss: 0.0014 || Timer: 1.9617 sec.\n","===> Epoch 25 Complete: Avg. Loss: 0.0025\n","===> Epoch[26](1/25): Loss: 0.0012 || Timer: 1.9419 sec.\n","===> Epoch[26](2/25): Loss: 0.0026 || Timer: 1.9291 sec.\n","===> Epoch[26](3/25): Loss: 0.0029 || Timer: 1.9344 sec.\n","===> Epoch[26](4/25): Loss: 0.0025 || Timer: 1.9287 sec.\n","===> Epoch[26](5/25): Loss: 0.0017 || Timer: 1.9344 sec.\n","===> Epoch[26](6/25): Loss: 0.0024 || Timer: 1.9289 sec.\n","===> Epoch[26](7/25): Loss: 0.0031 || Timer: 1.9548 sec.\n","===> Epoch[26](8/25): Loss: 0.0023 || Timer: 1.9285 sec.\n","===> Epoch[26](9/25): Loss: 0.0029 || Timer: 1.9325 sec.\n","===> Epoch[26](10/25): Loss: 0.0044 || Timer: 1.9322 sec.\n","===> Epoch[26](11/25): Loss: 0.0022 || Timer: 1.9327 sec.\n","===> Epoch[26](12/25): Loss: 0.0032 || Timer: 1.9282 sec.\n","===> Epoch[26](13/25): Loss: 0.0017 || Timer: 1.9321 sec.\n","===> Epoch[26](14/25): Loss: 0.0024 || Timer: 1.9441 sec.\n","===> Epoch[26](15/25): Loss: 0.0033 || Timer: 1.9311 sec.\n","===> Epoch[26](16/25): Loss: 0.0025 || Timer: 1.9320 sec.\n","===> Epoch[26](17/25): Loss: 0.0025 || Timer: 1.9326 sec.\n","===> Epoch[26](18/25): Loss: 0.0025 || Timer: 1.9300 sec.\n","===> Epoch[26](19/25): Loss: 0.0020 || Timer: 1.9316 sec.\n","===> Epoch[26](20/25): Loss: 0.0028 || Timer: 1.9298 sec.\n","===> Epoch[26](21/25): Loss: 0.0018 || Timer: 1.9320 sec.\n","===> Epoch[26](22/25): Loss: 0.0024 || Timer: 1.9455 sec.\n","===> Epoch[26](23/25): Loss: 0.0018 || Timer: 1.9318 sec.\n","===> Epoch[26](24/25): Loss: 0.0020 || Timer: 1.9284 sec.\n","===> Epoch[26](25/25): Loss: 0.0017 || Timer: 1.9315 sec.\n","===> Epoch 26 Complete: Avg. Loss: 0.0024\n","===> Epoch[27](1/25): Loss: 0.0014 || Timer: 1.9397 sec.\n","===> Epoch[27](2/25): Loss: 0.0023 || Timer: 1.9344 sec.\n","===> Epoch[27](3/25): Loss: 0.0020 || Timer: 1.9291 sec.\n","===> Epoch[27](4/25): Loss: 0.0026 || Timer: 1.9492 sec.\n","===> Epoch[27](5/25): Loss: 0.0023 || Timer: 1.9290 sec.\n","===> Epoch[27](6/25): Loss: 0.0024 || Timer: 1.9341 sec.\n","===> Epoch[27](7/25): Loss: 0.0026 || Timer: 1.9271 sec.\n","===> Epoch[27](8/25): Loss: 0.0031 || Timer: 1.9342 sec.\n","===> Epoch[27](9/25): Loss: 0.0039 || Timer: 1.9275 sec.\n","===> Epoch[27](10/25): Loss: 0.0021 || Timer: 1.9337 sec.\n","===> Epoch[27](11/25): Loss: 0.0020 || Timer: 1.9281 sec.\n","===> Epoch[27](12/25): Loss: 0.0028 || Timer: 1.9543 sec.\n","===> Epoch[27](13/25): Loss: 0.0017 || Timer: 1.9289 sec.\n","===> Epoch[27](14/25): Loss: 0.0017 || Timer: 1.9353 sec.\n","===> Epoch[27](15/25): Loss: 0.0024 || Timer: 1.9275 sec.\n","===> Epoch[27](16/25): Loss: 0.0031 || Timer: 1.9363 sec.\n","===> Epoch[27](17/25): Loss: 0.0017 || Timer: 1.9291 sec.\n","===> Epoch[27](18/25): Loss: 0.0014 || Timer: 1.9349 sec.\n","===> Epoch[27](19/25): Loss: 0.0036 || Timer: 1.9292 sec.\n","===> Epoch[27](20/25): Loss: 0.0032 || Timer: 1.9467 sec.\n","===> Epoch[27](21/25): Loss: 0.0034 || Timer: 1.9297 sec.\n","===> Epoch[27](22/25): Loss: 0.0022 || Timer: 1.9334 sec.\n","===> Epoch[27](23/25): Loss: 0.0020 || Timer: 1.9290 sec.\n","===> Epoch[27](24/25): Loss: 0.0028 || Timer: 1.9356 sec.\n","===> Epoch[27](25/25): Loss: 0.0021 || Timer: 1.9305 sec.\n","===> Epoch 27 Complete: Avg. Loss: 0.0024\n","===> Epoch[28](1/25): Loss: 0.0023 || Timer: 1.9385 sec.\n","===> Epoch[28](2/25): Loss: 0.0023 || Timer: 1.9476 sec.\n","===> Epoch[28](3/25): Loss: 0.0026 || Timer: 1.9291 sec.\n","===> Epoch[28](4/25): Loss: 0.0024 || Timer: 1.9337 sec.\n","===> Epoch[28](5/25): Loss: 0.0024 || Timer: 1.9295 sec.\n","===> Epoch[28](6/25): Loss: 0.0024 || Timer: 1.9324 sec.\n","===> Epoch[28](7/25): Loss: 0.0022 || Timer: 1.9293 sec.\n","===> Epoch[28](8/25): Loss: 0.0032 || Timer: 1.9354 sec.\n","===> Epoch[28](9/25): Loss: 0.0013 || Timer: 1.9287 sec.\n","===> Epoch[28](10/25): Loss: 0.0019 || Timer: 1.9518 sec.\n","===> Epoch[28](11/25): Loss: 0.0016 || Timer: 1.9292 sec.\n","===> Epoch[28](12/25): Loss: 0.0017 || Timer: 1.9332 sec.\n","===> Epoch[28](13/25): Loss: 0.0016 || Timer: 1.9333 sec.\n","===> Epoch[28](14/25): Loss: 0.0023 || Timer: 1.9323 sec.\n","===> Epoch[28](15/25): Loss: 0.0021 || Timer: 1.9321 sec.\n","===> Epoch[28](16/25): Loss: 0.0023 || Timer: 1.9351 sec.\n","===> Epoch[28](17/25): Loss: 0.0021 || Timer: 1.9424 sec.\n","===> Epoch[28](18/25): Loss: 0.0021 || Timer: 1.9309 sec.\n","===> Epoch[28](19/25): Loss: 0.0012 || Timer: 1.9301 sec.\n","===> Epoch[28](20/25): Loss: 0.0025 || Timer: 1.9310 sec.\n","===> Epoch[28](21/25): Loss: 0.0019 || Timer: 1.9294 sec.\n","===> Epoch[28](22/25): Loss: 0.0021 || Timer: 1.9328 sec.\n","===> Epoch[28](23/25): Loss: 0.0019 || Timer: 1.9303 sec.\n","===> Epoch[28](24/25): Loss: 0.0035 || Timer: 1.9319 sec.\n","===> Epoch[28](25/25): Loss: 0.0017 || Timer: 1.9471 sec.\n","===> Epoch 28 Complete: Avg. Loss: 0.0021\n","===> Epoch[29](1/25): Loss: 0.0020 || Timer: 1.9462 sec.\n","===> Epoch[29](2/25): Loss: 0.0030 || Timer: 1.9300 sec.\n","===> Epoch[29](3/25): Loss: 0.0018 || Timer: 1.9355 sec.\n","===> Epoch[29](4/25): Loss: 0.0017 || Timer: 1.9323 sec.\n","===> Epoch[29](5/25): Loss: 0.0017 || Timer: 1.9353 sec.\n","===> Epoch[29](6/25): Loss: 0.0024 || Timer: 1.9303 sec.\n","===> Epoch[29](7/25): Loss: 0.0018 || Timer: 1.9525 sec.\n","===> Epoch[29](8/25): Loss: 0.0022 || Timer: 1.9286 sec.\n","===> Epoch[29](9/25): Loss: 0.0030 || Timer: 1.9354 sec.\n","===> Epoch[29](10/25): Loss: 0.0023 || Timer: 1.9300 sec.\n","===> Epoch[29](11/25): Loss: 0.0021 || Timer: 1.9342 sec.\n","===> Epoch[29](12/25): Loss: 0.0019 || Timer: 1.9293 sec.\n","===> Epoch[29](13/25): Loss: 0.0031 || Timer: 1.9346 sec.\n","===> Epoch[29](14/25): Loss: 0.0020 || Timer: 1.9422 sec.\n","===> Epoch[29](15/25): Loss: 0.0012 || Timer: 1.9380 sec.\n","===> Epoch[29](16/25): Loss: 0.0016 || Timer: 1.9288 sec.\n","===> Epoch[29](17/25): Loss: 0.0027 || Timer: 1.9381 sec.\n","===> Epoch[29](18/25): Loss: 0.0017 || Timer: 1.9290 sec.\n","===> Epoch[29](19/25): Loss: 0.0024 || Timer: 1.9349 sec.\n","===> Epoch[29](20/25): Loss: 0.0019 || Timer: 1.9276 sec.\n","===> Epoch[29](21/25): Loss: 0.0028 || Timer: 1.9335 sec.\n","===> Epoch[29](22/25): Loss: 0.0021 || Timer: 1.9464 sec.\n","===> Epoch[29](23/25): Loss: 0.0025 || Timer: 1.9349 sec.\n","===> Epoch[29](24/25): Loss: 0.0026 || Timer: 1.9302 sec.\n","===> Epoch[29](25/25): Loss: 0.0021 || Timer: 1.9349 sec.\n","===> Epoch 29 Complete: Avg. Loss: 0.0022\n","===> Epoch[30](1/25): Loss: 0.0023 || Timer: 1.9458 sec.\n","===> Epoch[30](2/25): Loss: 0.0020 || Timer: 1.9299 sec.\n","===> Epoch[30](3/25): Loss: 0.0020 || Timer: 1.9325 sec.\n","===> Epoch[30](4/25): Loss: 0.0020 || Timer: 1.9485 sec.\n","===> Epoch[30](5/25): Loss: 0.0019 || Timer: 1.9337 sec.\n","===> Epoch[30](6/25): Loss: 0.0028 || Timer: 1.9315 sec.\n","===> Epoch[30](7/25): Loss: 0.0025 || Timer: 1.9317 sec.\n","===> Epoch[30](8/25): Loss: 0.0026 || Timer: 1.9314 sec.\n","===> Epoch[30](9/25): Loss: 0.0025 || Timer: 1.9323 sec.\n","===> Epoch[30](10/25): Loss: 0.0021 || Timer: 1.9305 sec.\n","===> Epoch[30](11/25): Loss: 0.0022 || Timer: 1.9324 sec.\n","===> Epoch[30](12/25): Loss: 0.0020 || Timer: 1.9550 sec.\n","===> Epoch[30](13/25): Loss: 0.0019 || Timer: 1.9323 sec.\n","===> Epoch[30](14/25): Loss: 0.0029 || Timer: 1.9294 sec.\n","===> Epoch[30](15/25): Loss: 0.0016 || Timer: 1.9334 sec.\n","===> Epoch[30](16/25): Loss: 0.0015 || Timer: 1.9294 sec.\n","===> Epoch[30](17/25): Loss: 0.0019 || Timer: 1.9331 sec.\n","===> Epoch[30](18/25): Loss: 0.0018 || Timer: 1.9295 sec.\n","===> Epoch[30](19/25): Loss: 0.0017 || Timer: 1.9323 sec.\n","===> Epoch[30](20/25): Loss: 0.0018 || Timer: 1.9486 sec.\n","===> Epoch[30](21/25): Loss: 0.0025 || Timer: 1.9317 sec.\n","===> Epoch[30](22/25): Loss: 0.0017 || Timer: 1.9305 sec.\n","===> Epoch[30](23/25): Loss: 0.0017 || Timer: 1.9314 sec.\n","===> Epoch[30](24/25): Loss: 0.0027 || Timer: 1.9298 sec.\n","===> Epoch[30](25/25): Loss: 0.0024 || Timer: 1.9328 sec.\n","===> Epoch 30 Complete: Avg. Loss: 0.0021\n","Checkpoint saved to /content/gdrive/My Drive/졸업논문/졸업논문/scale=2/weights_scale=2/WCNN_epoch_30.pth\n","===> Epoch[31](1/25): Loss: 0.0023 || Timer: 1.9379 sec.\n","===> Epoch[31](2/25): Loss: 0.0012 || Timer: 1.9525 sec.\n","===> Epoch[31](3/25): Loss: 0.0021 || Timer: 1.9285 sec.\n","===> Epoch[31](4/25): Loss: 0.0022 || Timer: 1.9345 sec.\n","===> Epoch[31](5/25): Loss: 0.0030 || Timer: 1.9286 sec.\n","===> Epoch[31](6/25): Loss: 0.0017 || Timer: 1.9337 sec.\n","===> Epoch[31](7/25): Loss: 0.0016 || Timer: 1.9297 sec.\n","===> Epoch[31](8/25): Loss: 0.0014 || Timer: 1.9359 sec.\n","===> Epoch[31](9/25): Loss: 0.0027 || Timer: 1.9290 sec.\n","===> Epoch[31](10/25): Loss: 0.0022 || Timer: 1.9480 sec.\n","===> Epoch[31](11/25): Loss: 0.0018 || Timer: 1.9287 sec.\n","===> Epoch[31](12/25): Loss: 0.0030 || Timer: 1.9353 sec.\n","===> Epoch[31](13/25): Loss: 0.0018 || Timer: 1.9292 sec.\n","===> Epoch[31](14/25): Loss: 0.0023 || Timer: 1.9354 sec.\n","===> Epoch[31](15/25): Loss: 0.0021 || Timer: 1.9293 sec.\n","===> Epoch[31](16/25): Loss: 0.0022 || Timer: 1.9330 sec.\n","===> Epoch[31](17/25): Loss: 0.0015 || Timer: 1.9519 sec.\n","===> Epoch[31](18/25): Loss: 0.0030 || Timer: 1.9340 sec.\n","===> Epoch[31](19/25): Loss: 0.0021 || Timer: 1.9287 sec.\n","===> Epoch[31](20/25): Loss: 0.0021 || Timer: 1.9341 sec.\n","===> Epoch[31](21/25): Loss: 0.0021 || Timer: 1.9295 sec.\n","===> Epoch[31](22/25): Loss: 0.0020 || Timer: 1.9353 sec.\n","===> Epoch[31](23/25): Loss: 0.0024 || Timer: 1.9286 sec.\n","===> Epoch[31](24/25): Loss: 0.0026 || Timer: 1.9343 sec.\n","===> Epoch[31](25/25): Loss: 0.0015 || Timer: 1.9369 sec.\n","===> Epoch 31 Complete: Avg. Loss: 0.0021\n","===> Epoch[32](1/25): Loss: 0.0017 || Timer: 1.9487 sec.\n","===> Epoch[32](2/25): Loss: 0.0016 || Timer: 1.9329 sec.\n","===> Epoch[32](3/25): Loss: 0.0018 || Timer: 1.9302 sec.\n","===> Epoch[32](4/25): Loss: 0.0020 || Timer: 1.9333 sec.\n","===> Epoch[32](5/25): Loss: 0.0027 || Timer: 1.9299 sec.\n","===> Epoch[32](6/25): Loss: 0.0026 || Timer: 1.9315 sec.\n","===> Epoch[32](7/25): Loss: 0.0021 || Timer: 1.9435 sec.\n","===> Epoch[32](8/25): Loss: 0.0013 || Timer: 1.9349 sec.\n","===> Epoch[32](9/25): Loss: 0.0018 || Timer: 1.9298 sec.\n","===> Epoch[32](10/25): Loss: 0.0022 || Timer: 1.9328 sec.\n","===> Epoch[32](11/25): Loss: 0.0024 || Timer: 1.9305 sec.\n","===> Epoch[32](12/25): Loss: 0.0015 || Timer: 1.9326 sec.\n","===> Epoch[32](13/25): Loss: 0.0019 || Timer: 1.9299 sec.\n","===> Epoch[32](14/25): Loss: 0.0023 || Timer: 1.9314 sec.\n","===> Epoch[32](15/25): Loss: 0.0036 || Timer: 1.9451 sec.\n","===> Epoch[32](16/25): Loss: 0.0018 || Timer: 1.9340 sec.\n","===> Epoch[32](17/25): Loss: 0.0015 || Timer: 1.9293 sec.\n","===> Epoch[32](18/25): Loss: 0.0016 || Timer: 1.9322 sec.\n","===> Epoch[32](19/25): Loss: 0.0022 || Timer: 1.9302 sec.\n","===> Epoch[32](20/25): Loss: 0.0018 || Timer: 1.9331 sec.\n","===> Epoch[32](21/25): Loss: 0.0030 || Timer: 1.9322 sec.\n","===> Epoch[32](22/25): Loss: 0.0022 || Timer: 1.9325 sec.\n","===> Epoch[32](23/25): Loss: 0.0015 || Timer: 1.9472 sec.\n","===> Epoch[32](24/25): Loss: 0.0024 || Timer: 1.9315 sec.\n","===> Epoch[32](25/25): Loss: 0.0027 || Timer: 1.9312 sec.\n","===> Epoch 32 Complete: Avg. Loss: 0.0021\n","===> Epoch[33](1/25): Loss: 0.0021 || Timer: 1.9463 sec.\n","===> Epoch[33](2/25): Loss: 0.0020 || Timer: 1.9284 sec.\n","===> Epoch[33](3/25): Loss: 0.0013 || Timer: 1.9349 sec.\n","===> Epoch[33](4/25): Loss: 0.0020 || Timer: 1.9280 sec.\n","===> Epoch[33](5/25): Loss: 0.0022 || Timer: 1.9518 sec.\n","===> Epoch[33](6/25): Loss: 0.0024 || Timer: 1.9292 sec.\n","===> Epoch[33](7/25): Loss: 0.0020 || Timer: 1.9342 sec.\n","===> Epoch[33](8/25): Loss: 0.0015 || Timer: 1.9302 sec.\n","===> Epoch[33](9/25): Loss: 0.0021 || Timer: 1.9356 sec.\n","===> Epoch[33](10/25): Loss: 0.0021 || Timer: 1.9291 sec.\n","===> Epoch[33](11/25): Loss: 0.0024 || Timer: 1.9361 sec.\n","===> Epoch[33](12/25): Loss: 0.0019 || Timer: 1.9286 sec.\n","===> Epoch[33](13/25): Loss: 0.0024 || Timer: 1.9491 sec.\n","===> Epoch[33](14/25): Loss: 0.0029 || Timer: 1.9296 sec.\n","===> Epoch[33](15/25): Loss: 0.0026 || Timer: 1.9346 sec.\n","===> Epoch[33](16/25): Loss: 0.0012 || Timer: 1.9288 sec.\n","===> Epoch[33](17/25): Loss: 0.0025 || Timer: 1.9345 sec.\n","===> Epoch[33](18/25): Loss: 0.0018 || Timer: 1.9310 sec.\n","===> Epoch[33](19/25): Loss: 0.0015 || Timer: 1.9335 sec.\n","===> Epoch[33](20/25): Loss: 0.0031 || Timer: 1.9296 sec.\n","===> Epoch[33](21/25): Loss: 0.0018 || Timer: 1.9573 sec.\n","===> Epoch[33](22/25): Loss: 0.0020 || Timer: 1.9292 sec.\n","===> Epoch[33](23/25): Loss: 0.0019 || Timer: 1.9363 sec.\n","===> Epoch[33](24/25): Loss: 0.0017 || Timer: 1.9283 sec.\n","===> Epoch[33](25/25): Loss: 0.0022 || Timer: 1.9344 sec.\n","===> Epoch 33 Complete: Avg. Loss: 0.0021\n","===> Epoch[34](1/25): Loss: 0.0033 || Timer: 1.9386 sec.\n","===> Epoch[34](2/25): Loss: 0.0030 || Timer: 1.9311 sec.\n","===> Epoch[34](3/25): Loss: 0.0049 || Timer: 1.9480 sec.\n","===> Epoch[34](4/25): Loss: 0.0106 || Timer: 1.9309 sec.\n","===> Epoch[34](5/25): Loss: 0.0119 || Timer: 1.9337 sec.\n","===> Epoch[34](6/25): Loss: 0.0151 || Timer: 1.9298 sec.\n","===> Epoch[34](7/25): Loss: 0.0101 || Timer: 1.9318 sec.\n","===> Epoch[34](8/25): Loss: 0.0042 || Timer: 1.9294 sec.\n","===> Epoch[34](9/25): Loss: 0.0053 || Timer: 1.9335 sec.\n","===> Epoch[34](10/25): Loss: 0.0029 || Timer: 1.9299 sec.\n","===> Epoch[34](11/25): Loss: 0.0048 || Timer: 1.9532 sec.\n","===> Epoch[34](12/25): Loss: 0.0029 || Timer: 1.9305 sec.\n","===> Epoch[34](13/25): Loss: 0.0048 || Timer: 1.9326 sec.\n","===> Epoch[34](14/25): Loss: 0.0025 || Timer: 1.9291 sec.\n","===> Epoch[34](15/25): Loss: 0.0044 || Timer: 1.9311 sec.\n","===> Epoch[34](16/25): Loss: 0.0040 || Timer: 1.9304 sec.\n","===> Epoch[34](17/25): Loss: 0.0030 || Timer: 1.9319 sec.\n","===> Epoch[34](18/25): Loss: 0.0060 || Timer: 1.9293 sec.\n","===> Epoch[34](19/25): Loss: 0.0036 || Timer: 1.9461 sec.\n","===> Epoch[34](20/25): Loss: 0.0022 || Timer: 1.9290 sec.\n","===> Epoch[34](21/25): Loss: 0.0052 || Timer: 1.9320 sec.\n","===> Epoch[34](22/25): Loss: 0.0034 || Timer: 1.9300 sec.\n","===> Epoch[34](23/25): Loss: 0.0026 || Timer: 1.9312 sec.\n","===> Epoch[34](24/25): Loss: 0.0050 || Timer: 1.9298 sec.\n","===> Epoch[34](25/25): Loss: 0.0026 || Timer: 1.9340 sec.\n","===> Epoch 34 Complete: Avg. Loss: 0.0051\n","===> Epoch[35](1/25): Loss: 0.0038 || Timer: 1.9456 sec.\n","===> Epoch[35](2/25): Loss: 0.0032 || Timer: 1.9341 sec.\n","===> Epoch[35](3/25): Loss: 0.0031 || Timer: 1.9282 sec.\n","===> Epoch[35](4/25): Loss: 0.0026 || Timer: 1.9342 sec.\n","===> Epoch[35](5/25): Loss: 0.0026 || Timer: 1.9286 sec.\n","===> Epoch[35](6/25): Loss: 0.0031 || Timer: 1.9355 sec.\n","===> Epoch[35](7/25): Loss: 0.0029 || Timer: 1.9284 sec.\n","===> Epoch[35](8/25): Loss: 0.0025 || Timer: 1.9520 sec.\n","===> Epoch[35](9/25): Loss: 0.0020 || Timer: 1.9288 sec.\n","===> Epoch[35](10/25): Loss: 0.0017 || Timer: 1.9344 sec.\n","===> Epoch[35](11/25): Loss: 0.0013 || Timer: 1.9328 sec.\n","===> Epoch[35](12/25): Loss: 0.0023 || Timer: 1.9363 sec.\n","===> Epoch[35](13/25): Loss: 0.0025 || Timer: 1.9282 sec.\n","===> Epoch[35](14/25): Loss: 0.0021 || Timer: 1.9363 sec.\n","===> Epoch[35](15/25): Loss: 0.0019 || Timer: 1.9300 sec.\n","===> Epoch[35](16/25): Loss: 0.0021 || Timer: 1.9493 sec.\n","===> Epoch[35](17/25): Loss: 0.0033 || Timer: 1.9296 sec.\n","===> Epoch[35](18/25): Loss: 0.0019 || Timer: 1.9339 sec.\n","===> Epoch[35](19/25): Loss: 0.0022 || Timer: 1.9284 sec.\n","===> Epoch[35](20/25): Loss: 0.0021 || Timer: 1.9349 sec.\n","===> Epoch[35](21/25): Loss: 0.0022 || Timer: 1.9289 sec.\n","===> Epoch[35](22/25): Loss: 0.0024 || Timer: 1.9366 sec.\n","===> Epoch[35](23/25): Loss: 0.0024 || Timer: 1.9294 sec.\n","===> Epoch[35](24/25): Loss: 0.0017 || Timer: 1.9509 sec.\n","===> Epoch[35](25/25): Loss: 0.0023 || Timer: 1.9297 sec.\n","===> Epoch 35 Complete: Avg. Loss: 0.0024\n","===> Epoch[36](1/25): Loss: 0.0018 || Timer: 1.9427 sec.\n","===> Epoch[36](2/25): Loss: 0.0026 || Timer: 1.9347 sec.\n","===> Epoch[36](3/25): Loss: 0.0023 || Timer: 1.9312 sec.\n","===> Epoch[36](4/25): Loss: 0.0027 || Timer: 1.9320 sec.\n","===> Epoch[36](5/25): Loss: 0.0025 || Timer: 1.9290 sec.\n","===> Epoch[36](6/25): Loss: 0.0022 || Timer: 1.9457 sec.\n","===> Epoch[36](7/25): Loss: 0.0021 || Timer: 1.9287 sec.\n","===> Epoch[36](8/25): Loss: 0.0021 || Timer: 1.9319 sec.\n","===> Epoch[36](9/25): Loss: 0.0016 || Timer: 1.9295 sec.\n","===> Epoch[36](10/25): Loss: 0.0013 || Timer: 1.9313 sec.\n","===> Epoch[36](11/25): Loss: 0.0022 || Timer: 1.9303 sec.\n","===> Epoch[36](12/25): Loss: 0.0020 || Timer: 1.9315 sec.\n","===> Epoch[36](13/25): Loss: 0.0026 || Timer: 1.9312 sec.\n","===> Epoch[36](14/25): Loss: 0.0021 || Timer: 1.9532 sec.\n","===> Epoch[36](15/25): Loss: 0.0012 || Timer: 1.9296 sec.\n","===> Epoch[36](16/25): Loss: 0.0019 || Timer: 1.9328 sec.\n","===> Epoch[36](17/25): Loss: 0.0026 || Timer: 1.9307 sec.\n","===> Epoch[36](18/25): Loss: 0.0024 || Timer: 1.9318 sec.\n","===> Epoch[36](19/25): Loss: 0.0017 || Timer: 1.9304 sec.\n","===> Epoch[36](20/25): Loss: 0.0021 || Timer: 1.9311 sec.\n","===> Epoch[36](21/25): Loss: 0.0023 || Timer: 1.9306 sec.\n","===> Epoch[36](22/25): Loss: 0.0020 || Timer: 1.9499 sec.\n","===> Epoch[36](23/25): Loss: 0.0022 || Timer: 1.9294 sec.\n","===> Epoch[36](24/25): Loss: 0.0018 || Timer: 1.9335 sec.\n","===> Epoch[36](25/25): Loss: 0.0023 || Timer: 1.9306 sec.\n","===> Epoch 36 Complete: Avg. Loss: 0.0021\n","===> Epoch[37](1/25): Loss: 0.0018 || Timer: 1.9445 sec.\n","===> Epoch[37](2/25): Loss: 0.0019 || Timer: 1.9308 sec.\n","===> Epoch[37](3/25): Loss: 0.0023 || Timer: 1.9353 sec.\n","===> Epoch[37](4/25): Loss: 0.0022 || Timer: 1.9427 sec.\n","===> Epoch[37](5/25): Loss: 0.0031 || Timer: 1.9339 sec.\n","===> Epoch[37](6/25): Loss: 0.0020 || Timer: 1.9278 sec.\n","===> Epoch[37](7/25): Loss: 0.0016 || Timer: 1.9339 sec.\n","===> Epoch[37](8/25): Loss: 0.0026 || Timer: 1.9332 sec.\n","===> Epoch[37](9/25): Loss: 0.0023 || Timer: 1.9356 sec.\n","===> Epoch[37](10/25): Loss: 0.0021 || Timer: 1.9289 sec.\n","===> Epoch[37](11/25): Loss: 0.0014 || Timer: 1.9358 sec.\n","===> Epoch[37](12/25): Loss: 0.0017 || Timer: 1.9427 sec.\n","===> Epoch[37](13/25): Loss: 0.0026 || Timer: 1.9330 sec.\n","===> Epoch[37](14/25): Loss: 0.0025 || Timer: 1.9292 sec.\n","===> Epoch[37](15/25): Loss: 0.0026 || Timer: 1.9330 sec.\n","===> Epoch[37](16/25): Loss: 0.0014 || Timer: 1.9353 sec.\n","===> Epoch[37](17/25): Loss: 0.0026 || Timer: 1.9349 sec.\n","===> Epoch[37](18/25): Loss: 0.0016 || Timer: 1.9284 sec.\n","===> Epoch[37](19/25): Loss: 0.0027 || Timer: 1.9358 sec.\n","===> Epoch[37](20/25): Loss: 0.0019 || Timer: 1.9467 sec.\n","===> Epoch[37](21/25): Loss: 0.0010 || Timer: 1.9332 sec.\n","===> Epoch[37](22/25): Loss: 0.0022 || Timer: 1.9282 sec.\n","===> Epoch[37](23/25): Loss: 0.0017 || Timer: 1.9341 sec.\n","===> Epoch[37](24/25): Loss: 0.0028 || Timer: 1.9312 sec.\n","===> Epoch[37](25/25): Loss: 0.0021 || Timer: 1.9334 sec.\n","===> Epoch 37 Complete: Avg. Loss: 0.0021\n","===> Epoch[38](1/25): Loss: 0.0013 || Timer: 1.9403 sec.\n","===> Epoch[38](2/25): Loss: 0.0021 || Timer: 1.9412 sec.\n","===> Epoch[38](3/25): Loss: 0.0017 || Timer: 1.9365 sec.\n","===> Epoch[38](4/25): Loss: 0.0031 || Timer: 1.9305 sec.\n","===> Epoch[38](5/25): Loss: 0.0021 || Timer: 1.9342 sec.\n","===> Epoch[38](6/25): Loss: 0.0028 || Timer: 1.9335 sec.\n","===> Epoch[38](7/25): Loss: 0.0028 || Timer: 1.9316 sec.\n","===> Epoch[38](8/25): Loss: 0.0018 || Timer: 1.9287 sec.\n","===> Epoch[38](9/25): Loss: 0.0019 || Timer: 1.9531 sec.\n","===> Epoch[38](10/25): Loss: 0.0015 || Timer: 1.9298 sec.\n","===> Epoch[38](11/25): Loss: 0.0022 || Timer: 1.9316 sec.\n","===> Epoch[38](12/25): Loss: 0.0016 || Timer: 1.9303 sec.\n","===> Epoch[38](13/25): Loss: 0.0016 || Timer: 1.9318 sec.\n","===> Epoch[38](14/25): Loss: 0.0018 || Timer: 1.9300 sec.\n","===> Epoch[38](15/25): Loss: 0.0029 || Timer: 1.9325 sec.\n","===> Epoch[38](16/25): Loss: 0.0019 || Timer: 1.9538 sec.\n","===> Epoch[38](17/25): Loss: 0.0015 || Timer: 1.9320 sec.\n","===> Epoch[38](18/25): Loss: 0.0016 || Timer: 1.9292 sec.\n","===> Epoch[38](19/25): Loss: 0.0014 || Timer: 1.9320 sec.\n","===> Epoch[38](20/25): Loss: 0.0024 || Timer: 1.9292 sec.\n","===> Epoch[38](21/25): Loss: 0.0018 || Timer: 1.9321 sec.\n","===> Epoch[38](22/25): Loss: 0.0021 || Timer: 1.9308 sec.\n","===> Epoch[38](23/25): Loss: 0.0017 || Timer: 1.9329 sec.\n","===> Epoch[38](24/25): Loss: 0.0024 || Timer: 1.9423 sec.\n","===> Epoch[38](25/25): Loss: 0.0022 || Timer: 1.9329 sec.\n","===> Epoch 38 Complete: Avg. Loss: 0.0020\n","===> Epoch[39](1/25): Loss: 0.0014 || Timer: 1.9386 sec.\n","===> Epoch[39](2/25): Loss: 0.0020 || Timer: 1.9335 sec.\n","===> Epoch[39](3/25): Loss: 0.0014 || Timer: 1.9290 sec.\n","===> Epoch[39](4/25): Loss: 0.0026 || Timer: 1.9347 sec.\n","===> Epoch[39](5/25): Loss: 0.0016 || Timer: 1.9286 sec.\n","===> Epoch[39](6/25): Loss: 0.0021 || Timer: 1.9517 sec.\n","===> Epoch[39](7/25): Loss: 0.0013 || Timer: 1.9302 sec.\n","===> Epoch[39](8/25): Loss: 0.0023 || Timer: 1.9372 sec.\n","===> Epoch[39](9/25): Loss: 0.0025 || Timer: 1.9295 sec.\n","===> Epoch[39](10/25): Loss: 0.0019 || Timer: 1.9353 sec.\n","===> Epoch[39](11/25): Loss: 0.0022 || Timer: 1.9285 sec.\n","===> Epoch[39](12/25): Loss: 0.0022 || Timer: 1.9336 sec.\n","===> Epoch[39](13/25): Loss: 0.0016 || Timer: 1.9304 sec.\n","===> Epoch[39](14/25): Loss: 0.0016 || Timer: 1.9467 sec.\n","===> Epoch[39](15/25): Loss: 0.0022 || Timer: 1.9312 sec.\n","===> Epoch[39](16/25): Loss: 0.0027 || Timer: 1.9334 sec.\n","===> Epoch[39](17/25): Loss: 0.0023 || Timer: 1.9289 sec.\n","===> Epoch[39](18/25): Loss: 0.0019 || Timer: 1.9353 sec.\n","===> Epoch[39](19/25): Loss: 0.0018 || Timer: 1.9333 sec.\n","===> Epoch[39](20/25): Loss: 0.0017 || Timer: 1.9356 sec.\n","===> Epoch[39](21/25): Loss: 0.0033 || Timer: 1.9284 sec.\n","===> Epoch[39](22/25): Loss: 0.0016 || Timer: 1.9563 sec.\n","===> Epoch[39](23/25): Loss: 0.0016 || Timer: 1.9297 sec.\n","===> Epoch[39](24/25): Loss: 0.0017 || Timer: 1.9349 sec.\n","===> Epoch[39](25/25): Loss: 0.0020 || Timer: 1.9294 sec.\n","===> Epoch 39 Complete: Avg. Loss: 0.0020\n","===> Epoch[40](1/25): Loss: 0.0014 || Timer: 1.9433 sec.\n","===> Epoch[40](2/25): Loss: 0.0024 || Timer: 1.9406 sec.\n","===> Epoch[40](3/25): Loss: 0.0019 || Timer: 1.9305 sec.\n","===> Epoch[40](4/25): Loss: 0.0016 || Timer: 1.9484 sec.\n","===> Epoch[40](5/25): Loss: 0.0020 || Timer: 1.9295 sec.\n","===> Epoch[40](6/25): Loss: 0.0031 || Timer: 1.9341 sec.\n","===> Epoch[40](7/25): Loss: 0.0016 || Timer: 1.9287 sec.\n","===> Epoch[40](8/25): Loss: 0.0023 || Timer: 1.9317 sec.\n","===> Epoch[40](9/25): Loss: 0.0026 || Timer: 1.9298 sec.\n","===> Epoch[40](10/25): Loss: 0.0019 || Timer: 1.9332 sec.\n","===> Epoch[40](11/25): Loss: 0.0039 || Timer: 1.9312 sec.\n","===> Epoch[40](12/25): Loss: 0.0019 || Timer: 1.9463 sec.\n","===> Epoch[40](13/25): Loss: 0.0016 || Timer: 1.9300 sec.\n","===> Epoch[40](14/25): Loss: 0.0021 || Timer: 1.9308 sec.\n","===> Epoch[40](15/25): Loss: 0.0019 || Timer: 1.9300 sec.\n","===> Epoch[40](16/25): Loss: 0.0027 || Timer: 1.9323 sec.\n","===> Epoch[40](17/25): Loss: 0.0025 || Timer: 1.9292 sec.\n","===> Epoch[40](18/25): Loss: 0.0017 || Timer: 1.9331 sec.\n","===> Epoch[40](19/25): Loss: 0.0026 || Timer: 1.9299 sec.\n","===> Epoch[40](20/25): Loss: 0.0023 || Timer: 1.9559 sec.\n","===> Epoch[40](21/25): Loss: 0.0022 || Timer: 1.9301 sec.\n","===> Epoch[40](22/25): Loss: 0.0018 || Timer: 1.9338 sec.\n","===> Epoch[40](23/25): Loss: 0.0018 || Timer: 1.9291 sec.\n","===> Epoch[40](24/25): Loss: 0.0020 || Timer: 1.9338 sec.\n","===> Epoch[40](25/25): Loss: 0.0020 || Timer: 1.9314 sec.\n","===> Epoch 40 Complete: Avg. Loss: 0.0021\n","Checkpoint saved to /content/gdrive/My Drive/졸업논문/졸업논문/scale=2/weights_scale=2/WCNN_epoch_40.pth\n","===> Epoch[41](1/25): Loss: 0.0021 || Timer: 1.9426 sec.\n","===> Epoch[41](2/25): Loss: 0.0012 || Timer: 1.9485 sec.\n","===> Epoch[41](3/25): Loss: 0.0017 || Timer: 1.9347 sec.\n","===> Epoch[41](4/25): Loss: 0.0034 || Timer: 1.9288 sec.\n","===> Epoch[41](5/25): Loss: 0.0013 || Timer: 1.9349 sec.\n","===> Epoch[41](6/25): Loss: 0.0024 || Timer: 1.9288 sec.\n","===> Epoch[41](7/25): Loss: 0.0023 || Timer: 1.9337 sec.\n","===> Epoch[41](8/25): Loss: 0.0015 || Timer: 1.9294 sec.\n","===> Epoch[41](9/25): Loss: 0.0018 || Timer: 1.9383 sec.\n","===> Epoch[41](10/25): Loss: 0.0018 || Timer: 1.9481 sec.\n","===> Epoch[41](11/25): Loss: 0.0016 || Timer: 1.9357 sec.\n","===> Epoch[41](12/25): Loss: 0.0018 || Timer: 1.9279 sec.\n","===> Epoch[41](13/25): Loss: 0.0017 || Timer: 1.9344 sec.\n","===> Epoch[41](14/25): Loss: 0.0018 || Timer: 1.9304 sec.\n","===> Epoch[41](15/25): Loss: 0.0014 || Timer: 1.9339 sec.\n","===> Epoch[41](16/25): Loss: 0.0026 || Timer: 1.9299 sec.\n","===> Epoch[41](17/25): Loss: 0.0014 || Timer: 1.9532 sec.\n","===> Epoch[41](18/25): Loss: 0.0025 || Timer: 1.9308 sec.\n","===> Epoch[41](19/25): Loss: 0.0022 || Timer: 1.9348 sec.\n","===> Epoch[41](20/25): Loss: 0.0025 || Timer: 1.9288 sec.\n","===> Epoch[41](21/25): Loss: 0.0020 || Timer: 1.9353 sec.\n","===> Epoch[41](22/25): Loss: 0.0016 || Timer: 1.9304 sec.\n","===> Epoch[41](23/25): Loss: 0.0022 || Timer: 1.9345 sec.\n","===> Epoch[41](24/25): Loss: 0.0021 || Timer: 1.9333 sec.\n","===> Epoch[41](25/25): Loss: 0.0023 || Timer: 1.9512 sec.\n","===> Epoch 41 Complete: Avg. Loss: 0.0020\n","===> Epoch[42](1/25): Loss: 0.0016 || Timer: 1.9584 sec.\n","===> Epoch[42](2/25): Loss: 0.0020 || Timer: 1.9299 sec.\n","===> Epoch[42](3/25): Loss: 0.0019 || Timer: 1.9334 sec.\n","===> Epoch[42](4/25): Loss: 0.0019 || Timer: 1.9304 sec.\n","===> Epoch[42](5/25): Loss: 0.0019 || Timer: 1.9402 sec.\n","===> Epoch[42](6/25): Loss: 0.0017 || Timer: 1.9295 sec.\n","===> Epoch[42](7/25): Loss: 0.0021 || Timer: 1.9479 sec.\n","===> Epoch[42](8/25): Loss: 0.0024 || Timer: 1.9292 sec.\n","===> Epoch[42](9/25): Loss: 0.0016 || Timer: 1.9338 sec.\n","===> Epoch[42](10/25): Loss: 0.0021 || Timer: 1.9300 sec.\n","===> Epoch[42](11/25): Loss: 0.0018 || Timer: 1.9309 sec.\n","===> Epoch[42](12/25): Loss: 0.0018 || Timer: 1.9302 sec.\n","===> Epoch[42](13/25): Loss: 0.0020 || Timer: 1.9323 sec.\n","===> Epoch[42](14/25): Loss: 0.0020 || Timer: 1.9451 sec.\n","===> Epoch[42](15/25): Loss: 0.0017 || Timer: 1.9321 sec.\n","===> Epoch[42](16/25): Loss: 0.0012 || Timer: 1.9309 sec.\n","===> Epoch[42](17/25): Loss: 0.0016 || Timer: 1.9326 sec.\n","===> Epoch[42](18/25): Loss: 0.0013 || Timer: 1.9328 sec.\n","===> Epoch[42](19/25): Loss: 0.0019 || Timer: 1.9315 sec.\n","===> Epoch[42](20/25): Loss: 0.0011 || Timer: 1.9296 sec.\n","===> Epoch[42](21/25): Loss: 0.0029 || Timer: 1.9342 sec.\n","===> Epoch[42](22/25): Loss: 0.0016 || Timer: 1.9500 sec.\n","===> Epoch[42](23/25): Loss: 0.0029 || Timer: 1.9313 sec.\n","===> Epoch[42](24/25): Loss: 0.0012 || Timer: 1.9297 sec.\n","===> Epoch[42](25/25): Loss: 0.0021 || Timer: 1.9331 sec.\n","===> Epoch 42 Complete: Avg. Loss: 0.0019\n","===> Epoch[43](1/25): Loss: 0.0022 || Timer: 1.9403 sec.\n","===> Epoch[43](2/25): Loss: 0.0016 || Timer: 1.9349 sec.\n","===> Epoch[43](3/25): Loss: 0.0021 || Timer: 1.9289 sec.\n","===> Epoch[43](4/25): Loss: 0.0023 || Timer: 1.9484 sec.\n","===> Epoch[43](5/25): Loss: 0.0012 || Timer: 1.9302 sec.\n","===> Epoch[43](6/25): Loss: 0.0020 || Timer: 1.9338 sec.\n","===> Epoch[43](7/25): Loss: 0.0019 || Timer: 1.9295 sec.\n","===> Epoch[43](8/25): Loss: 0.0019 || Timer: 1.9360 sec.\n","===> Epoch[43](9/25): Loss: 0.0022 || Timer: 1.9283 sec.\n","===> Epoch[43](10/25): Loss: 0.0016 || Timer: 1.9351 sec.\n","===> Epoch[43](11/25): Loss: 0.0018 || Timer: 1.9461 sec.\n","===> Epoch[43](12/25): Loss: 0.0023 || Timer: 1.9336 sec.\n","===> Epoch[43](13/25): Loss: 0.0014 || Timer: 1.9291 sec.\n","===> Epoch[43](14/25): Loss: 0.0026 || Timer: 1.9348 sec.\n","===> Epoch[43](15/25): Loss: 0.0014 || Timer: 1.9306 sec.\n","===> Epoch[43](16/25): Loss: 0.0018 || Timer: 1.9360 sec.\n","===> Epoch[43](17/25): Loss: 0.0016 || Timer: 1.9306 sec.\n","===> Epoch[43](18/25): Loss: 0.0022 || Timer: 1.9357 sec.\n","===> Epoch[43](19/25): Loss: 0.0017 || Timer: 1.9500 sec.\n","===> Epoch[43](20/25): Loss: 0.0017 || Timer: 1.9338 sec.\n","===> Epoch[43](21/25): Loss: 0.0019 || Timer: 1.9288 sec.\n","===> Epoch[43](22/25): Loss: 0.0024 || Timer: 1.9379 sec.\n","===> Epoch[43](23/25): Loss: 0.0016 || Timer: 1.9286 sec.\n","===> Epoch[43](24/25): Loss: 0.0016 || Timer: 1.9334 sec.\n","===> Epoch[43](25/25): Loss: 0.0015 || Timer: 1.9289 sec.\n","===> Epoch 43 Complete: Avg. Loss: 0.0019\n","===> Epoch[44](1/25): Loss: 0.0021 || Timer: 1.9492 sec.\n","===> Epoch[44](2/25): Loss: 0.0017 || Timer: 1.9322 sec.\n","===> Epoch[44](3/25): Loss: 0.0013 || Timer: 1.9284 sec.\n","===> Epoch[44](4/25): Loss: 0.0017 || Timer: 1.9324 sec.\n","===> Epoch[44](5/25): Loss: 0.0015 || Timer: 1.9315 sec.\n","===> Epoch[44](6/25): Loss: 0.0016 || Timer: 1.9327 sec.\n","===> Epoch[44](7/25): Loss: 0.0035 || Timer: 1.9304 sec.\n","===> Epoch[44](8/25): Loss: 0.0022 || Timer: 1.9562 sec.\n","===> Epoch[44](9/25): Loss: 0.0022 || Timer: 1.9302 sec.\n","===> Epoch[44](10/25): Loss: 0.0019 || Timer: 1.9344 sec.\n","===> Epoch[44](11/25): Loss: 0.0022 || Timer: 1.9302 sec.\n","===> Epoch[44](12/25): Loss: 0.0017 || Timer: 1.9335 sec.\n","===> Epoch[44](13/25): Loss: 0.0023 || Timer: 1.9297 sec.\n","===> Epoch[44](14/25): Loss: 0.0016 || Timer: 1.9330 sec.\n","===> Epoch[44](15/25): Loss: 0.0022 || Timer: 1.9283 sec.\n","===> Epoch[44](16/25): Loss: 0.0015 || Timer: 1.9510 sec.\n","===> Epoch[44](17/25): Loss: 0.0017 || Timer: 1.9321 sec.\n","===> Epoch[44](18/25): Loss: 0.0012 || Timer: 1.9332 sec.\n","===> Epoch[44](19/25): Loss: 0.0014 || Timer: 1.9320 sec.\n","===> Epoch[44](20/25): Loss: 0.0025 || Timer: 1.9335 sec.\n","===> Epoch[44](21/25): Loss: 0.0020 || Timer: 1.9304 sec.\n","===> Epoch[44](22/25): Loss: 0.0021 || Timer: 1.9319 sec.\n","===> Epoch[44](23/25): Loss: 0.0012 || Timer: 1.9305 sec.\n","===> Epoch[44](24/25): Loss: 0.0012 || Timer: 1.9449 sec.\n","===> Epoch[44](25/25): Loss: 0.0014 || Timer: 1.9309 sec.\n","===> Epoch 44 Complete: Avg. Loss: 0.0018\n","===> Epoch[45](1/25): Loss: 0.0026 || Timer: 1.9419 sec.\n","===> Epoch[45](2/25): Loss: 0.0025 || Timer: 1.9308 sec.\n","===> Epoch[45](3/25): Loss: 0.0015 || Timer: 1.9365 sec.\n","===> Epoch[45](4/25): Loss: 0.0011 || Timer: 1.9279 sec.\n","===> Epoch[45](5/25): Loss: 0.0020 || Timer: 1.9344 sec.\n","===> Epoch[45](6/25): Loss: 0.0025 || Timer: 1.9459 sec.\n","===> Epoch[45](7/25): Loss: 0.0019 || Timer: 1.9419 sec.\n","===> Epoch[45](8/25): Loss: 0.0017 || Timer: 1.9283 sec.\n","===> Epoch[45](9/25): Loss: 0.0017 || Timer: 1.9348 sec.\n","===> Epoch[45](10/25): Loss: 0.0017 || Timer: 1.9291 sec.\n","===> Epoch[45](11/25): Loss: 0.0014 || Timer: 1.9346 sec.\n","===> Epoch[45](12/25): Loss: 0.0018 || Timer: 1.9283 sec.\n","===> Epoch[45](13/25): Loss: 0.0014 || Timer: 1.9343 sec.\n","===> Epoch[45](14/25): Loss: 0.0019 || Timer: 1.9487 sec.\n","===> Epoch[45](15/25): Loss: 0.0018 || Timer: 1.9340 sec.\n","===> Epoch[45](16/25): Loss: 0.0018 || Timer: 1.9287 sec.\n","===> Epoch[45](17/25): Loss: 0.0018 || Timer: 1.9339 sec.\n","===> Epoch[45](18/25): Loss: 0.0015 || Timer: 1.9287 sec.\n","===> Epoch[45](19/25): Loss: 0.0019 || Timer: 1.9346 sec.\n","===> Epoch[45](20/25): Loss: 0.0020 || Timer: 1.9279 sec.\n","===> Epoch[45](21/25): Loss: 0.0024 || Timer: 1.9376 sec.\n","===> Epoch[45](22/25): Loss: 0.0025 || Timer: 1.9412 sec.\n","===> Epoch[45](23/25): Loss: 0.0018 || Timer: 1.9348 sec.\n","===> Epoch[45](24/25): Loss: 0.0015 || Timer: 1.9299 sec.\n","===> Epoch[45](25/25): Loss: 0.0032 || Timer: 1.9332 sec.\n","===> Epoch 45 Complete: Avg. Loss: 0.0019\n","===> Epoch[46](1/25): Loss: 0.0028 || Timer: 1.9422 sec.\n","===> Epoch[46](2/25): Loss: 0.0024 || Timer: 1.9294 sec.\n","===> Epoch[46](3/25): Loss: 0.0014 || Timer: 1.9336 sec.\n","===> Epoch[46](4/25): Loss: 0.0021 || Timer: 1.9519 sec.\n","===> Epoch[46](5/25): Loss: 0.0020 || Timer: 1.9340 sec.\n","===> Epoch[46](6/25): Loss: 0.0017 || Timer: 1.9295 sec.\n","===> Epoch[46](7/25): Loss: 0.0018 || Timer: 1.9310 sec.\n","===> Epoch[46](8/25): Loss: 0.0029 || Timer: 1.9281 sec.\n","===> Epoch[46](9/25): Loss: 0.0020 || Timer: 1.9322 sec.\n","===> Epoch[46](10/25): Loss: 0.0019 || Timer: 1.9301 sec.\n","===> Epoch[46](11/25): Loss: 0.0014 || Timer: 1.9415 sec.\n","===> Epoch[46](12/25): Loss: 0.0017 || Timer: 1.9304 sec.\n","===> Epoch[46](13/25): Loss: 0.0014 || Timer: 1.9339 sec.\n","===> Epoch[46](14/25): Loss: 0.0012 || Timer: 1.9295 sec.\n","===> Epoch[46](15/25): Loss: 0.0013 || Timer: 1.9323 sec.\n","===> Epoch[46](16/25): Loss: 0.0027 || Timer: 1.9301 sec.\n","===> Epoch[46](17/25): Loss: 0.0019 || Timer: 1.9319 sec.\n","===> Epoch[46](18/25): Loss: 0.0029 || Timer: 1.9319 sec.\n","===> Epoch[46](19/25): Loss: 0.0022 || Timer: 1.9493 sec.\n","===> Epoch[46](20/25): Loss: 0.0022 || Timer: 1.9294 sec.\n","===> Epoch[46](21/25): Loss: 0.0020 || Timer: 1.9312 sec.\n","===> Epoch[46](22/25): Loss: 0.0012 || Timer: 1.9307 sec.\n","===> Epoch[46](23/25): Loss: 0.0015 || Timer: 1.9316 sec.\n","===> Epoch[46](24/25): Loss: 0.0024 || Timer: 1.9299 sec.\n","===> Epoch[46](25/25): Loss: 0.0018 || Timer: 1.9323 sec.\n","===> Epoch 46 Complete: Avg. Loss: 0.0020\n","===> Epoch[47](1/25): Loss: 0.0027 || Timer: 1.9520 sec.\n","===> Epoch[47](2/25): Loss: 0.0019 || Timer: 1.9360 sec.\n","===> Epoch[47](3/25): Loss: 0.0015 || Timer: 1.9297 sec.\n","===> Epoch[47](4/25): Loss: 0.0016 || Timer: 1.9350 sec.\n","===> Epoch[47](5/25): Loss: 0.0018 || Timer: 1.9287 sec.\n","===> Epoch[47](6/25): Loss: 0.0017 || Timer: 1.9360 sec.\n","===> Epoch[47](7/25): Loss: 0.0017 || Timer: 1.9305 sec.\n","===> Epoch[47](8/25): Loss: 0.0011 || Timer: 1.9474 sec.\n","===> Epoch[47](9/25): Loss: 0.0013 || Timer: 1.9290 sec.\n","===> Epoch[47](10/25): Loss: 0.0010 || Timer: 1.9341 sec.\n","===> Epoch[47](11/25): Loss: 0.0013 || Timer: 1.9313 sec.\n","===> Epoch[47](12/25): Loss: 0.0017 || Timer: 1.9347 sec.\n","===> Epoch[47](13/25): Loss: 0.0015 || Timer: 1.9305 sec.\n","===> Epoch[47](14/25): Loss: 0.0021 || Timer: 1.9335 sec.\n","===> Epoch[47](15/25): Loss: 0.0009 || Timer: 1.9289 sec.\n","===> Epoch[47](16/25): Loss: 0.0020 || Timer: 1.9581 sec.\n","===> Epoch[47](17/25): Loss: 0.0018 || Timer: 1.9290 sec.\n","===> Epoch[47](18/25): Loss: 0.0012 || Timer: 1.9372 sec.\n","===> Epoch[47](19/25): Loss: 0.0020 || Timer: 1.9299 sec.\n","===> Epoch[47](20/25): Loss: 0.0015 || Timer: 1.9361 sec.\n","===> Epoch[47](21/25): Loss: 0.0024 || Timer: 1.9284 sec.\n","===> Epoch[47](22/25): Loss: 0.0016 || Timer: 1.9366 sec.\n","===> Epoch[47](23/25): Loss: 0.0014 || Timer: 1.9294 sec.\n","===> Epoch[47](24/25): Loss: 0.0011 || Timer: 1.9525 sec.\n","===> Epoch[47](25/25): Loss: 0.0021 || Timer: 1.9293 sec.\n","===> Epoch 47 Complete: Avg. Loss: 0.0016\n","===> Epoch[48](1/25): Loss: 0.0019 || Timer: 1.9465 sec.\n","===> Epoch[48](2/25): Loss: 0.0014 || Timer: 1.9322 sec.\n","===> Epoch[48](3/25): Loss: 0.0016 || Timer: 1.9286 sec.\n","===> Epoch[48](4/25): Loss: 0.0014 || Timer: 1.9329 sec.\n","===> Epoch[48](5/25): Loss: 0.0023 || Timer: 1.9319 sec.\n","===> Epoch[48](6/25): Loss: 0.0014 || Timer: 1.9529 sec.\n","===> Epoch[48](7/25): Loss: 0.0013 || Timer: 1.9317 sec.\n","===> Epoch[48](8/25): Loss: 0.0016 || Timer: 1.9340 sec.\n","===> Epoch[48](9/25): Loss: 0.0024 || Timer: 1.9305 sec.\n","===> Epoch[48](10/25): Loss: 0.0012 || Timer: 1.9351 sec.\n","===> Epoch[48](11/25): Loss: 0.0013 || Timer: 1.9300 sec.\n","===> Epoch[48](12/25): Loss: 0.0015 || Timer: 1.9381 sec.\n","===> Epoch[48](13/25): Loss: 0.0017 || Timer: 1.9303 sec.\n","===> Epoch[48](14/25): Loss: 0.0020 || Timer: 1.9457 sec.\n","===> Epoch[48](15/25): Loss: 0.0022 || Timer: 1.9285 sec.\n","===> Epoch[48](16/25): Loss: 0.0031 || Timer: 1.9333 sec.\n","===> Epoch[48](17/25): Loss: 0.0015 || Timer: 1.9315 sec.\n","===> Epoch[48](18/25): Loss: 0.0018 || Timer: 1.9328 sec.\n","===> Epoch[48](19/25): Loss: 0.0024 || Timer: 1.9306 sec.\n","===> Epoch[48](20/25): Loss: 0.0018 || Timer: 1.9335 sec.\n","===> Epoch[48](21/25): Loss: 0.0020 || Timer: 1.9304 sec.\n","===> Epoch[48](22/25): Loss: 0.0012 || Timer: 1.9504 sec.\n","===> Epoch[48](23/25): Loss: 0.0016 || Timer: 1.9289 sec.\n","===> Epoch[48](24/25): Loss: 0.0020 || Timer: 1.9354 sec.\n","===> Epoch[48](25/25): Loss: 0.0013 || Timer: 1.9304 sec.\n","===> Epoch 48 Complete: Avg. Loss: 0.0018\n","===> Epoch[49](1/25): Loss: 0.0024 || Timer: 1.9435 sec.\n","===> Epoch[49](2/25): Loss: 0.0036 || Timer: 1.9289 sec.\n","===> Epoch[49](3/25): Loss: 0.0034 || Timer: 1.9357 sec.\n","===> Epoch[49](4/25): Loss: 0.0017 || Timer: 1.9410 sec.\n","===> Epoch[49](5/25): Loss: 0.0043 || Timer: 1.9387 sec.\n","===> Epoch[49](6/25): Loss: 0.0061 || Timer: 1.9289 sec.\n","===> Epoch[49](7/25): Loss: 0.0022 || Timer: 1.9418 sec.\n","===> Epoch[49](8/25): Loss: 0.0032 || Timer: 1.9300 sec.\n","===> Epoch[49](9/25): Loss: 0.0053 || Timer: 1.9353 sec.\n","===> Epoch[49](10/25): Loss: 0.0059 || Timer: 1.9296 sec.\n","===> Epoch[49](11/25): Loss: 0.0024 || Timer: 1.9531 sec.\n","===> Epoch[49](12/25): Loss: 0.0047 || Timer: 1.9276 sec.\n","===> Epoch[49](13/25): Loss: 0.0045 || Timer: 1.9344 sec.\n","===> Epoch[49](14/25): Loss: 0.0029 || Timer: 1.9277 sec.\n","===> Epoch[49](15/25): Loss: 0.0022 || Timer: 1.9336 sec.\n","===> Epoch[49](16/25): Loss: 0.0025 || Timer: 1.9302 sec.\n","===> Epoch[49](17/25): Loss: 0.0037 || Timer: 1.9358 sec.\n","===> Epoch[49](18/25): Loss: 0.0025 || Timer: 1.9283 sec.\n","===> Epoch[49](19/25): Loss: 0.0027 || Timer: 1.9473 sec.\n","===> Epoch[49](20/25): Loss: 0.0013 || Timer: 1.9283 sec.\n","===> Epoch[49](21/25): Loss: 0.0029 || Timer: 1.9336 sec.\n","===> Epoch[49](22/25): Loss: 0.0027 || Timer: 1.9283 sec.\n","===> Epoch[49](23/25): Loss: 0.0034 || Timer: 1.9353 sec.\n","===> Epoch[49](24/25): Loss: 0.0027 || Timer: 1.9280 sec.\n","===> Epoch[49](25/25): Loss: 0.0029 || Timer: 1.9341 sec.\n","===> Epoch 49 Complete: Avg. Loss: 0.0033\n","===> Epoch[50](1/25): Loss: 0.0022 || Timer: 1.9464 sec.\n","===> Epoch[50](2/25): Loss: 0.0027 || Timer: 1.9296 sec.\n","===> Epoch[50](3/25): Loss: 0.0032 || Timer: 1.9340 sec.\n","===> Epoch[50](4/25): Loss: 0.0030 || Timer: 1.9314 sec.\n","===> Epoch[50](5/25): Loss: 0.0020 || Timer: 1.9330 sec.\n","===> Epoch[50](6/25): Loss: 0.0024 || Timer: 1.9338 sec.\n","===> Epoch[50](7/25): Loss: 0.0017 || Timer: 1.9326 sec.\n","===> Epoch[50](8/25): Loss: 0.0025 || Timer: 1.9522 sec.\n","===> Epoch[50](9/25): Loss: 0.0017 || Timer: 1.9326 sec.\n","===> Epoch[50](10/25): Loss: 0.0019 || Timer: 1.9307 sec.\n","===> Epoch[50](11/25): Loss: 0.0017 || Timer: 1.9327 sec.\n","===> Epoch[50](12/25): Loss: 0.0028 || Timer: 1.9334 sec.\n","===> Epoch[50](13/25): Loss: 0.0023 || Timer: 1.9329 sec.\n","===> Epoch[50](14/25): Loss: 0.0018 || Timer: 1.9353 sec.\n","===> Epoch[50](15/25): Loss: 0.0023 || Timer: 1.9324 sec.\n","===> Epoch[50](16/25): Loss: 0.0014 || Timer: 1.9408 sec.\n","===> Epoch[50](17/25): Loss: 0.0021 || Timer: 1.9333 sec.\n","===> Epoch[50](18/25): Loss: 0.0018 || Timer: 1.9300 sec.\n","===> Epoch[50](19/25): Loss: 0.0018 || Timer: 1.9325 sec.\n","===> Epoch[50](20/25): Loss: 0.0012 || Timer: 1.9328 sec.\n","===> Epoch[50](21/25): Loss: 0.0013 || Timer: 1.9324 sec.\n","===> Epoch[50](22/25): Loss: 0.0023 || Timer: 1.9288 sec.\n","===> Epoch[50](23/25): Loss: 0.0014 || Timer: 1.9312 sec.\n","===> Epoch[50](24/25): Loss: 0.0021 || Timer: 1.9492 sec.\n","===> Epoch[50](25/25): Loss: 0.0024 || Timer: 1.9331 sec.\n","===> Epoch 50 Complete: Avg. Loss: 0.0021\n","Checkpoint saved to /content/gdrive/My Drive/졸업논문/졸업논문/scale=2/weights_scale=2/WCNN_epoch_50.pth\n","===> Epoch[51](1/25): Loss: 0.0031 || Timer: 1.9570 sec.\n","===> Epoch[51](2/25): Loss: 0.0024 || Timer: 1.9342 sec.\n","===> Epoch[51](3/25): Loss: 0.0022 || Timer: 1.9299 sec.\n","===> Epoch[51](4/25): Loss: 0.0019 || Timer: 1.9344 sec.\n","===> Epoch[51](5/25): Loss: 0.0017 || Timer: 1.9287 sec.\n","===> Epoch[51](6/25): Loss: 0.0011 || Timer: 1.9537 sec.\n","===> Epoch[51](7/25): Loss: 0.0022 || Timer: 1.9306 sec.\n","===> Epoch[51](8/25): Loss: 0.0028 || Timer: 1.9345 sec.\n","===> Epoch[51](9/25): Loss: 0.0017 || Timer: 1.9286 sec.\n","===> Epoch[51](10/25): Loss: 0.0025 || Timer: 1.9349 sec.\n","===> Epoch[51](11/25): Loss: 0.0014 || Timer: 1.9279 sec.\n","===> Epoch[51](12/25): Loss: 0.0014 || Timer: 1.9352 sec.\n","===> Epoch[51](13/25): Loss: 0.0021 || Timer: 1.9295 sec.\n","===> Epoch[51](14/25): Loss: 0.0018 || Timer: 1.9489 sec.\n","===> Epoch[51](15/25): Loss: 0.0018 || Timer: 1.9284 sec.\n","===> Epoch[51](16/25): Loss: 0.0017 || Timer: 1.9351 sec.\n","===> Epoch[51](17/25): Loss: 0.0016 || Timer: 1.9303 sec.\n","===> Epoch[51](18/25): Loss: 0.0020 || Timer: 1.9346 sec.\n","===> Epoch[51](19/25): Loss: 0.0007 || Timer: 1.9299 sec.\n","===> Epoch[51](20/25): Loss: 0.0017 || Timer: 1.9345 sec.\n","===> Epoch[51](21/25): Loss: 0.0027 || Timer: 1.9425 sec.\n","===> Epoch[51](22/25): Loss: 0.0021 || Timer: 1.9358 sec.\n","===> Epoch[51](23/25): Loss: 0.0025 || Timer: 1.9292 sec.\n","===> Epoch[51](24/25): Loss: 0.0025 || Timer: 1.9356 sec.\n","===> Epoch[51](25/25): Loss: 0.0020 || Timer: 1.9288 sec.\n","===> Epoch 51 Complete: Avg. Loss: 0.0020\n","===> Epoch[52](1/25): Loss: 0.0016 || Timer: 1.9618 sec.\n","===> Epoch[52](2/25): Loss: 0.0017 || Timer: 1.9327 sec.\n","===> Epoch[52](3/25): Loss: 0.0020 || Timer: 1.9519 sec.\n","===> Epoch[52](4/25): Loss: 0.0022 || Timer: 1.9330 sec.\n","===> Epoch[52](5/25): Loss: 0.0014 || Timer: 1.9291 sec.\n","===> Epoch[52](6/25): Loss: 0.0018 || Timer: 1.9326 sec.\n","===> Epoch[52](7/25): Loss: 0.0014 || Timer: 1.9300 sec.\n","===> Epoch[52](8/25): Loss: 0.0023 || Timer: 1.9343 sec.\n","===> Epoch[52](9/25): Loss: 0.0026 || Timer: 1.9300 sec.\n","===> Epoch[52](10/25): Loss: 0.0016 || Timer: 1.9343 sec.\n","===> Epoch[52](11/25): Loss: 0.0014 || Timer: 1.9501 sec.\n","===> Epoch[52](12/25): Loss: 0.0011 || Timer: 1.9316 sec.\n","===> Epoch[52](13/25): Loss: 0.0014 || Timer: 1.9281 sec.\n","===> Epoch[52](14/25): Loss: 0.0016 || Timer: 1.9332 sec.\n","===> Epoch[52](15/25): Loss: 0.0023 || Timer: 1.9297 sec.\n","===> Epoch[52](16/25): Loss: 0.0018 || Timer: 1.9344 sec.\n","===> Epoch[52](17/25): Loss: 0.0018 || Timer: 1.9302 sec.\n","===> Epoch[52](18/25): Loss: 0.0021 || Timer: 1.9323 sec.\n","===> Epoch[52](19/25): Loss: 0.0018 || Timer: 1.9388 sec.\n","===> Epoch[52](20/25): Loss: 0.0016 || Timer: 1.9318 sec.\n","===> Epoch[52](21/25): Loss: 0.0012 || Timer: 1.9290 sec.\n","===> Epoch[52](22/25): Loss: 0.0015 || Timer: 1.9318 sec.\n","===> Epoch[52](23/25): Loss: 0.0018 || Timer: 1.9287 sec.\n","===> Epoch[52](24/25): Loss: 0.0011 || Timer: 1.9332 sec.\n","===> Epoch[52](25/25): Loss: 0.0019 || Timer: 1.9295 sec.\n","===> Epoch 52 Complete: Avg. Loss: 0.0017\n","===> Epoch[53](1/25): Loss: 0.0009 || Timer: 1.9565 sec.\n","===> Epoch[53](2/25): Loss: 0.0012 || Timer: 1.9282 sec.\n","===> Epoch[53](3/25): Loss: 0.0022 || Timer: 1.9358 sec.\n","===> Epoch[53](4/25): Loss: 0.0019 || Timer: 1.9283 sec.\n","===> Epoch[53](5/25): Loss: 0.0015 || Timer: 1.9321 sec.\n","===> Epoch[53](6/25): Loss: 0.0017 || Timer: 1.9281 sec.\n","===> Epoch[53](7/25): Loss: 0.0016 || Timer: 1.9334 sec.\n","===> Epoch[53](8/25): Loss: 0.0018 || Timer: 1.9517 sec.\n","===> Epoch[53](9/25): Loss: 0.0026 || Timer: 1.9334 sec.\n","===> Epoch[53](10/25): Loss: 0.0020 || Timer: 1.9304 sec.\n","===> Epoch[53](11/25): Loss: 0.0020 || Timer: 1.9343 sec.\n","===> Epoch[53](12/25): Loss: 0.0016 || Timer: 1.9281 sec.\n","===> Epoch[53](13/25): Loss: 0.0019 || Timer: 1.9328 sec.\n","===> Epoch[53](14/25): Loss: 0.0019 || Timer: 1.9289 sec.\n","===> Epoch[53](15/25): Loss: 0.0015 || Timer: 1.9330 sec.\n","===> Epoch[53](16/25): Loss: 0.0022 || Timer: 1.9361 sec.\n","===> Epoch[53](17/25): Loss: 0.0020 || Timer: 1.9354 sec.\n","===> Epoch[53](18/25): Loss: 0.0016 || Timer: 1.9287 sec.\n","===> Epoch[53](19/25): Loss: 0.0017 || Timer: 1.9347 sec.\n","===> Epoch[53](20/25): Loss: 0.0022 || Timer: 1.9298 sec.\n","===> Epoch[53](21/25): Loss: 0.0018 || Timer: 1.9348 sec.\n","===> Epoch[53](22/25): Loss: 0.0016 || Timer: 1.9280 sec.\n","===> Epoch[53](23/25): Loss: 0.0015 || Timer: 1.9355 sec.\n","===> Epoch[53](24/25): Loss: 0.0016 || Timer: 1.9496 sec.\n","===> Epoch[53](25/25): Loss: 0.0019 || Timer: 1.9353 sec.\n","===> Epoch 53 Complete: Avg. Loss: 0.0018\n","===> Epoch[54](1/25): Loss: 0.0016 || Timer: 1.9360 sec.\n","===> Epoch[54](2/25): Loss: 0.0028 || Timer: 1.9314 sec.\n","===> Epoch[54](3/25): Loss: 0.0011 || Timer: 1.9364 sec.\n","===> Epoch[54](4/25): Loss: 0.0026 || Timer: 1.9296 sec.\n","===> Epoch[54](5/25): Loss: 0.0014 || Timer: 1.9336 sec.\n","===> Epoch[54](6/25): Loss: 0.0019 || Timer: 1.9496 sec.\n","===> Epoch[54](7/25): Loss: 0.0016 || Timer: 1.9313 sec.\n","===> Epoch[54](8/25): Loss: 0.0019 || Timer: 1.9308 sec.\n","===> Epoch[54](9/25): Loss: 0.0017 || Timer: 1.9330 sec.\n","===> Epoch[54](10/25): Loss: 0.0022 || Timer: 1.9296 sec.\n","===> Epoch[54](11/25): Loss: 0.0018 || Timer: 1.9324 sec.\n","===> Epoch[54](12/25): Loss: 0.0018 || Timer: 1.9318 sec.\n","===> Epoch[54](13/25): Loss: 0.0015 || Timer: 1.9442 sec.\n","===> Epoch[54](14/25): Loss: 0.0021 || Timer: 1.9298 sec.\n","===> Epoch[54](15/25): Loss: 0.0016 || Timer: 1.9310 sec.\n","===> Epoch[54](16/25): Loss: 0.0025 || Timer: 1.9299 sec.\n","===> Epoch[54](17/25): Loss: 0.0017 || Timer: 1.9320 sec.\n","===> Epoch[54](18/25): Loss: 0.0018 || Timer: 1.9301 sec.\n","===> Epoch[54](19/25): Loss: 0.0015 || Timer: 1.9320 sec.\n","===> Epoch[54](20/25): Loss: 0.0020 || Timer: 1.9444 sec.\n","===> Epoch[54](21/25): Loss: 0.0012 || Timer: 1.9340 sec.\n","===> Epoch[54](22/25): Loss: 0.0011 || Timer: 1.9290 sec.\n","===> Epoch[54](23/25): Loss: 0.0016 || Timer: 1.9314 sec.\n","===> Epoch[54](24/25): Loss: 0.0015 || Timer: 1.9295 sec.\n","===> Epoch[54](25/25): Loss: 0.0017 || Timer: 1.9325 sec.\n","===> Epoch 54 Complete: Avg. Loss: 0.0018\n","===> Epoch[55](1/25): Loss: 0.0016 || Timer: 1.9474 sec.\n","===> Epoch[55](2/25): Loss: 0.0019 || Timer: 1.9593 sec.\n","===> Epoch[55](3/25): Loss: 0.0017 || Timer: 1.9284 sec.\n","===> Epoch[55](4/25): Loss: 0.0020 || Timer: 1.9357 sec.\n","===> Epoch[55](5/25): Loss: 0.0019 || Timer: 1.9290 sec.\n","===> Epoch[55](6/25): Loss: 0.0018 || Timer: 1.9333 sec.\n","===> Epoch[55](7/25): Loss: 0.0020 || Timer: 1.9270 sec.\n","===> Epoch[55](8/25): Loss: 0.0016 || Timer: 1.9340 sec.\n","===> Epoch[55](9/25): Loss: 0.0011 || Timer: 1.9289 sec.\n","===> Epoch[55](10/25): Loss: 0.0020 || Timer: 1.9488 sec.\n","===> Epoch[55](11/25): Loss: 0.0013 || Timer: 1.9294 sec.\n","===> Epoch[55](12/25): Loss: 0.0025 || Timer: 1.9338 sec.\n","===> Epoch[55](13/25): Loss: 0.0013 || Timer: 1.9313 sec.\n","===> Epoch[55](14/25): Loss: 0.0017 || Timer: 1.9380 sec.\n","===> Epoch[55](15/25): Loss: 0.0017 || Timer: 1.9293 sec.\n","===> Epoch[55](16/25): Loss: 0.0024 || Timer: 1.9361 sec.\n","===> Epoch[55](17/25): Loss: 0.0031 || Timer: 1.9278 sec.\n","===> Epoch[55](18/25): Loss: 0.0037 || Timer: 1.9460 sec.\n","===> Epoch[55](19/25): Loss: 0.0014 || Timer: 1.9282 sec.\n","===> Epoch[55](20/25): Loss: 0.0042 || Timer: 1.9344 sec.\n","===> Epoch[55](21/25): Loss: 0.0070 || Timer: 1.9290 sec.\n","===> Epoch[55](22/25): Loss: 0.0014 || Timer: 1.9350 sec.\n","===> Epoch[55](23/25): Loss: 0.0043 || Timer: 1.9296 sec.\n","===> Epoch[55](24/25): Loss: 0.0060 || Timer: 1.9341 sec.\n","===> Epoch[55](25/25): Loss: 0.0016 || Timer: 1.9291 sec.\n","===> Epoch 55 Complete: Avg. Loss: 0.0024\n","===> Epoch[56](1/25): Loss: 0.0062 || Timer: 1.9454 sec.\n","===> Epoch[56](2/25): Loss: 0.0058 || Timer: 1.9325 sec.\n","===> Epoch[56](3/25): Loss: 0.0023 || Timer: 1.9321 sec.\n","===> Epoch[56](4/25): Loss: 0.0049 || Timer: 1.9329 sec.\n","===> Epoch[56](5/25): Loss: 0.0022 || Timer: 1.9296 sec.\n","===> Epoch[56](6/25): Loss: 0.0043 || Timer: 1.9327 sec.\n","===> Epoch[56](7/25): Loss: 0.0020 || Timer: 1.9288 sec.\n","===> Epoch[56](8/25): Loss: 0.0031 || Timer: 1.9510 sec.\n","===> Epoch[56](9/25): Loss: 0.0019 || Timer: 1.9299 sec.\n","===> Epoch[56](10/25): Loss: 0.0027 || Timer: 1.9356 sec.\n","===> Epoch[56](11/25): Loss: 0.0028 || Timer: 1.9298 sec.\n","===> Epoch[56](12/25): Loss: 0.0033 || Timer: 1.9305 sec.\n","===> Epoch[56](13/25): Loss: 0.0019 || Timer: 1.9302 sec.\n","===> Epoch[56](14/25): Loss: 0.0039 || Timer: 1.9323 sec.\n","===> Epoch[56](15/25): Loss: 0.0026 || Timer: 1.9297 sec.\n","===> Epoch[56](16/25): Loss: 0.0028 || Timer: 1.9475 sec.\n","===> Epoch[56](17/25): Loss: 0.0043 || Timer: 1.9318 sec.\n","===> Epoch[56](18/25): Loss: 0.0016 || Timer: 1.9323 sec.\n","===> Epoch[56](19/25): Loss: 0.0033 || Timer: 1.9308 sec.\n","===> Epoch[56](20/25): Loss: 0.0027 || Timer: 1.9324 sec.\n","===> Epoch[56](21/25): Loss: 0.0030 || Timer: 1.9340 sec.\n","===> Epoch[56](22/25): Loss: 0.0026 || Timer: 1.9356 sec.\n","===> Epoch[56](23/25): Loss: 0.0018 || Timer: 1.9289 sec.\n","===> Epoch[56](24/25): Loss: 0.0024 || Timer: 1.9542 sec.\n","===> Epoch[56](25/25): Loss: 0.0019 || Timer: 1.9292 sec.\n","===> Epoch 56 Complete: Avg. Loss: 0.0031\n","===> Epoch[57](1/25): Loss: 0.0024 || Timer: 1.9511 sec.\n","===> Epoch[57](2/25): Loss: 0.0022 || Timer: 1.9313 sec.\n","===> Epoch[57](3/25): Loss: 0.0018 || Timer: 1.9354 sec.\n","===> Epoch[57](4/25): Loss: 0.0017 || Timer: 1.9313 sec.\n","===> Epoch[57](5/25): Loss: 0.0022 || Timer: 1.9349 sec.\n","===> Epoch[57](6/25): Loss: 0.0020 || Timer: 1.9494 sec.\n","===> Epoch[57](7/25): Loss: 0.0023 || Timer: 1.9352 sec.\n","===> Epoch[57](8/25): Loss: 0.0010 || Timer: 1.9331 sec.\n","===> Epoch[57](9/25): Loss: 0.0027 || Timer: 1.9348 sec.\n","===> Epoch[57](10/25): Loss: 0.0016 || Timer: 1.9292 sec.\n","===> Epoch[57](11/25): Loss: 0.0014 || Timer: 1.9346 sec.\n","===> Epoch[57](12/25): Loss: 0.0014 || Timer: 1.9291 sec.\n","===> Epoch[57](13/25): Loss: 0.0016 || Timer: 1.9362 sec.\n","===> Epoch[57](14/25): Loss: 0.0017 || Timer: 1.9422 sec.\n","===> Epoch[57](15/25): Loss: 0.0030 || Timer: 1.9335 sec.\n","===> Epoch[57](16/25): Loss: 0.0021 || Timer: 1.9292 sec.\n","===> Epoch[57](17/25): Loss: 0.0014 || Timer: 1.9336 sec.\n","===> Epoch[57](18/25): Loss: 0.0021 || Timer: 1.9306 sec.\n","===> Epoch[57](19/25): Loss: 0.0015 || Timer: 1.9347 sec.\n","===> Epoch[57](20/25): Loss: 0.0018 || Timer: 1.9290 sec.\n","===> Epoch[57](21/25): Loss: 0.0020 || Timer: 1.9579 sec.\n","===> Epoch[57](22/25): Loss: 0.0015 || Timer: 1.9286 sec.\n","===> Epoch[57](23/25): Loss: 0.0014 || Timer: 1.9338 sec.\n","===> Epoch[57](24/25): Loss: 0.0014 || Timer: 1.9276 sec.\n","===> Epoch[57](25/25): Loss: 0.0021 || Timer: 1.9339 sec.\n","===> Epoch 57 Complete: Avg. Loss: 0.0019\n","===> Epoch[58](1/25): Loss: 0.0011 || Timer: 1.9447 sec.\n","===> Epoch[58](2/25): Loss: 0.0023 || Timer: 1.9298 sec.\n","===> Epoch[58](3/25): Loss: 0.0014 || Timer: 1.9441 sec.\n","===> Epoch[58](4/25): Loss: 0.0016 || Timer: 1.9316 sec.\n","===> Epoch[58](5/25): Loss: 0.0015 || Timer: 1.9323 sec.\n","===> Epoch[58](6/25): Loss: 0.0020 || Timer: 1.9293 sec.\n","===> Epoch[58](7/25): Loss: 0.0020 || Timer: 1.9308 sec.\n","===> Epoch[58](8/25): Loss: 0.0014 || Timer: 1.9294 sec.\n","===> Epoch[58](9/25): Loss: 0.0018 || Timer: 1.9310 sec.\n","===> Epoch[58](10/25): Loss: 0.0017 || Timer: 1.9433 sec.\n","===> Epoch[58](11/25): Loss: 0.0017 || Timer: 1.9326 sec.\n","===> Epoch[58](12/25): Loss: 0.0011 || Timer: 1.9284 sec.\n","===> Epoch[58](13/25): Loss: 0.0022 || Timer: 1.9323 sec.\n","===> Epoch[58](14/25): Loss: 0.0033 || Timer: 1.9292 sec.\n","===> Epoch[58](15/25): Loss: 0.0016 || Timer: 1.9329 sec.\n","===> Epoch[58](16/25): Loss: 0.0011 || Timer: 1.9312 sec.\n","===> Epoch[58](17/25): Loss: 0.0021 || Timer: 1.9321 sec.\n","===> Epoch[58](18/25): Loss: 0.0016 || Timer: 1.9516 sec.\n","===> Epoch[58](19/25): Loss: 0.0016 || Timer: 1.9317 sec.\n","===> Epoch[58](20/25): Loss: 0.0018 || Timer: 1.9306 sec.\n","===> Epoch[58](21/25): Loss: 0.0015 || Timer: 1.9335 sec.\n","===> Epoch[58](22/25): Loss: 0.0013 || Timer: 1.9292 sec.\n","===> Epoch[58](23/25): Loss: 0.0017 || Timer: 1.9325 sec.\n","===> Epoch[58](24/25): Loss: 0.0013 || Timer: 1.9292 sec.\n","===> Epoch[58](25/25): Loss: 0.0023 || Timer: 1.9334 sec.\n","===> Epoch 58 Complete: Avg. Loss: 0.0017\n","===> Epoch[59](1/25): Loss: 0.0017 || Timer: 1.9528 sec.\n","===> Epoch[59](2/25): Loss: 0.0021 || Timer: 1.9346 sec.\n","===> Epoch[59](3/25): Loss: 0.0020 || Timer: 1.9295 sec.\n","===> Epoch[59](4/25): Loss: 0.0012 || Timer: 1.9342 sec.\n","===> Epoch[59](5/25): Loss: 0.0012 || Timer: 1.9311 sec.\n","===> Epoch[59](6/25): Loss: 0.0010 || Timer: 1.9357 sec.\n","===> Epoch[59](7/25): Loss: 0.0017 || Timer: 1.9287 sec.\n","===> Epoch[59](8/25): Loss: 0.0022 || Timer: 1.9469 sec.\n","===> Epoch[59](9/25): Loss: 0.0023 || Timer: 1.9290 sec.\n","===> Epoch[59](10/25): Loss: 0.0017 || Timer: 1.9348 sec.\n","===> Epoch[59](11/25): Loss: 0.0016 || Timer: 1.9288 sec.\n","===> Epoch[59](12/25): Loss: 0.0022 || Timer: 1.9343 sec.\n","===> Epoch[59](13/25): Loss: 0.0011 || Timer: 1.9288 sec.\n","===> Epoch[59](14/25): Loss: 0.0014 || Timer: 1.9433 sec.\n","===> Epoch[59](15/25): Loss: 0.0015 || Timer: 1.9449 sec.\n","===> Epoch[59](16/25): Loss: 0.0021 || Timer: 1.9358 sec.\n","===> Epoch[59](17/25): Loss: 0.0016 || Timer: 1.9277 sec.\n","===> Epoch[59](18/25): Loss: 0.0020 || Timer: 1.9360 sec.\n","===> Epoch[59](19/25): Loss: 0.0016 || Timer: 1.9289 sec.\n","===> Epoch[59](20/25): Loss: 0.0009 || Timer: 1.9355 sec.\n","===> Epoch[59](21/25): Loss: 0.0007 || Timer: 1.9289 sec.\n","===> Epoch[59](22/25): Loss: 0.0013 || Timer: 1.9569 sec.\n","===> Epoch[59](23/25): Loss: 0.0021 || Timer: 1.9293 sec.\n","===> Epoch[59](24/25): Loss: 0.0014 || Timer: 1.9367 sec.\n","===> Epoch[59](25/25): Loss: 0.0014 || Timer: 1.9288 sec.\n","===> Epoch 59 Complete: Avg. Loss: 0.0016\n","===> Epoch[60](1/25): Loss: 0.0015 || Timer: 1.9360 sec.\n","===> Epoch[60](2/25): Loss: 0.0010 || Timer: 1.9329 sec.\n","===> Epoch[60](3/25): Loss: 0.0014 || Timer: 1.9302 sec.\n","===> Epoch[60](4/25): Loss: 0.0013 || Timer: 1.9530 sec.\n","===> Epoch[60](5/25): Loss: 0.0022 || Timer: 1.9302 sec.\n","===> Epoch[60](6/25): Loss: 0.0010 || Timer: 1.9344 sec.\n","===> Epoch[60](7/25): Loss: 0.0013 || Timer: 1.9296 sec.\n","===> Epoch[60](8/25): Loss: 0.0018 || Timer: 1.9335 sec.\n","===> Epoch[60](9/25): Loss: 0.0015 || Timer: 1.9298 sec.\n","===> Epoch[60](10/25): Loss: 0.0014 || Timer: 1.9340 sec.\n","===> Epoch[60](11/25): Loss: 0.0017 || Timer: 1.9303 sec.\n","===> Epoch[60](12/25): Loss: 0.0014 || Timer: 1.9473 sec.\n","===> Epoch[60](13/25): Loss: 0.0012 || Timer: 1.9298 sec.\n","===> Epoch[60](14/25): Loss: 0.0014 || Timer: 1.9339 sec.\n","===> Epoch[60](15/25): Loss: 0.0018 || Timer: 1.9314 sec.\n","===> Epoch[60](16/25): Loss: 0.0020 || Timer: 1.9323 sec.\n","===> Epoch[60](17/25): Loss: 0.0021 || Timer: 1.9306 sec.\n","===> Epoch[60](18/25): Loss: 0.0024 || Timer: 1.9327 sec.\n","===> Epoch[60](19/25): Loss: 0.0018 || Timer: 1.9299 sec.\n","===> Epoch[60](20/25): Loss: 0.0016 || Timer: 1.9429 sec.\n","===> Epoch[60](21/25): Loss: 0.0012 || Timer: 1.9291 sec.\n","===> Epoch[60](22/25): Loss: 0.0017 || Timer: 1.9319 sec.\n","===> Epoch[60](23/25): Loss: 0.0014 || Timer: 1.9302 sec.\n","===> Epoch[60](24/25): Loss: 0.0012 || Timer: 1.9356 sec.\n","===> Epoch[60](25/25): Loss: 0.0015 || Timer: 1.9295 sec.\n","===> Epoch 60 Complete: Avg. Loss: 0.0016\n","Checkpoint saved to /content/gdrive/My Drive/졸업논문/졸업논문/scale=2/weights_scale=2/WCNN_epoch_60.pth\n","===> Epoch[61](1/25): Loss: 0.0015 || Timer: 1.9512 sec.\n","===> Epoch[61](2/25): Loss: 0.0019 || Timer: 1.9459 sec.\n","===> Epoch[61](3/25): Loss: 0.0024 || Timer: 1.9325 sec.\n","===> Epoch[61](4/25): Loss: 0.0008 || Timer: 1.9302 sec.\n","===> Epoch[61](5/25): Loss: 0.0017 || Timer: 1.9388 sec.\n","===> Epoch[61](6/25): Loss: 0.0013 || Timer: 1.9297 sec.\n","===> Epoch[61](7/25): Loss: 0.0012 || Timer: 1.9341 sec.\n","===> Epoch[61](8/25): Loss: 0.0017 || Timer: 1.9300 sec.\n","===> Epoch[61](9/25): Loss: 0.0017 || Timer: 1.9496 sec.\n","===> Epoch[61](10/25): Loss: 0.0025 || Timer: 1.9297 sec.\n","===> Epoch[61](11/25): Loss: 0.0015 || Timer: 1.9330 sec.\n","===> Epoch[61](12/25): Loss: 0.0014 || Timer: 1.9293 sec.\n","===> Epoch[61](13/25): Loss: 0.0014 || Timer: 1.9345 sec.\n","===> Epoch[61](14/25): Loss: 0.0011 || Timer: 1.9285 sec.\n","===> Epoch[61](15/25): Loss: 0.0019 || Timer: 1.9361 sec.\n","===> Epoch[61](16/25): Loss: 0.0012 || Timer: 1.9493 sec.\n","===> Epoch[61](17/25): Loss: 0.0018 || Timer: 1.9354 sec.\n","===> Epoch[61](18/25): Loss: 0.0022 || Timer: 1.9296 sec.\n","===> Epoch[61](19/25): Loss: 0.0010 || Timer: 1.9353 sec.\n","===> Epoch[61](20/25): Loss: 0.0009 || Timer: 1.9291 sec.\n","===> Epoch[61](21/25): Loss: 0.0017 || Timer: 1.9348 sec.\n","===> Epoch[61](22/25): Loss: 0.0023 || Timer: 1.9291 sec.\n","===> Epoch[61](23/25): Loss: 0.0013 || Timer: 1.9348 sec.\n","===> Epoch[61](24/25): Loss: 0.0020 || Timer: 1.9450 sec.\n","===> Epoch[61](25/25): Loss: 0.0020 || Timer: 1.9349 sec.\n","===> Epoch 61 Complete: Avg. Loss: 0.0016\n","===> Epoch[62](1/25): Loss: 0.0012 || Timer: 1.9455 sec.\n","===> Epoch[62](2/25): Loss: 0.0025 || Timer: 1.9297 sec.\n","===> Epoch[62](3/25): Loss: 0.0010 || Timer: 1.9324 sec.\n","===> Epoch[62](4/25): Loss: 0.0020 || Timer: 1.9297 sec.\n","===> Epoch[62](5/25): Loss: 0.0027 || Timer: 1.9331 sec.\n","===> Epoch[62](6/25): Loss: 0.0012 || Timer: 1.9431 sec.\n","===> Epoch[62](7/25): Loss: 0.0011 || Timer: 1.9316 sec.\n","===> Epoch[62](8/25): Loss: 0.0011 || Timer: 1.9318 sec.\n","===> Epoch[62](9/25): Loss: 0.0017 || Timer: 1.9325 sec.\n","===> Epoch[62](10/25): Loss: 0.0015 || Timer: 1.9302 sec.\n","===> Epoch[62](11/25): Loss: 0.0016 || Timer: 1.9338 sec.\n","===> Epoch[62](12/25): Loss: 0.0017 || Timer: 1.9305 sec.\n","===> Epoch[62](13/25): Loss: 0.0016 || Timer: 1.9322 sec.\n","===> Epoch[62](14/25): Loss: 0.0016 || Timer: 1.9468 sec.\n","===> Epoch[62](15/25): Loss: 0.0012 || Timer: 1.9322 sec.\n","===> Epoch[62](16/25): Loss: 0.0018 || Timer: 1.9290 sec.\n","===> Epoch[62](17/25): Loss: 0.0014 || Timer: 1.9316 sec.\n","===> Epoch[62](18/25): Loss: 0.0019 || Timer: 1.9288 sec.\n","===> Epoch[62](19/25): Loss: 0.0016 || Timer: 1.9301 sec.\n","===> Epoch[62](20/25): Loss: 0.0017 || Timer: 1.9287 sec.\n","===> Epoch[62](21/25): Loss: 0.0019 || Timer: 1.9517 sec.\n","===> Epoch[62](22/25): Loss: 0.0020 || Timer: 1.9304 sec.\n","===> Epoch[62](23/25): Loss: 0.0013 || Timer: 1.9306 sec.\n","===> Epoch[62](24/25): Loss: 0.0020 || Timer: 1.9304 sec.\n","===> Epoch[62](25/25): Loss: 0.0016 || Timer: 1.9313 sec.\n","===> Epoch 62 Complete: Avg. Loss: 0.0016\n","===> Epoch[63](1/25): Loss: 0.0016 || Timer: 1.9350 sec.\n","===> Epoch[63](2/25): Loss: 0.0022 || Timer: 1.9379 sec.\n","===> Epoch[63](3/25): Loss: 0.0022 || Timer: 1.9510 sec.\n","===> Epoch[63](4/25): Loss: 0.0016 || Timer: 1.9347 sec.\n","===> Epoch[63](5/25): Loss: 0.0014 || Timer: 1.9289 sec.\n","===> Epoch[63](6/25): Loss: 0.0017 || Timer: 1.9335 sec.\n","===> Epoch[63](7/25): Loss: 0.0021 || Timer: 1.9284 sec.\n","===> Epoch[63](8/25): Loss: 0.0013 || Timer: 1.9343 sec.\n","===> Epoch[63](9/25): Loss: 0.0015 || Timer: 1.9287 sec.\n","===> Epoch[63](10/25): Loss: 0.0022 || Timer: 1.9577 sec.\n","===> Epoch[63](11/25): Loss: 0.0014 || Timer: 1.9295 sec.\n","===> Epoch[63](12/25): Loss: 0.0014 || Timer: 1.9342 sec.\n","===> Epoch[63](13/25): Loss: 0.0011 || Timer: 1.9290 sec.\n","===> Epoch[63](14/25): Loss: 0.0022 || Timer: 1.9338 sec.\n","===> Epoch[63](15/25): Loss: 0.0025 || Timer: 1.9288 sec.\n","===> Epoch[63](16/25): Loss: 0.0017 || Timer: 1.9351 sec.\n","===> Epoch[63](17/25): Loss: 0.0012 || Timer: 1.9305 sec.\n","===> Epoch[63](18/25): Loss: 0.0021 || Timer: 1.9550 sec.\n","===> Epoch[63](19/25): Loss: 0.0023 || Timer: 1.9296 sec.\n","===> Epoch[63](20/25): Loss: 0.0011 || Timer: 1.9355 sec.\n","===> Epoch[63](21/25): Loss: 0.0016 || Timer: 1.9278 sec.\n","===> Epoch[63](22/25): Loss: 0.0014 || Timer: 1.9346 sec.\n","===> Epoch[63](23/25): Loss: 0.0009 || Timer: 1.9288 sec.\n","===> Epoch[63](24/25): Loss: 0.0017 || Timer: 1.9352 sec.\n","===> Epoch[63](25/25): Loss: 0.0012 || Timer: 1.9292 sec.\n","===> Epoch 63 Complete: Avg. Loss: 0.0017\n","===> Epoch[64](1/25): Loss: 0.0013 || Timer: 1.9503 sec.\n","===> Epoch[64](2/25): Loss: 0.0019 || Timer: 1.9415 sec.\n","===> Epoch[64](3/25): Loss: 0.0018 || Timer: 1.9339 sec.\n","===> Epoch[64](4/25): Loss: 0.0025 || Timer: 1.9336 sec.\n","===> Epoch[64](5/25): Loss: 0.0016 || Timer: 1.9301 sec.\n","===> Epoch[64](6/25): Loss: 0.0021 || Timer: 1.9323 sec.\n","===> Epoch[64](7/25): Loss: 0.0019 || Timer: 1.9290 sec.\n","===> Epoch[64](8/25): Loss: 0.0017 || Timer: 1.9492 sec.\n","===> Epoch[64](9/25): Loss: 0.0018 || Timer: 1.9296 sec.\n","===> Epoch[64](10/25): Loss: 0.0019 || Timer: 1.9327 sec.\n","===> Epoch[64](11/25): Loss: 0.0023 || Timer: 1.9306 sec.\n","===> Epoch[64](12/25): Loss: 0.0012 || Timer: 1.9369 sec.\n","===> Epoch[64](13/25): Loss: 0.0017 || Timer: 1.9310 sec.\n","===> Epoch[64](14/25): Loss: 0.0014 || Timer: 1.9318 sec.\n","===> Epoch[64](15/25): Loss: 0.0016 || Timer: 1.9495 sec.\n","===> Epoch[64](16/25): Loss: 0.0020 || Timer: 1.9314 sec.\n","===> Epoch[64](17/25): Loss: 0.0021 || Timer: 1.9290 sec.\n","===> Epoch[64](18/25): Loss: 0.0011 || Timer: 1.9368 sec.\n","===> Epoch[64](19/25): Loss: 0.0026 || Timer: 1.9312 sec.\n","===> Epoch[64](20/25): Loss: 0.0021 || Timer: 1.9341 sec.\n","===> Epoch[64](21/25): Loss: 0.0017 || Timer: 1.9307 sec.\n","===> Epoch[64](22/25): Loss: 0.0011 || Timer: 1.9332 sec.\n","===> Epoch[64](23/25): Loss: 0.0016 || Timer: 1.9498 sec.\n","===> Epoch[64](24/25): Loss: 0.0020 || Timer: 1.9324 sec.\n","===> Epoch[64](25/25): Loss: 0.0016 || Timer: 1.9307 sec.\n","===> Epoch 64 Complete: Avg. Loss: 0.0018\n","===> Epoch[65](1/25): Loss: 0.0022 || Timer: 1.9435 sec.\n","===> Epoch[65](2/25): Loss: 0.0015 || Timer: 1.9309 sec.\n","===> Epoch[65](3/25): Loss: 0.0015 || Timer: 1.9338 sec.\n","===> Epoch[65](4/25): Loss: 0.0012 || Timer: 1.9280 sec.\n","===> Epoch[65](5/25): Loss: 0.0013 || Timer: 1.9559 sec.\n","===> Epoch[65](6/25): Loss: 0.0015 || Timer: 1.9288 sec.\n","===> Epoch[65](7/25): Loss: 0.0019 || Timer: 1.9348 sec.\n","===> Epoch[65](8/25): Loss: 0.0019 || Timer: 1.9287 sec.\n","===> Epoch[65](9/25): Loss: 0.0020 || Timer: 1.9340 sec.\n","===> Epoch[65](10/25): Loss: 0.0009 || Timer: 1.9283 sec.\n","===> Epoch[65](11/25): Loss: 0.0021 || Timer: 1.9343 sec.\n","===> Epoch[65](12/25): Loss: 0.0021 || Timer: 1.9288 sec.\n","===> Epoch[65](13/25): Loss: 0.0022 || Timer: 1.9495 sec.\n","===> Epoch[65](14/25): Loss: 0.0011 || Timer: 1.9291 sec.\n","===> Epoch[65](15/25): Loss: 0.0023 || Timer: 1.9353 sec.\n","===> Epoch[65](16/25): Loss: 0.0020 || Timer: 1.9282 sec.\n","===> Epoch[65](17/25): Loss: 0.0016 || Timer: 1.9336 sec.\n","===> Epoch[65](18/25): Loss: 0.0011 || Timer: 1.9285 sec.\n","===> Epoch[65](19/25): Loss: 0.0010 || Timer: 1.9355 sec.\n","===> Epoch[65](20/25): Loss: 0.0015 || Timer: 1.9448 sec.\n","===> Epoch[65](21/25): Loss: 0.0016 || Timer: 1.9337 sec.\n","===> Epoch[65](22/25): Loss: 0.0022 || Timer: 1.9290 sec.\n","===> Epoch[65](23/25): Loss: 0.0014 || Timer: 1.9343 sec.\n","===> Epoch[65](24/25): Loss: 0.0012 || Timer: 1.9300 sec.\n","===> Epoch[65](25/25): Loss: 0.0019 || Timer: 1.9353 sec.\n","===> Epoch 65 Complete: Avg. Loss: 0.0016\n","===> Epoch[66](1/25): Loss: 0.0017 || Timer: 1.9462 sec.\n","===> Epoch[66](2/25): Loss: 0.0019 || Timer: 1.9534 sec.\n","===> Epoch[66](3/25): Loss: 0.0012 || Timer: 1.9351 sec.\n","===> Epoch[66](4/25): Loss: 0.0012 || Timer: 1.9320 sec.\n","===> Epoch[66](5/25): Loss: 0.0017 || Timer: 1.9329 sec.\n","===> Epoch[66](6/25): Loss: 0.0011 || Timer: 1.9290 sec.\n","===> Epoch[66](7/25): Loss: 0.0019 || Timer: 1.9309 sec.\n","===> Epoch[66](8/25): Loss: 0.0022 || Timer: 1.9313 sec.\n","===> Epoch[66](9/25): Loss: 0.0022 || Timer: 1.9315 sec.\n","===> Epoch[66](10/25): Loss: 0.0018 || Timer: 1.9461 sec.\n","===> Epoch[66](11/25): Loss: 0.0025 || Timer: 1.9335 sec.\n","===> Epoch[66](12/25): Loss: 0.0016 || Timer: 1.9293 sec.\n","===> Epoch[66](13/25): Loss: 0.0021 || Timer: 1.9358 sec.\n","===> Epoch[66](14/25): Loss: 0.0023 || Timer: 1.9302 sec.\n","===> Epoch[66](15/25): Loss: 0.0024 || Timer: 1.9319 sec.\n","===> Epoch[66](16/25): Loss: 0.0039 || Timer: 1.9304 sec.\n","===> Epoch[66](17/25): Loss: 0.0031 || Timer: 1.9503 sec.\n","===> Epoch[66](18/25): Loss: 0.0012 || Timer: 1.9303 sec.\n","===> Epoch[66](19/25): Loss: 0.0025 || Timer: 1.9337 sec.\n","===> Epoch[66](20/25): Loss: 0.0025 || Timer: 1.9287 sec.\n","===> Epoch[66](21/25): Loss: 0.0027 || Timer: 1.9327 sec.\n","===> Epoch[66](22/25): Loss: 0.0022 || Timer: 1.9301 sec.\n","===> Epoch[66](23/25): Loss: 0.0031 || Timer: 1.9324 sec.\n","===> Epoch[66](24/25): Loss: 0.0023 || Timer: 1.9322 sec.\n","===> Epoch[66](25/25): Loss: 0.0018 || Timer: 1.9432 sec.\n","===> Epoch 66 Complete: Avg. Loss: 0.0021\n","===> Epoch[67](1/25): Loss: 0.0040 || Timer: 1.9408 sec.\n","===> Epoch[67](2/25): Loss: 0.0014 || Timer: 1.9365 sec.\n","===> Epoch[67](3/25): Loss: 0.0026 || Timer: 1.9293 sec.\n","===> Epoch[67](4/25): Loss: 0.0021 || Timer: 1.9362 sec.\n","===> Epoch[67](5/25): Loss: 0.0022 || Timer: 1.9281 sec.\n","===> Epoch[67](6/25): Loss: 0.0022 || Timer: 1.9398 sec.\n","===> Epoch[67](7/25): Loss: 0.0017 || Timer: 1.9528 sec.\n","===> Epoch[67](8/25): Loss: 0.0019 || Timer: 1.9350 sec.\n","===> Epoch[67](9/25): Loss: 0.0025 || Timer: 1.9308 sec.\n","===> Epoch[67](10/25): Loss: 0.0017 || Timer: 1.9351 sec.\n","===> Epoch[67](11/25): Loss: 0.0024 || Timer: 1.9297 sec.\n","===> Epoch[67](12/25): Loss: 0.0024 || Timer: 1.9355 sec.\n","===> Epoch[67](13/25): Loss: 0.0024 || Timer: 1.9283 sec.\n","===> Epoch[67](14/25): Loss: 0.0014 || Timer: 1.9362 sec.\n","===> Epoch[67](15/25): Loss: 0.0017 || Timer: 1.9431 sec.\n","===> Epoch[67](16/25): Loss: 0.0022 || Timer: 1.9367 sec.\n","===> Epoch[67](17/25): Loss: 0.0022 || Timer: 1.9287 sec.\n","===> Epoch[67](18/25): Loss: 0.0019 || Timer: 1.9350 sec.\n","===> Epoch[67](19/25): Loss: 0.0016 || Timer: 1.9299 sec.\n","===> Epoch[67](20/25): Loss: 0.0016 || Timer: 1.9343 sec.\n","===> Epoch[67](21/25): Loss: 0.0028 || Timer: 1.9321 sec.\n","===> Epoch[67](22/25): Loss: 0.0025 || Timer: 1.9376 sec.\n","===> Epoch[67](23/25): Loss: 0.0018 || Timer: 1.9504 sec.\n","===> Epoch[67](24/25): Loss: 0.0026 || Timer: 1.9367 sec.\n","===> Epoch[67](25/25): Loss: 0.0020 || Timer: 1.9301 sec.\n","===> Epoch 67 Complete: Avg. Loss: 0.0021\n","===> Epoch[68](1/25): Loss: 0.0021 || Timer: 1.9391 sec.\n","===> Epoch[68](2/25): Loss: 0.0031 || Timer: 1.9347 sec.\n","===> Epoch[68](3/25): Loss: 0.0019 || Timer: 1.9305 sec.\n","===> Epoch[68](4/25): Loss: 0.0012 || Timer: 1.9333 sec.\n","===> Epoch[68](5/25): Loss: 0.0020 || Timer: 1.9520 sec.\n","===> Epoch[68](6/25): Loss: 0.0019 || Timer: 1.9338 sec.\n","===> Epoch[68](7/25): Loss: 0.0025 || Timer: 1.9303 sec.\n","===> Epoch[68](8/25): Loss: 0.0013 || Timer: 1.9322 sec.\n","===> Epoch[68](9/25): Loss: 0.0023 || Timer: 1.9311 sec.\n","===> Epoch[68](10/25): Loss: 0.0017 || Timer: 1.9345 sec.\n","===> Epoch[68](11/25): Loss: 0.0016 || Timer: 1.9292 sec.\n","===> Epoch[68](12/25): Loss: 0.0013 || Timer: 1.9476 sec.\n","===> Epoch[68](13/25): Loss: 0.0010 || Timer: 1.9300 sec.\n","===> Epoch[68](14/25): Loss: 0.0017 || Timer: 1.9341 sec.\n","===> Epoch[68](15/25): Loss: 0.0015 || Timer: 1.9310 sec.\n","===> Epoch[68](16/25): Loss: 0.0020 || Timer: 1.9343 sec.\n","===> Epoch[68](17/25): Loss: 0.0019 || Timer: 1.9307 sec.\n","===> Epoch[68](18/25): Loss: 0.0019 || Timer: 1.9351 sec.\n","===> Epoch[68](19/25): Loss: 0.0013 || Timer: 1.9314 sec.\n","===> Epoch[68](20/25): Loss: 0.0025 || Timer: 1.9528 sec.\n","===> Epoch[68](21/25): Loss: 0.0015 || Timer: 1.9306 sec.\n","===> Epoch[68](22/25): Loss: 0.0016 || Timer: 1.9337 sec.\n","===> Epoch[68](23/25): Loss: 0.0014 || Timer: 1.9302 sec.\n","===> Epoch[68](24/25): Loss: 0.0018 || Timer: 1.9337 sec.\n","===> Epoch[68](25/25): Loss: 0.0014 || Timer: 1.9304 sec.\n","===> Epoch 68 Complete: Avg. Loss: 0.0018\n","===> Epoch[69](1/25): Loss: 0.0019 || Timer: 1.9435 sec.\n","===> Epoch[69](2/25): Loss: 0.0013 || Timer: 1.9505 sec.\n","===> Epoch[69](3/25): Loss: 0.0014 || Timer: 1.9359 sec.\n","===> Epoch[69](4/25): Loss: 0.0032 || Timer: 1.9304 sec.\n","===> Epoch[69](5/25): Loss: 0.0014 || Timer: 1.9341 sec.\n","===> Epoch[69](6/25): Loss: 0.0022 || Timer: 1.9321 sec.\n","===> Epoch[69](7/25): Loss: 0.0012 || Timer: 1.9345 sec.\n","===> Epoch[69](8/25): Loss: 0.0017 || Timer: 1.9302 sec.\n","===> Epoch[69](9/25): Loss: 0.0020 || Timer: 1.9566 sec.\n","===> Epoch[69](10/25): Loss: 0.0015 || Timer: 1.9309 sec.\n","===> Epoch[69](11/25): Loss: 0.0018 || Timer: 1.9355 sec.\n","===> Epoch[69](12/25): Loss: 0.0011 || Timer: 1.9299 sec.\n","===> Epoch[69](13/25): Loss: 0.0014 || Timer: 1.9349 sec.\n","===> Epoch[69](14/25): Loss: 0.0016 || Timer: 1.9311 sec.\n","===> Epoch[69](15/25): Loss: 0.0017 || Timer: 1.9337 sec.\n","===> Epoch[69](16/25): Loss: 0.0015 || Timer: 1.9283 sec.\n","===> Epoch[69](17/25): Loss: 0.0017 || Timer: 1.9502 sec.\n","===> Epoch[69](18/25): Loss: 0.0013 || Timer: 1.9307 sec.\n","===> Epoch[69](19/25): Loss: 0.0011 || Timer: 1.9345 sec.\n","===> Epoch[69](20/25): Loss: 0.0011 || Timer: 1.9296 sec.\n","===> Epoch[69](21/25): Loss: 0.0016 || Timer: 1.9342 sec.\n","===> Epoch[69](22/25): Loss: 0.0013 || Timer: 1.9291 sec.\n","===> Epoch[69](23/25): Loss: 0.0015 || Timer: 1.9346 sec.\n","===> Epoch[69](24/25): Loss: 0.0014 || Timer: 1.9308 sec.\n","===> Epoch[69](25/25): Loss: 0.0013 || Timer: 1.9545 sec.\n","===> Epoch 69 Complete: Avg. Loss: 0.0016\n","===> Epoch[70](1/25): Loss: 0.0024 || Timer: 1.9414 sec.\n","===> Epoch[70](2/25): Loss: 0.0010 || Timer: 1.9326 sec.\n","===> Epoch[70](3/25): Loss: 0.0020 || Timer: 1.9324 sec.\n","===> Epoch[70](4/25): Loss: 0.0013 || Timer: 1.9315 sec.\n","===> Epoch[70](5/25): Loss: 0.0020 || Timer: 1.9338 sec.\n","===> Epoch[70](6/25): Loss: 0.0013 || Timer: 1.9293 sec.\n","===> Epoch[70](7/25): Loss: 0.0019 || Timer: 1.9578 sec.\n","===> Epoch[70](8/25): Loss: 0.0017 || Timer: 1.9301 sec.\n","===> Epoch[70](9/25): Loss: 0.0018 || Timer: 1.9316 sec.\n","===> Epoch[70](10/25): Loss: 0.0010 || Timer: 1.9294 sec.\n","===> Epoch[70](11/25): Loss: 0.0015 || Timer: 1.9319 sec.\n","===> Epoch[70](12/25): Loss: 0.0021 || Timer: 1.9338 sec.\n","===> Epoch[70](13/25): Loss: 0.0017 || Timer: 1.9325 sec.\n","===> Epoch[70](14/25): Loss: 0.0017 || Timer: 1.9400 sec.\n","===> Epoch[70](15/25): Loss: 0.0017 || Timer: 1.9315 sec.\n","===> Epoch[70](16/25): Loss: 0.0018 || Timer: 1.9309 sec.\n","===> Epoch[70](17/25): Loss: 0.0021 || Timer: 1.9337 sec.\n","===> Epoch[70](18/25): Loss: 0.0014 || Timer: 1.9296 sec.\n","===> Epoch[70](19/25): Loss: 0.0017 || Timer: 1.9321 sec.\n","===> Epoch[70](20/25): Loss: 0.0010 || Timer: 1.9295 sec.\n","===> Epoch[70](21/25): Loss: 0.0011 || Timer: 1.9323 sec.\n","===> Epoch[70](22/25): Loss: 0.0015 || Timer: 1.9463 sec.\n","===> Epoch[70](23/25): Loss: 0.0010 || Timer: 1.9326 sec.\n","===> Epoch[70](24/25): Loss: 0.0012 || Timer: 1.9277 sec.\n","===> Epoch[70](25/25): Loss: 0.0023 || Timer: 1.9319 sec.\n","===> Epoch 70 Complete: Avg. Loss: 0.0016\n","Checkpoint saved to /content/gdrive/My Drive/졸업논문/졸업논문/scale=2/weights_scale=2/WCNN_epoch_70.pth\n","===> Epoch[71](1/25): Loss: 0.0012 || Timer: 1.9393 sec.\n","===> Epoch[71](2/25): Loss: 0.0016 || Timer: 1.9348 sec.\n","===> Epoch[71](3/25): Loss: 0.0017 || Timer: 1.9288 sec.\n","===> Epoch[71](4/25): Loss: 0.0015 || Timer: 1.9526 sec.\n","===> Epoch[71](5/25): Loss: 0.0017 || Timer: 1.9288 sec.\n","===> Epoch[71](6/25): Loss: 0.0015 || Timer: 1.9363 sec.\n","===> Epoch[71](7/25): Loss: 0.0016 || Timer: 1.9329 sec.\n","===> Epoch[71](8/25): Loss: 0.0010 || Timer: 1.9351 sec.\n","===> Epoch[71](9/25): Loss: 0.0011 || Timer: 1.9293 sec.\n","===> Epoch[71](10/25): Loss: 0.0020 || Timer: 1.9358 sec.\n","===> Epoch[71](11/25): Loss: 0.0010 || Timer: 1.9361 sec.\n","===> Epoch[71](12/25): Loss: 0.0014 || Timer: 1.9508 sec.\n","===> Epoch[71](13/25): Loss: 0.0011 || Timer: 1.9301 sec.\n","===> Epoch[71](14/25): Loss: 0.0033 || Timer: 1.9373 sec.\n","===> Epoch[71](15/25): Loss: 0.0018 || Timer: 1.9307 sec.\n","===> Epoch[71](16/25): Loss: 0.0020 || Timer: 1.9414 sec.\n","===> Epoch[71](17/25): Loss: 0.0019 || Timer: 1.9276 sec.\n","===> Epoch[71](18/25): Loss: 0.0018 || Timer: 1.9338 sec.\n","===> Epoch[71](19/25): Loss: 0.0034 || Timer: 1.9282 sec.\n","===> Epoch[71](20/25): Loss: 0.0029 || Timer: 1.9567 sec.\n","===> Epoch[71](21/25): Loss: 0.0019 || Timer: 1.9291 sec.\n","===> Epoch[71](22/25): Loss: 0.0013 || Timer: 1.9365 sec.\n","===> Epoch[71](23/25): Loss: 0.0016 || Timer: 1.9291 sec.\n","===> Epoch[71](24/25): Loss: 0.0012 || Timer: 1.9338 sec.\n","===> Epoch[71](25/25): Loss: 0.0016 || Timer: 1.9288 sec.\n","===> Epoch 71 Complete: Avg. Loss: 0.0017\n","===> Epoch[72](1/25): Loss: 0.0022 || Timer: 1.9353 sec.\n","===> Epoch[72](2/25): Loss: 0.0014 || Timer: 1.9525 sec.\n","===> Epoch[72](3/25): Loss: 0.0026 || Timer: 1.9281 sec.\n","===> Epoch[72](4/25): Loss: 0.0020 || Timer: 1.9321 sec.\n","===> Epoch[72](5/25): Loss: 0.0021 || Timer: 1.9314 sec.\n","===> Epoch[72](6/25): Loss: 0.0015 || Timer: 1.9323 sec.\n","===> Epoch[72](7/25): Loss: 0.0028 || Timer: 1.9298 sec.\n","===> Epoch[72](8/25): Loss: 0.0023 || Timer: 1.9318 sec.\n","===> Epoch[72](9/25): Loss: 0.0034 || Timer: 1.9424 sec.\n","===> Epoch[72](10/25): Loss: 0.0017 || Timer: 1.9318 sec.\n","===> Epoch[72](11/25): Loss: 0.0016 || Timer: 1.9296 sec.\n","===> Epoch[72](12/25): Loss: 0.0029 || Timer: 1.9319 sec.\n","===> Epoch[72](13/25): Loss: 0.0044 || Timer: 1.9292 sec.\n","===> Epoch[72](14/25): Loss: 0.0023 || Timer: 1.9331 sec.\n","===> Epoch[72](15/25): Loss: 0.0015 || Timer: 1.9300 sec.\n","===> Epoch[72](16/25): Loss: 0.0021 || Timer: 1.9336 sec.\n","===> Epoch[72](17/25): Loss: 0.0026 || Timer: 1.9514 sec.\n","===> Epoch[72](18/25): Loss: 0.0025 || Timer: 1.9329 sec.\n","===> Epoch[72](19/25): Loss: 0.0017 || Timer: 1.9291 sec.\n","===> Epoch[72](20/25): Loss: 0.0019 || Timer: 1.9308 sec.\n","===> Epoch[72](21/25): Loss: 0.0048 || Timer: 1.9296 sec.\n","===> Epoch[72](22/25): Loss: 0.0058 || Timer: 1.9323 sec.\n","===> Epoch[72](23/25): Loss: 0.0027 || Timer: 1.9323 sec.\n","===> Epoch[72](24/25): Loss: 0.0023 || Timer: 1.9423 sec.\n","===> Epoch[72](25/25): Loss: 0.0036 || Timer: 1.9296 sec.\n","===> Epoch 72 Complete: Avg. Loss: 0.0026\n","===> Epoch[73](1/25): Loss: 0.0021 || Timer: 1.9502 sec.\n","===> Epoch[73](2/25): Loss: 0.0039 || Timer: 1.9303 sec.\n","===> Epoch[73](3/25): Loss: 0.0027 || Timer: 1.9356 sec.\n","===> Epoch[73](4/25): Loss: 0.0021 || Timer: 1.9286 sec.\n","===> Epoch[73](5/25): Loss: 0.0041 || Timer: 1.9326 sec.\n","===> Epoch[73](6/25): Loss: 0.0033 || Timer: 1.9448 sec.\n","===> Epoch[73](7/25): Loss: 0.0017 || Timer: 1.9338 sec.\n","===> Epoch[73](8/25): Loss: 0.0028 || Timer: 1.9298 sec.\n","===> Epoch[73](9/25): Loss: 0.0044 || Timer: 1.9344 sec.\n","===> Epoch[73](10/25): Loss: 0.0021 || Timer: 1.9313 sec.\n","===> Epoch[73](11/25): Loss: 0.0027 || Timer: 1.9344 sec.\n","===> Epoch[73](12/25): Loss: 0.0028 || Timer: 1.9287 sec.\n","===> Epoch[73](13/25): Loss: 0.0025 || Timer: 1.9543 sec.\n","===> Epoch[73](14/25): Loss: 0.0028 || Timer: 1.9287 sec.\n","===> Epoch[73](15/25): Loss: 0.0023 || Timer: 1.9324 sec.\n","===> Epoch[73](16/25): Loss: 0.0021 || Timer: 1.9289 sec.\n","===> Epoch[73](17/25): Loss: 0.0026 || Timer: 1.9363 sec.\n","===> Epoch[73](18/25): Loss: 0.0022 || Timer: 1.9283 sec.\n","===> Epoch[73](19/25): Loss: 0.0021 || Timer: 1.9347 sec.\n","===> Epoch[73](20/25): Loss: 0.0022 || Timer: 1.9517 sec.\n","===> Epoch[73](21/25): Loss: 0.0026 || Timer: 1.9331 sec.\n","===> Epoch[73](22/25): Loss: 0.0019 || Timer: 1.9296 sec.\n","===> Epoch[73](23/25): Loss: 0.0044 || Timer: 1.9350 sec.\n","===> Epoch[73](24/25): Loss: 0.0035 || Timer: 1.9307 sec.\n","===> Epoch[73](25/25): Loss: 0.0020 || Timer: 1.9332 sec.\n","===> Epoch 73 Complete: Avg. Loss: 0.0027\n","===> Epoch[74](1/25): Loss: 0.0050 || Timer: 1.9411 sec.\n","===> Epoch[74](2/25): Loss: 0.0034 || Timer: 1.9496 sec.\n","===> Epoch[74](3/25): Loss: 0.0025 || Timer: 1.9329 sec.\n","===> Epoch[74](4/25): Loss: 0.0019 || Timer: 1.9291 sec.\n","===> Epoch[74](5/25): Loss: 0.0025 || Timer: 1.9340 sec.\n","===> Epoch[74](6/25): Loss: 0.0025 || Timer: 1.9304 sec.\n","===> Epoch[74](7/25): Loss: 0.0035 || Timer: 1.9309 sec.\n","===> Epoch[74](8/25): Loss: 0.0021 || Timer: 1.9289 sec.\n","===> Epoch[74](9/25): Loss: 0.0036 || Timer: 1.9312 sec.\n","===> Epoch[74](10/25): Loss: 0.0024 || Timer: 1.9444 sec.\n","===> Epoch[74](11/25): Loss: 0.0011 || Timer: 1.9337 sec.\n","===> Epoch[74](12/25): Loss: 0.0018 || Timer: 1.9272 sec.\n","===> Epoch[74](13/25): Loss: 0.0025 || Timer: 1.9306 sec.\n","===> Epoch[74](14/25): Loss: 0.0026 || Timer: 1.9269 sec.\n","===> Epoch[74](15/25): Loss: 0.0031 || Timer: 1.9312 sec.\n","===> Epoch[74](16/25): Loss: 0.0016 || Timer: 1.9287 sec.\n","===> Epoch[74](17/25): Loss: 0.0023 || Timer: 1.9528 sec.\n","===> Epoch[74](18/25): Loss: 0.0023 || Timer: 1.9301 sec.\n","===> Epoch[74](19/25): Loss: 0.0018 || Timer: 1.9317 sec.\n","===> Epoch[74](20/25): Loss: 0.0027 || Timer: 1.9292 sec.\n","===> Epoch[74](21/25): Loss: 0.0021 || Timer: 1.9335 sec.\n","===> Epoch[74](22/25): Loss: 0.0026 || Timer: 1.9297 sec.\n","===> Epoch[74](23/25): Loss: 0.0021 || Timer: 1.9330 sec.\n","===> Epoch[74](24/25): Loss: 0.0024 || Timer: 1.9464 sec.\n","===> Epoch[74](25/25): Loss: 0.0032 || Timer: 1.9323 sec.\n","===> Epoch 74 Complete: Avg. Loss: 0.0025\n","===> Epoch[75](1/25): Loss: 0.0019 || Timer: 1.9339 sec.\n","===> Epoch[75](2/25): Loss: 0.0018 || Timer: 1.9354 sec.\n","===> Epoch[75](3/25): Loss: 0.0030 || Timer: 1.9288 sec.\n","===> Epoch[75](4/25): Loss: 0.0015 || Timer: 1.9349 sec.\n","===> Epoch[75](5/25): Loss: 0.0026 || Timer: 1.9325 sec.\n","===> Epoch[75](6/25): Loss: 0.0034 || Timer: 1.9492 sec.\n","===> Epoch[75](7/25): Loss: 0.0022 || Timer: 1.9298 sec.\n","===> Epoch[75](8/25): Loss: 0.0022 || Timer: 1.9383 sec.\n","===> Epoch[75](9/25): Loss: 0.0029 || Timer: 1.9290 sec.\n","===> Epoch[75](10/25): Loss: 0.0020 || Timer: 1.9374 sec.\n","===> Epoch[75](11/25): Loss: 0.0032 || Timer: 1.9297 sec.\n","===> Epoch[75](12/25): Loss: 0.0017 || Timer: 1.9361 sec.\n","===> Epoch[75](13/25): Loss: 0.0014 || Timer: 1.9546 sec.\n","===> Epoch[75](14/25): Loss: 0.0030 || Timer: 1.9394 sec.\n","===> Epoch[75](15/25): Loss: 0.0023 || Timer: 1.9294 sec.\n","===> Epoch[75](16/25): Loss: 0.0030 || Timer: 1.9361 sec.\n","===> Epoch[75](17/25): Loss: 0.0018 || Timer: 1.9285 sec.\n","===> Epoch[75](18/25): Loss: 0.0013 || Timer: 1.9366 sec.\n","===> Epoch[75](19/25): Loss: 0.0014 || Timer: 1.9272 sec.\n","===> Epoch[75](20/25): Loss: 0.0014 || Timer: 1.9361 sec.\n","===> Epoch[75](21/25): Loss: 0.0021 || Timer: 1.9526 sec.\n","===> Epoch[75](22/25): Loss: 0.0021 || Timer: 1.9352 sec.\n","===> Epoch[75](23/25): Loss: 0.0018 || Timer: 1.9281 sec.\n","===> Epoch[75](24/25): Loss: 0.0023 || Timer: 1.9352 sec.\n","===> Epoch[75](25/25): Loss: 0.0024 || Timer: 1.9286 sec.\n","===> Epoch 75 Complete: Avg. Loss: 0.0022\n","===> Epoch[76](1/25): Loss: 0.0020 || Timer: 1.9390 sec.\n","===> Epoch[76](2/25): Loss: 0.0013 || Timer: 1.9343 sec.\n","===> Epoch[76](3/25): Loss: 0.0019 || Timer: 1.9518 sec.\n","===> Epoch[76](4/25): Loss: 0.0018 || Timer: 1.9325 sec.\n","===> Epoch[76](5/25): Loss: 0.0015 || Timer: 1.9309 sec.\n","===> Epoch[76](6/25): Loss: 0.0015 || Timer: 1.9331 sec.\n","===> Epoch[76](7/25): Loss: 0.0016 || Timer: 1.9312 sec.\n","===> Epoch[76](8/25): Loss: 0.0018 || Timer: 1.9371 sec.\n","===> Epoch[76](9/25): Loss: 0.0021 || Timer: 1.9297 sec.\n","===> Epoch[76](10/25): Loss: 0.0019 || Timer: 1.9509 sec.\n","===> Epoch[76](11/25): Loss: 0.0018 || Timer: 1.9282 sec.\n","===> Epoch[76](12/25): Loss: 0.0017 || Timer: 1.9311 sec.\n","===> Epoch[76](13/25): Loss: 0.0014 || Timer: 1.9295 sec.\n","===> Epoch[76](14/25): Loss: 0.0019 || Timer: 1.9324 sec.\n","===> Epoch[76](15/25): Loss: 0.0021 || Timer: 1.9314 sec.\n","===> Epoch[76](16/25): Loss: 0.0018 || Timer: 1.9346 sec.\n","===> Epoch[76](17/25): Loss: 0.0022 || Timer: 1.9300 sec.\n","===> Epoch[76](18/25): Loss: 0.0021 || Timer: 1.9486 sec.\n","===> Epoch[76](19/25): Loss: 0.0022 || Timer: 1.9292 sec.\n","===> Epoch[76](20/25): Loss: 0.0017 || Timer: 1.9301 sec.\n","===> Epoch[76](21/25): Loss: 0.0019 || Timer: 1.9307 sec.\n","===> Epoch[76](22/25): Loss: 0.0014 || Timer: 1.9320 sec.\n","===> Epoch[76](23/25): Loss: 0.0013 || Timer: 1.9314 sec.\n","===> Epoch[76](24/25): Loss: 0.0016 || Timer: 1.9335 sec.\n","===> Epoch[76](25/25): Loss: 0.0016 || Timer: 1.9522 sec.\n","===> Epoch 76 Complete: Avg. Loss: 0.0018\n","===> Epoch[77](1/25): Loss: 0.0013 || Timer: 1.9472 sec.\n","===> Epoch[77](2/25): Loss: 0.0019 || Timer: 1.9302 sec.\n","===> Epoch[77](3/25): Loss: 0.0015 || Timer: 1.9357 sec.\n","===> Epoch[77](4/25): Loss: 0.0021 || Timer: 1.9288 sec.\n","===> Epoch[77](5/25): Loss: 0.0016 || Timer: 1.9348 sec.\n","===> Epoch[77](6/25): Loss: 0.0017 || Timer: 1.9307 sec.\n","===> Epoch[77](7/25): Loss: 0.0017 || Timer: 1.9539 sec.\n","===> Epoch[77](8/25): Loss: 0.0016 || Timer: 1.9293 sec.\n","===> Epoch[77](9/25): Loss: 0.0020 || Timer: 1.9358 sec.\n","===> Epoch[77](10/25): Loss: 0.0019 || Timer: 1.9283 sec.\n","===> Epoch[77](11/25): Loss: 0.0021 || Timer: 1.9359 sec.\n","===> Epoch[77](12/25): Loss: 0.0022 || Timer: 1.9293 sec.\n","===> Epoch[77](13/25): Loss: 0.0024 || Timer: 1.9340 sec.\n","===> Epoch[77](14/25): Loss: 0.0018 || Timer: 1.9477 sec.\n","===> Epoch[77](15/25): Loss: 0.0018 || Timer: 1.9362 sec.\n","===> Epoch[77](16/25): Loss: 0.0019 || Timer: 1.9302 sec.\n","===> Epoch[77](17/25): Loss: 0.0020 || Timer: 1.9356 sec.\n","===> Epoch[77](18/25): Loss: 0.0019 || Timer: 1.9308 sec.\n","===> Epoch[77](19/25): Loss: 0.0026 || Timer: 1.9358 sec.\n","===> Epoch[77](20/25): Loss: 0.0023 || Timer: 1.9299 sec.\n","===> Epoch[77](21/25): Loss: 0.0016 || Timer: 1.9332 sec.\n","===> Epoch[77](22/25): Loss: 0.0019 || Timer: 1.9436 sec.\n","===> Epoch[77](23/25): Loss: 0.0028 || Timer: 1.9347 sec.\n","===> Epoch[77](24/25): Loss: 0.0029 || Timer: 1.9285 sec.\n","===> Epoch[77](25/25): Loss: 0.0022 || Timer: 1.9343 sec.\n","===> Epoch 77 Complete: Avg. Loss: 0.0020\n","===> Epoch[78](1/25): Loss: 0.0012 || Timer: 1.9494 sec.\n","===> Epoch[78](2/25): Loss: 0.0016 || Timer: 1.9331 sec.\n","===> Epoch[78](3/25): Loss: 0.0019 || Timer: 1.9335 sec.\n","===> Epoch[78](4/25): Loss: 0.0023 || Timer: 1.9415 sec.\n","===> Epoch[78](5/25): Loss: 0.0026 || Timer: 1.9325 sec.\n","===> Epoch[78](6/25): Loss: 0.0014 || Timer: 1.9303 sec.\n","===> Epoch[78](7/25): Loss: 0.0021 || Timer: 1.9330 sec.\n","===> Epoch[78](8/25): Loss: 0.0022 || Timer: 1.9306 sec.\n","===> Epoch[78](9/25): Loss: 0.0010 || Timer: 1.9341 sec.\n","===> Epoch[78](10/25): Loss: 0.0028 || Timer: 1.9305 sec.\n","===> Epoch[78](11/25): Loss: 0.0017 || Timer: 1.9373 sec.\n","===> Epoch[78](12/25): Loss: 0.0013 || Timer: 1.9451 sec.\n","===> Epoch[78](13/25): Loss: 0.0019 || Timer: 1.9334 sec.\n","===> Epoch[78](14/25): Loss: 0.0020 || Timer: 1.9311 sec.\n","===> Epoch[78](15/25): Loss: 0.0015 || Timer: 1.9312 sec.\n","===> Epoch[78](16/25): Loss: 0.0020 || Timer: 1.9301 sec.\n","===> Epoch[78](17/25): Loss: 0.0019 || Timer: 1.9306 sec.\n","===> Epoch[78](18/25): Loss: 0.0016 || Timer: 1.9289 sec.\n","===> Epoch[78](19/25): Loss: 0.0028 || Timer: 1.9538 sec.\n","===> Epoch[78](20/25): Loss: 0.0010 || Timer: 1.9313 sec.\n","===> Epoch[78](21/25): Loss: 0.0013 || Timer: 1.9353 sec.\n","===> Epoch[78](22/25): Loss: 0.0014 || Timer: 1.9303 sec.\n","===> Epoch[78](23/25): Loss: 0.0012 || Timer: 1.9341 sec.\n","===> Epoch[78](24/25): Loss: 0.0015 || Timer: 1.9290 sec.\n","===> Epoch[78](25/25): Loss: 0.0023 || Timer: 1.9327 sec.\n","===> Epoch 78 Complete: Avg. Loss: 0.0018\n","===> Epoch[79](1/25): Loss: 0.0017 || Timer: 1.9553 sec.\n","===> Epoch[79](2/25): Loss: 0.0024 || Timer: 1.9366 sec.\n","===> Epoch[79](3/25): Loss: 0.0019 || Timer: 1.9307 sec.\n","===> Epoch[79](4/25): Loss: 0.0016 || Timer: 1.9356 sec.\n","===> Epoch[79](5/25): Loss: 0.0015 || Timer: 1.9298 sec.\n","===> Epoch[79](6/25): Loss: 0.0015 || Timer: 1.9364 sec.\n","===> Epoch[79](7/25): Loss: 0.0015 || Timer: 1.9286 sec.\n","===> Epoch[79](8/25): Loss: 0.0019 || Timer: 1.9473 sec.\n","===> Epoch[79](9/25): Loss: 0.0016 || Timer: 1.9285 sec.\n","===> Epoch[79](10/25): Loss: 0.0028 || Timer: 1.9332 sec.\n","===> Epoch[79](11/25): Loss: 0.0014 || Timer: 1.9329 sec.\n","===> Epoch[79](12/25): Loss: 0.0018 || Timer: 1.9337 sec.\n","===> Epoch[79](13/25): Loss: 0.0019 || Timer: 1.9333 sec.\n","===> Epoch[79](14/25): Loss: 0.0014 || Timer: 1.9354 sec.\n","===> Epoch[79](15/25): Loss: 0.0010 || Timer: 1.9300 sec.\n","===> Epoch[79](16/25): Loss: 0.0016 || Timer: 1.9521 sec.\n","===> Epoch[79](17/25): Loss: 0.0019 || Timer: 1.9306 sec.\n","===> Epoch[79](18/25): Loss: 0.0014 || Timer: 1.9355 sec.\n","===> Epoch[79](19/25): Loss: 0.0011 || Timer: 1.9288 sec.\n","===> Epoch[79](20/25): Loss: 0.0019 || Timer: 1.9347 sec.\n","===> Epoch[79](21/25): Loss: 0.0026 || Timer: 1.9279 sec.\n","===> Epoch[79](22/25): Loss: 0.0018 || Timer: 1.9341 sec.\n","===> Epoch[79](23/25): Loss: 0.0015 || Timer: 1.9523 sec.\n","===> Epoch[79](24/25): Loss: 0.0020 || Timer: 1.9361 sec.\n","===> Epoch[79](25/25): Loss: 0.0014 || Timer: 1.9287 sec.\n","===> Epoch 79 Complete: Avg. Loss: 0.0017\n","===> Epoch[80](1/25): Loss: 0.0015 || Timer: 1.9400 sec.\n","===> Epoch[80](2/25): Loss: 0.0020 || Timer: 1.9345 sec.\n","===> Epoch[80](3/25): Loss: 0.0026 || Timer: 1.9309 sec.\n","===> Epoch[80](4/25): Loss: 0.0016 || Timer: 1.9339 sec.\n","===> Epoch[80](5/25): Loss: 0.0013 || Timer: 1.9492 sec.\n","===> Epoch[80](6/25): Loss: 0.0026 || Timer: 1.9340 sec.\n","===> Epoch[80](7/25): Loss: 0.0017 || Timer: 1.9292 sec.\n","===> Epoch[80](8/25): Loss: 0.0019 || Timer: 1.9323 sec.\n","===> Epoch[80](9/25): Loss: 0.0020 || Timer: 1.9306 sec.\n","===> Epoch[80](10/25): Loss: 0.0017 || Timer: 1.9316 sec.\n","===> Epoch[80](11/25): Loss: 0.0024 || Timer: 1.9292 sec.\n","===> Epoch[80](12/25): Loss: 0.0027 || Timer: 1.9335 sec.\n","===> Epoch[80](13/25): Loss: 0.0014 || Timer: 1.9534 sec.\n","===> Epoch[80](14/25): Loss: 0.0014 || Timer: 1.9309 sec.\n","===> Epoch[80](15/25): Loss: 0.0011 || Timer: 1.9304 sec.\n","===> Epoch[80](16/25): Loss: 0.0020 || Timer: 1.9329 sec.\n","===> Epoch[80](17/25): Loss: 0.0017 || Timer: 1.9307 sec.\n","===> Epoch[80](18/25): Loss: 0.0015 || Timer: 1.9331 sec.\n","===> Epoch[80](19/25): Loss: 0.0018 || Timer: 1.9322 sec.\n","===> Epoch[80](20/25): Loss: 0.0014 || Timer: 1.9329 sec.\n","===> Epoch[80](21/25): Loss: 0.0021 || Timer: 1.9438 sec.\n","===> Epoch[80](22/25): Loss: 0.0018 || Timer: 1.9323 sec.\n","===> Epoch[80](23/25): Loss: 0.0011 || Timer: 1.9306 sec.\n","===> Epoch[80](24/25): Loss: 0.0015 || Timer: 1.9330 sec.\n","===> Epoch[80](25/25): Loss: 0.0018 || Timer: 1.9303 sec.\n","===> Epoch 80 Complete: Avg. Loss: 0.0018\n","Checkpoint saved to /content/gdrive/My Drive/졸업논문/졸업논문/scale=2/weights_scale=2/WCNN_epoch_80.pth\n","===> Epoch[81](1/25): Loss: 0.0015 || Timer: 1.9451 sec.\n","===> Epoch[81](2/25): Loss: 0.0011 || Timer: 1.9290 sec.\n","===> Epoch[81](3/25): Loss: 0.0012 || Timer: 1.9443 sec.\n","===> Epoch[81](4/25): Loss: 0.0015 || Timer: 1.9296 sec.\n","===> Epoch[81](5/25): Loss: 0.0020 || Timer: 1.9363 sec.\n","===> Epoch[81](6/25): Loss: 0.0012 || Timer: 1.9290 sec.\n","===> Epoch[81](7/25): Loss: 0.0014 || Timer: 1.9349 sec.\n","===> Epoch[81](8/25): Loss: 0.0020 || Timer: 1.9299 sec.\n","===> Epoch[81](9/25): Loss: 0.0013 || Timer: 1.9351 sec.\n","===> Epoch[81](10/25): Loss: 0.0014 || Timer: 1.9273 sec.\n","===> Epoch[81](11/25): Loss: 0.0008 || Timer: 1.9495 sec.\n","===> Epoch[81](12/25): Loss: 0.0011 || Timer: 1.9299 sec.\n","===> Epoch[81](13/25): Loss: 0.0019 || Timer: 1.9339 sec.\n","===> Epoch[81](14/25): Loss: 0.0011 || Timer: 1.9281 sec.\n","===> Epoch[81](15/25): Loss: 0.0009 || Timer: 1.9348 sec.\n","===> Epoch[81](16/25): Loss: 0.0027 || Timer: 1.9302 sec.\n","===> Epoch[81](17/25): Loss: 0.0018 || Timer: 1.9340 sec.\n","===> Epoch[81](18/25): Loss: 0.0018 || Timer: 1.9297 sec.\n","===> Epoch[81](19/25): Loss: 0.0015 || Timer: 1.9575 sec.\n","===> Epoch[81](20/25): Loss: 0.0016 || Timer: 1.9291 sec.\n","===> Epoch[81](21/25): Loss: 0.0018 || Timer: 1.9349 sec.\n","===> Epoch[81](22/25): Loss: 0.0024 || Timer: 1.9286 sec.\n","===> Epoch[81](23/25): Loss: 0.0024 || Timer: 1.9332 sec.\n","===> Epoch[81](24/25): Loss: 0.0018 || Timer: 1.9296 sec.\n","===> Epoch[81](25/25): Loss: 0.0030 || Timer: 1.9340 sec.\n","===> Epoch 81 Complete: Avg. Loss: 0.0017\n","===> Epoch[82](1/25): Loss: 0.0048 || Timer: 1.9629 sec.\n","===> Epoch[82](2/25): Loss: 0.0067 || Timer: 1.9296 sec.\n","===> Epoch[82](3/25): Loss: 0.0066 || Timer: 1.9332 sec.\n","===> Epoch[82](4/25): Loss: 0.0030 || Timer: 1.9296 sec.\n","===> Epoch[82](5/25): Loss: 0.0058 || Timer: 1.9327 sec.\n","===> Epoch[82](6/25): Loss: 0.0053 || Timer: 1.9307 sec.\n","===> Epoch[82](7/25): Loss: 0.0020 || Timer: 1.9313 sec.\n","===> Epoch[82](8/25): Loss: 0.0072 || Timer: 1.9509 sec.\n","===> Epoch[82](9/25): Loss: 0.0043 || Timer: 1.9327 sec.\n","===> Epoch[82](10/25): Loss: 0.0047 || Timer: 1.9292 sec.\n","===> Epoch[82](11/25): Loss: 0.0052 || Timer: 1.9335 sec.\n","===> Epoch[82](12/25): Loss: 0.0037 || Timer: 1.9295 sec.\n","===> Epoch[82](13/25): Loss: 0.0027 || Timer: 1.9351 sec.\n","===> Epoch[82](14/25): Loss: 0.0030 || Timer: 1.9296 sec.\n","===> Epoch[82](15/25): Loss: 0.0025 || Timer: 1.9437 sec.\n","===> Epoch[82](16/25): Loss: 0.0045 || Timer: 1.9316 sec.\n","===> Epoch[82](17/25): Loss: 0.0022 || Timer: 1.9319 sec.\n","===> Epoch[82](18/25): Loss: 0.0033 || Timer: 1.9305 sec.\n","===> Epoch[82](19/25): Loss: 0.0016 || Timer: 1.9330 sec.\n","===> Epoch[82](20/25): Loss: 0.0035 || Timer: 1.9300 sec.\n","===> Epoch[82](21/25): Loss: 0.0017 || Timer: 1.9317 sec.\n","===> Epoch[82](22/25): Loss: 0.0021 || Timer: 1.9437 sec.\n","===> Epoch[82](23/25): Loss: 0.0036 || Timer: 1.9332 sec.\n","===> Epoch[82](24/25): Loss: 0.0018 || Timer: 1.9301 sec.\n","===> Epoch[82](25/25): Loss: 0.0030 || Timer: 1.9326 sec.\n","===> Epoch 82 Complete: Avg. Loss: 0.0038\n","===> Epoch[83](1/25): Loss: 0.0022 || Timer: 1.9400 sec.\n","===> Epoch[83](2/25): Loss: 0.0021 || Timer: 1.9349 sec.\n","===> Epoch[83](3/25): Loss: 0.0024 || Timer: 1.9302 sec.\n","===> Epoch[83](4/25): Loss: 0.0037 || Timer: 1.9464 sec.\n","===> Epoch[83](5/25): Loss: 0.0024 || Timer: 1.9287 sec.\n","===> Epoch[83](6/25): Loss: 0.0018 || Timer: 1.9335 sec.\n","===> Epoch[83](7/25): Loss: 0.0030 || Timer: 1.9301 sec.\n","===> Epoch[83](8/25): Loss: 0.0025 || Timer: 1.9353 sec.\n","===> Epoch[83](9/25): Loss: 0.0034 || Timer: 1.9300 sec.\n","===> Epoch[83](10/25): Loss: 0.0056 || Timer: 1.9335 sec.\n","===> Epoch[83](11/25): Loss: 0.0055 || Timer: 1.9283 sec.\n","===> Epoch[83](12/25): Loss: 0.0018 || Timer: 1.9565 sec.\n","===> Epoch[83](13/25): Loss: 0.0052 || Timer: 1.9290 sec.\n","===> Epoch[83](14/25): Loss: 0.0038 || Timer: 1.9347 sec.\n","===> Epoch[83](15/25): Loss: 0.0053 || Timer: 1.9287 sec.\n","===> Epoch[83](16/25): Loss: 0.0137 || Timer: 1.9343 sec.\n","===> Epoch[83](17/25): Loss: 0.0104 || Timer: 1.9284 sec.\n","===> Epoch[83](18/25): Loss: 0.0077 || Timer: 1.9341 sec.\n","===> Epoch[83](19/25): Loss: 0.0144 || Timer: 1.9380 sec.\n","===> Epoch[83](20/25): Loss: 0.0024 || Timer: 1.9343 sec.\n","===> Epoch[83](21/25): Loss: 0.0103 || Timer: 1.9282 sec.\n","===> Epoch[83](22/25): Loss: 0.0080 || Timer: 1.9346 sec.\n","===> Epoch[83](23/25): Loss: 0.0018 || Timer: 1.9291 sec.\n","===> Epoch[83](24/25): Loss: 0.0074 || Timer: 1.9373 sec.\n","===> Epoch[83](25/25): Loss: 0.0034 || Timer: 1.9290 sec.\n","===> Epoch 83 Complete: Avg. Loss: 0.0052\n","===> Epoch[84](1/25): Loss: 0.0059 || Timer: 1.9495 sec.\n","===> Epoch[84](2/25): Loss: 0.0043 || Timer: 1.9347 sec.\n","===> Epoch[84](3/25): Loss: 0.0044 || Timer: 1.9310 sec.\n","===> Epoch[84](4/25): Loss: 0.0047 || Timer: 1.9331 sec.\n","===> Epoch[84](5/25): Loss: 0.0050 || Timer: 1.9296 sec.\n","===> Epoch[84](6/25): Loss: 0.0025 || Timer: 1.9336 sec.\n","===> Epoch[84](7/25): Loss: 0.0026 || Timer: 1.9299 sec.\n","===> Epoch[84](8/25): Loss: 0.0026 || Timer: 1.9539 sec.\n","===> Epoch[84](9/25): Loss: 0.0020 || Timer: 1.9301 sec.\n","===> Epoch[84](10/25): Loss: 0.0039 || Timer: 1.9313 sec.\n","===> Epoch[84](11/25): Loss: 0.0025 || Timer: 1.9352 sec.\n","===> Epoch[84](12/25): Loss: 0.0040 || Timer: 1.9313 sec.\n","===> Epoch[84](13/25): Loss: 0.0017 || Timer: 1.9303 sec.\n","===> Epoch[84](14/25): Loss: 0.0037 || Timer: 1.9315 sec.\n","===> Epoch[84](15/25): Loss: 0.0019 || Timer: 1.9343 sec.\n","===> Epoch[84](16/25): Loss: 0.0028 || Timer: 1.9498 sec.\n","===> Epoch[84](17/25): Loss: 0.0019 || Timer: 1.9316 sec.\n","===> Epoch[84](18/25): Loss: 0.0024 || Timer: 1.9313 sec.\n","===> Epoch[84](19/25): Loss: 0.0025 || Timer: 1.9324 sec.\n","===> Epoch[84](20/25): Loss: 0.0016 || Timer: 1.9304 sec.\n","===> Epoch[84](21/25): Loss: 0.0027 || Timer: 1.9310 sec.\n","===> Epoch[84](22/25): Loss: 0.0017 || Timer: 1.9314 sec.\n","===> Epoch[84](23/25): Loss: 0.0024 || Timer: 1.9445 sec.\n","===> Epoch[84](24/25): Loss: 0.0022 || Timer: 1.9317 sec.\n","===> Epoch[84](25/25): Loss: 0.0040 || Timer: 1.9286 sec.\n","===> Epoch 84 Complete: Avg. Loss: 0.0030\n","===> Epoch[85](1/25): Loss: 0.0023 || Timer: 1.9505 sec.\n","===> Epoch[85](2/25): Loss: 0.0019 || Timer: 1.9292 sec.\n","===> Epoch[85](3/25): Loss: 0.0013 || Timer: 1.9332 sec.\n","===> Epoch[85](4/25): Loss: 0.0018 || Timer: 1.9294 sec.\n","===> Epoch[85](5/25): Loss: 0.0022 || Timer: 1.9510 sec.\n","===> Epoch[85](6/25): Loss: 0.0018 || Timer: 1.9298 sec.\n","===> Epoch[85](7/25): Loss: 0.0023 || Timer: 1.9354 sec.\n","===> Epoch[85](8/25): Loss: 0.0028 || Timer: 1.9314 sec.\n","===> Epoch[85](9/25): Loss: 0.0026 || Timer: 1.9340 sec.\n","===> Epoch[85](10/25): Loss: 0.0025 || Timer: 1.9271 sec.\n","===> Epoch[85](11/25): Loss: 0.0025 || Timer: 1.9336 sec.\n","===> Epoch[85](12/25): Loss: 0.0032 || Timer: 1.9438 sec.\n","===> Epoch[85](13/25): Loss: 0.0029 || Timer: 1.9329 sec.\n","===> Epoch[85](14/25): Loss: 0.0036 || Timer: 1.9277 sec.\n","===> Epoch[85](15/25): Loss: 0.0029 || Timer: 1.9346 sec.\n","===> Epoch[85](16/25): Loss: 0.0028 || Timer: 1.9288 sec.\n","===> Epoch[85](17/25): Loss: 0.0025 || Timer: 1.9354 sec.\n","===> Epoch[85](18/25): Loss: 0.0036 || Timer: 1.9304 sec.\n","===> Epoch[85](19/25): Loss: 0.0043 || Timer: 1.9567 sec.\n","===> Epoch[85](20/25): Loss: 0.0019 || Timer: 1.9305 sec.\n","===> Epoch[85](21/25): Loss: 0.0038 || Timer: 1.9339 sec.\n","===> Epoch[85](22/25): Loss: 0.0024 || Timer: 1.9295 sec.\n","===> Epoch[85](23/25): Loss: 0.0019 || Timer: 1.9340 sec.\n","===> Epoch[85](24/25): Loss: 0.0026 || Timer: 1.9285 sec.\n","===> Epoch[85](25/25): Loss: 0.0033 || Timer: 1.9341 sec.\n","===> Epoch 85 Complete: Avg. Loss: 0.0026\n","===> Epoch[86](1/25): Loss: 0.0022 || Timer: 1.9482 sec.\n","===> Epoch[86](2/25): Loss: 0.0022 || Timer: 1.9327 sec.\n","===> Epoch[86](3/25): Loss: 0.0021 || Timer: 1.9327 sec.\n","===> Epoch[86](4/25): Loss: 0.0019 || Timer: 1.9301 sec.\n","===> Epoch[86](5/25): Loss: 0.0016 || Timer: 1.9308 sec.\n","===> Epoch[86](6/25): Loss: 0.0015 || Timer: 1.9293 sec.\n","===> Epoch[86](7/25): Loss: 0.0028 || Timer: 1.9346 sec.\n","===> Epoch[86](8/25): Loss: 0.0018 || Timer: 1.9530 sec.\n","===> Epoch[86](9/25): Loss: 0.0024 || Timer: 1.9308 sec.\n","===> Epoch[86](10/25): Loss: 0.0027 || Timer: 1.9294 sec.\n","===> Epoch[86](11/25): Loss: 0.0020 || Timer: 1.9336 sec.\n","===> Epoch[86](12/25): Loss: 0.0044 || Timer: 1.9298 sec.\n","===> Epoch[86](13/25): Loss: 0.0018 || Timer: 1.9340 sec.\n","===> Epoch[86](14/25): Loss: 0.0022 || Timer: 1.9300 sec.\n","===> Epoch[86](15/25): Loss: 0.0014 || Timer: 1.9509 sec.\n","===> Epoch[86](16/25): Loss: 0.0023 || Timer: 1.9298 sec.\n","===> Epoch[86](17/25): Loss: 0.0027 || Timer: 1.9304 sec.\n","===> Epoch[86](18/25): Loss: 0.0018 || Timer: 1.9301 sec.\n","===> Epoch[86](19/25): Loss: 0.0013 || Timer: 1.9334 sec.\n","===> Epoch[86](20/25): Loss: 0.0018 || Timer: 1.9311 sec.\n","===> Epoch[86](21/25): Loss: 0.0024 || Timer: 1.9320 sec.\n","===> Epoch[86](22/25): Loss: 0.0026 || Timer: 1.9438 sec.\n","===> Epoch[86](23/25): Loss: 0.0013 || Timer: 1.9318 sec.\n","===> Epoch[86](24/25): Loss: 0.0018 || Timer: 1.9299 sec.\n","===> Epoch[86](25/25): Loss: 0.0014 || Timer: 1.9308 sec.\n","===> Epoch 86 Complete: Avg. Loss: 0.0021\n","===> Epoch[87](1/25): Loss: 0.0012 || Timer: 1.9417 sec.\n","===> Epoch[87](2/25): Loss: 0.0017 || Timer: 1.9353 sec.\n","===> Epoch[87](3/25): Loss: 0.0016 || Timer: 1.9285 sec.\n","===> Epoch[87](4/25): Loss: 0.0018 || Timer: 1.9549 sec.\n","===> Epoch[87](5/25): Loss: 0.0017 || Timer: 1.9289 sec.\n","===> Epoch[87](6/25): Loss: 0.0016 || Timer: 1.9352 sec.\n","===> Epoch[87](7/25): Loss: 0.0017 || Timer: 1.9288 sec.\n","===> Epoch[87](8/25): Loss: 0.0013 || Timer: 1.9337 sec.\n","===> Epoch[87](9/25): Loss: 0.0011 || Timer: 1.9277 sec.\n","===> Epoch[87](10/25): Loss: 0.0015 || Timer: 1.9347 sec.\n","===> Epoch[87](11/25): Loss: 0.0013 || Timer: 1.9486 sec.\n","===> Epoch[87](12/25): Loss: 0.0019 || Timer: 1.9345 sec.\n","===> Epoch[87](13/25): Loss: 0.0014 || Timer: 1.9283 sec.\n","===> Epoch[87](14/25): Loss: 0.0024 || Timer: 1.9337 sec.\n","===> Epoch[87](15/25): Loss: 0.0019 || Timer: 1.9298 sec.\n","===> Epoch[87](16/25): Loss: 0.0013 || Timer: 1.9369 sec.\n","===> Epoch[87](17/25): Loss: 0.0017 || Timer: 1.9307 sec.\n","===> Epoch[87](18/25): Loss: 0.0022 || Timer: 1.9479 sec.\n","===> Epoch[87](19/25): Loss: 0.0013 || Timer: 1.9291 sec.\n","===> Epoch[87](20/25): Loss: 0.0031 || Timer: 1.9338 sec.\n","===> Epoch[87](21/25): Loss: 0.0024 || Timer: 1.9299 sec.\n","===> Epoch[87](22/25): Loss: 0.0014 || Timer: 1.9370 sec.\n","===> Epoch[87](23/25): Loss: 0.0031 || Timer: 1.9298 sec.\n","===> Epoch[87](24/25): Loss: 0.0010 || Timer: 1.9344 sec.\n","===> Epoch[87](25/25): Loss: 0.0013 || Timer: 1.9276 sec.\n","===> Epoch 87 Complete: Avg. Loss: 0.0017\n","===> Epoch[88](1/25): Loss: 0.0020 || Timer: 1.9457 sec.\n","===> Epoch[88](2/25): Loss: 0.0012 || Timer: 1.9328 sec.\n","===> Epoch[88](3/25): Loss: 0.0014 || Timer: 1.9341 sec.\n","===> Epoch[88](4/25): Loss: 0.0017 || Timer: 1.9332 sec.\n","===> Epoch[88](5/25): Loss: 0.0014 || Timer: 1.9297 sec.\n","===> Epoch[88](6/25): Loss: 0.0015 || Timer: 1.9313 sec.\n","===> Epoch[88](7/25): Loss: 0.0019 || Timer: 1.9295 sec.\n","===> Epoch[88](8/25): Loss: 0.0008 || Timer: 1.9423 sec.\n","===> Epoch[88](9/25): Loss: 0.0015 || Timer: 1.9295 sec.\n","===> Epoch[88](10/25): Loss: 0.0014 || Timer: 1.9378 sec.\n","===> Epoch[88](11/25): Loss: 0.0023 || Timer: 1.9305 sec.\n","===> Epoch[88](12/25): Loss: 0.0011 || Timer: 1.9330 sec.\n","===> Epoch[88](13/25): Loss: 0.0011 || Timer: 1.9295 sec.\n","===> Epoch[88](14/25): Loss: 0.0019 || Timer: 1.9314 sec.\n","===> Epoch[88](15/25): Loss: 0.0011 || Timer: 1.9541 sec.\n","===> Epoch[88](16/25): Loss: 0.0018 || Timer: 1.9334 sec.\n","===> Epoch[88](17/25): Loss: 0.0022 || Timer: 1.9292 sec.\n","===> Epoch[88](18/25): Loss: 0.0021 || Timer: 1.9335 sec.\n","===> Epoch[88](19/25): Loss: 0.0017 || Timer: 1.9317 sec.\n","===> Epoch[88](20/25): Loss: 0.0018 || Timer: 1.9336 sec.\n","===> Epoch[88](21/25): Loss: 0.0011 || Timer: 1.9280 sec.\n","===> Epoch[88](22/25): Loss: 0.0015 || Timer: 1.9537 sec.\n","===> Epoch[88](23/25): Loss: 0.0018 || Timer: 1.9290 sec.\n","===> Epoch[88](24/25): Loss: 0.0010 || Timer: 1.9347 sec.\n","===> Epoch[88](25/25): Loss: 0.0016 || Timer: 1.9312 sec.\n","===> Epoch 88 Complete: Avg. Loss: 0.0016\n","===> Epoch[89](1/25): Loss: 0.0011 || Timer: 1.9470 sec.\n","===> Epoch[89](2/25): Loss: 0.0016 || Timer: 1.9282 sec.\n","===> Epoch[89](3/25): Loss: 0.0015 || Timer: 1.9379 sec.\n","===> Epoch[89](4/25): Loss: 0.0019 || Timer: 1.9466 sec.\n","===> Epoch[89](5/25): Loss: 0.0026 || Timer: 1.9344 sec.\n","===> Epoch[89](6/25): Loss: 0.0017 || Timer: 1.9295 sec.\n","===> Epoch[89](7/25): Loss: 0.0018 || Timer: 1.9344 sec.\n","===> Epoch[89](8/25): Loss: 0.0017 || Timer: 1.9294 sec.\n","===> Epoch[89](9/25): Loss: 0.0014 || Timer: 1.9350 sec.\n","===> Epoch[89](10/25): Loss: 0.0015 || Timer: 1.9315 sec.\n","===> Epoch[89](11/25): Loss: 0.0015 || Timer: 1.9337 sec.\n","===> Epoch[89](12/25): Loss: 0.0021 || Timer: 1.9374 sec.\n","===> Epoch[89](13/25): Loss: 0.0019 || Timer: 1.9347 sec.\n","===> Epoch[89](14/25): Loss: 0.0012 || Timer: 1.9304 sec.\n","===> Epoch[89](15/25): Loss: 0.0016 || Timer: 1.9352 sec.\n","===> Epoch[89](16/25): Loss: 0.0013 || Timer: 1.9291 sec.\n","===> Epoch[89](17/25): Loss: 0.0009 || Timer: 1.9341 sec.\n","===> Epoch[89](18/25): Loss: 0.0013 || Timer: 1.9295 sec.\n","===> Epoch[89](19/25): Loss: 0.0017 || Timer: 1.9500 sec.\n","===> Epoch[89](20/25): Loss: 0.0018 || Timer: 1.9300 sec.\n","===> Epoch[89](21/25): Loss: 0.0011 || Timer: 1.9344 sec.\n","===> Epoch[89](22/25): Loss: 0.0021 || Timer: 1.9299 sec.\n","===> Epoch[89](23/25): Loss: 0.0026 || Timer: 1.9333 sec.\n","===> Epoch[89](24/25): Loss: 0.0024 || Timer: 1.9292 sec.\n","===> Epoch[89](25/25): Loss: 0.0024 || Timer: 1.9347 sec.\n","===> Epoch 89 Complete: Avg. Loss: 0.0017\n","===> Epoch[90](1/25): Loss: 0.0013 || Timer: 1.9465 sec.\n","===> Epoch[90](2/25): Loss: 0.0016 || Timer: 1.9323 sec.\n","===> Epoch[90](3/25): Loss: 0.0021 || Timer: 1.9335 sec.\n","===> Epoch[90](4/25): Loss: 0.0020 || Timer: 1.9302 sec.\n","===> Epoch[90](5/25): Loss: 0.0015 || Timer: 1.9329 sec.\n","===> Epoch[90](6/25): Loss: 0.0020 || Timer: 1.9290 sec.\n","===> Epoch[90](7/25): Loss: 0.0017 || Timer: 1.9327 sec.\n","===> Epoch[90](8/25): Loss: 0.0018 || Timer: 1.9409 sec.\n","===> Epoch[90](9/25): Loss: 0.0017 || Timer: 1.9335 sec.\n","===> Epoch[90](10/25): Loss: 0.0017 || Timer: 1.9318 sec.\n","===> Epoch[90](11/25): Loss: 0.0018 || Timer: 1.9312 sec.\n","===> Epoch[90](12/25): Loss: 0.0019 || Timer: 1.9309 sec.\n","===> Epoch[90](13/25): Loss: 0.0015 || Timer: 1.9329 sec.\n","===> Epoch[90](14/25): Loss: 0.0012 || Timer: 1.9293 sec.\n","===> Epoch[90](15/25): Loss: 0.0019 || Timer: 1.9336 sec.\n","===> Epoch[90](16/25): Loss: 0.0012 || Timer: 1.9540 sec.\n","===> Epoch[90](17/25): Loss: 0.0021 || Timer: 1.9324 sec.\n","===> Epoch[90](18/25): Loss: 0.0014 || Timer: 1.9301 sec.\n","===> Epoch[90](19/25): Loss: 0.0016 || Timer: 1.9323 sec.\n","===> Epoch[90](20/25): Loss: 0.0013 || Timer: 1.9313 sec.\n","===> Epoch[90](21/25): Loss: 0.0016 || Timer: 1.9334 sec.\n","===> Epoch[90](22/25): Loss: 0.0016 || Timer: 1.9302 sec.\n","===> Epoch[90](23/25): Loss: 0.0018 || Timer: 1.9325 sec.\n","===> Epoch[90](24/25): Loss: 0.0013 || Timer: 1.9406 sec.\n","===> Epoch[90](25/25): Loss: 0.0019 || Timer: 1.9318 sec.\n","===> Epoch 90 Complete: Avg. Loss: 0.0017\n","Checkpoint saved to /content/gdrive/My Drive/졸업논문/졸업논문/scale=2/weights_scale=2/WCNN_epoch_90.pth\n","===> Epoch[91](1/25): Loss: 0.0020 || Timer: 1.9406 sec.\n","===> Epoch[91](2/25): Loss: 0.0012 || Timer: 1.9360 sec.\n","===> Epoch[91](3/25): Loss: 0.0020 || Timer: 1.9290 sec.\n","===> Epoch[91](4/25): Loss: 0.0012 || Timer: 1.9347 sec.\n","===> Epoch[91](5/25): Loss: 0.0022 || Timer: 1.9310 sec.\n","===> Epoch[91](6/25): Loss: 0.0021 || Timer: 1.9557 sec.\n","===> Epoch[91](7/25): Loss: 0.0022 || Timer: 1.9290 sec.\n","===> Epoch[91](8/25): Loss: 0.0016 || Timer: 1.9349 sec.\n","===> Epoch[91](9/25): Loss: 0.0016 || Timer: 1.9296 sec.\n","===> Epoch[91](10/25): Loss: 0.0017 || Timer: 1.9343 sec.\n","===> Epoch[91](11/25): Loss: 0.0020 || Timer: 1.9303 sec.\n","===> Epoch[91](12/25): Loss: 0.0017 || Timer: 1.9361 sec.\n","===> Epoch[91](13/25): Loss: 0.0012 || Timer: 1.9286 sec.\n","===> Epoch[91](14/25): Loss: 0.0022 || Timer: 1.9457 sec.\n","===> Epoch[91](15/25): Loss: 0.0031 || Timer: 1.9305 sec.\n","===> Epoch[91](16/25): Loss: 0.0019 || Timer: 1.9338 sec.\n","===> Epoch[91](17/25): Loss: 0.0015 || Timer: 1.9283 sec.\n","===> Epoch[91](18/25): Loss: 0.0014 || Timer: 1.9342 sec.\n","===> Epoch[91](19/25): Loss: 0.0019 || Timer: 1.9302 sec.\n","===> Epoch[91](20/25): Loss: 0.0034 || Timer: 1.9347 sec.\n","===> Epoch[91](21/25): Loss: 0.0016 || Timer: 1.9285 sec.\n","===> Epoch[91](22/25): Loss: 0.0020 || Timer: 1.9504 sec.\n","===> Epoch[91](23/25): Loss: 0.0022 || Timer: 1.9297 sec.\n","===> Epoch[91](24/25): Loss: 0.0020 || Timer: 1.9342 sec.\n","===> Epoch[91](25/25): Loss: 0.0022 || Timer: 1.9294 sec.\n","===> Epoch 91 Complete: Avg. Loss: 0.0019\n","===> Epoch[92](1/25): Loss: 0.0020 || Timer: 1.9405 sec.\n","===> Epoch[92](2/25): Loss: 0.0019 || Timer: 1.9341 sec.\n","===> Epoch[92](3/25): Loss: 0.0020 || Timer: 1.9299 sec.\n","===> Epoch[92](4/25): Loss: 0.0035 || Timer: 1.9560 sec.\n","===> Epoch[92](5/25): Loss: 0.0019 || Timer: 1.9309 sec.\n","===> Epoch[92](6/25): Loss: 0.0019 || Timer: 1.9326 sec.\n","===> Epoch[92](7/25): Loss: 0.0043 || Timer: 1.9311 sec.\n","===> Epoch[92](8/25): Loss: 0.0054 || Timer: 1.9324 sec.\n","===> Epoch[92](9/25): Loss: 0.0018 || Timer: 1.9291 sec.\n","===> Epoch[92](10/25): Loss: 0.0052 || Timer: 1.9305 sec.\n","===> Epoch[92](11/25): Loss: 0.0029 || Timer: 1.9335 sec.\n","===> Epoch[92](12/25): Loss: 0.0039 || Timer: 1.9499 sec.\n","===> Epoch[92](13/25): Loss: 0.0076 || Timer: 1.9335 sec.\n","===> Epoch[92](14/25): Loss: 0.0028 || Timer: 1.9361 sec.\n","===> Epoch[92](15/25): Loss: 0.0039 || Timer: 1.9304 sec.\n","===> Epoch[92](16/25): Loss: 0.0029 || Timer: 1.9329 sec.\n","===> Epoch[92](17/25): Loss: 0.0031 || Timer: 1.9313 sec.\n","===> Epoch[92](18/25): Loss: 0.0026 || Timer: 1.9315 sec.\n","===> Epoch[92](19/25): Loss: 0.0026 || Timer: 1.9300 sec.\n","===> Epoch[92](20/25): Loss: 0.0015 || Timer: 1.9542 sec.\n","===> Epoch[92](21/25): Loss: 0.0017 || Timer: 1.9304 sec.\n","===> Epoch[92](22/25): Loss: 0.0031 || Timer: 1.9335 sec.\n","===> Epoch[92](23/25): Loss: 0.0023 || Timer: 1.9296 sec.\n","===> Epoch[92](24/25): Loss: 0.0021 || Timer: 1.9336 sec.\n","===> Epoch[92](25/25): Loss: 0.0014 || Timer: 1.9311 sec.\n","===> Epoch 92 Complete: Avg. Loss: 0.0030\n","===> Epoch[93](1/25): Loss: 0.0015 || Timer: 1.9408 sec.\n","===> Epoch[93](2/25): Loss: 0.0018 || Timer: 1.9537 sec.\n","===> Epoch[93](3/25): Loss: 0.0011 || Timer: 1.9369 sec.\n","===> Epoch[93](4/25): Loss: 0.0014 || Timer: 1.9296 sec.\n","===> Epoch[93](5/25): Loss: 0.0016 || Timer: 1.9347 sec.\n","===> Epoch[93](6/25): Loss: 0.0025 || Timer: 1.9307 sec.\n","===> Epoch[93](7/25): Loss: 0.0012 || Timer: 1.9337 sec.\n","===> Epoch[93](8/25): Loss: 0.0026 || Timer: 1.9288 sec.\n","===> Epoch[93](9/25): Loss: 0.0016 || Timer: 1.9350 sec.\n","===> Epoch[93](10/25): Loss: 0.0016 || Timer: 1.9443 sec.\n","===> Epoch[93](11/25): Loss: 0.0023 || Timer: 1.9359 sec.\n","===> Epoch[93](12/25): Loss: 0.0014 || Timer: 1.9294 sec.\n","===> Epoch[93](13/25): Loss: 0.0007 || Timer: 1.9356 sec.\n","===> Epoch[93](14/25): Loss: 0.0023 || Timer: 1.9300 sec.\n","===> Epoch[93](15/25): Loss: 0.0016 || Timer: 1.9337 sec.\n","===> Epoch[93](16/25): Loss: 0.0016 || Timer: 1.9306 sec.\n","===> Epoch[93](17/25): Loss: 0.0024 || Timer: 1.9357 sec.\n","===> Epoch[93](18/25): Loss: 0.0020 || Timer: 1.9503 sec.\n","===> Epoch[93](19/25): Loss: 0.0017 || Timer: 1.9381 sec.\n","===> Epoch[93](20/25): Loss: 0.0017 || Timer: 1.9303 sec.\n","===> Epoch[93](21/25): Loss: 0.0023 || Timer: 1.9364 sec.\n","===> Epoch[93](22/25): Loss: 0.0025 || Timer: 1.9284 sec.\n","===> Epoch[93](23/25): Loss: 0.0019 || Timer: 1.9351 sec.\n","===> Epoch[93](24/25): Loss: 0.0018 || Timer: 1.9311 sec.\n","===> Epoch[93](25/25): Loss: 0.0015 || Timer: 1.9353 sec.\n","===> Epoch 93 Complete: Avg. Loss: 0.0018\n","===> Epoch[94](1/25): Loss: 0.0023 || Timer: 1.9570 sec.\n","===> Epoch[94](2/25): Loss: 0.0016 || Timer: 1.9304 sec.\n","===> Epoch[94](3/25): Loss: 0.0025 || Timer: 1.9315 sec.\n","===> Epoch[94](4/25): Loss: 0.0020 || Timer: 1.9311 sec.\n","===> Epoch[94](5/25): Loss: 0.0026 || Timer: 1.9324 sec.\n","===> Epoch[94](6/25): Loss: 0.0035 || Timer: 1.9308 sec.\n","===> Epoch[94](7/25): Loss: 0.0017 || Timer: 1.9316 sec.\n","===> Epoch[94](8/25): Loss: 0.0022 || Timer: 1.9487 sec.\n","===> Epoch[94](9/25): Loss: 0.0032 || Timer: 1.9319 sec.\n","===> Epoch[94](10/25): Loss: 0.0017 || Timer: 1.9301 sec.\n","===> Epoch[94](11/25): Loss: 0.0028 || Timer: 1.9340 sec.\n","===> Epoch[94](12/25): Loss: 0.0029 || Timer: 1.9305 sec.\n","===> Epoch[94](13/25): Loss: 0.0022 || Timer: 1.9350 sec.\n","===> Epoch[94](14/25): Loss: 0.0024 || Timer: 1.9297 sec.\n","===> Epoch[94](15/25): Loss: 0.0028 || Timer: 1.9321 sec.\n","===> Epoch[94](16/25): Loss: 0.0023 || Timer: 1.9481 sec.\n","===> Epoch[94](17/25): Loss: 0.0012 || Timer: 1.9367 sec.\n","===> Epoch[94](18/25): Loss: 0.0016 || Timer: 1.9321 sec.\n","===> Epoch[94](19/25): Loss: 0.0025 || Timer: 1.9342 sec.\n","===> Epoch[94](20/25): Loss: 0.0020 || Timer: 1.9310 sec.\n","===> Epoch[94](21/25): Loss: 0.0014 || Timer: 1.9330 sec.\n","===> Epoch[94](22/25): Loss: 0.0028 || Timer: 1.9307 sec.\n","===> Epoch[94](23/25): Loss: 0.0040 || Timer: 1.9330 sec.\n","===> Epoch[94](24/25): Loss: 0.0010 || Timer: 1.9507 sec.\n","===> Epoch[94](25/25): Loss: 0.0016 || Timer: 1.9308 sec.\n","===> Epoch 94 Complete: Avg. Loss: 0.0023\n","===> Epoch[95](1/25): Loss: 0.0018 || Timer: 1.9359 sec.\n","===> Epoch[95](2/25): Loss: 0.0013 || Timer: 1.9338 sec.\n","===> Epoch[95](3/25): Loss: 0.0016 || Timer: 1.9299 sec.\n","===> Epoch[95](4/25): Loss: 0.0017 || Timer: 1.9353 sec.\n","===> Epoch[95](5/25): Loss: 0.0015 || Timer: 1.9292 sec.\n","===> Epoch[95](6/25): Loss: 0.0017 || Timer: 1.9465 sec.\n","===> Epoch[95](7/25): Loss: 0.0014 || Timer: 1.9292 sec.\n","===> Epoch[95](8/25): Loss: 0.0013 || Timer: 1.9361 sec.\n","===> Epoch[95](9/25): Loss: 0.0020 || Timer: 1.9291 sec.\n","===> Epoch[95](10/25): Loss: 0.0023 || Timer: 1.9357 sec.\n","===> Epoch[95](11/25): Loss: 0.0018 || Timer: 1.9289 sec.\n","===> Epoch[95](12/25): Loss: 0.0021 || Timer: 1.9354 sec.\n","===> Epoch[95](13/25): Loss: 0.0018 || Timer: 1.9294 sec.\n","===> Epoch[95](14/25): Loss: 0.0024 || Timer: 1.9586 sec.\n","===> Epoch[95](15/25): Loss: 0.0024 || Timer: 1.9296 sec.\n","===> Epoch[95](16/25): Loss: 0.0042 || Timer: 1.9355 sec.\n","===> Epoch[95](17/25): Loss: 0.0045 || Timer: 1.9280 sec.\n","===> Epoch[95](18/25): Loss: 0.0038 || Timer: 1.9343 sec.\n","===> Epoch[95](19/25): Loss: 0.0029 || Timer: 1.9297 sec.\n","===> Epoch[95](20/25): Loss: 0.0065 || Timer: 1.9352 sec.\n","===> Epoch[95](21/25): Loss: 0.0027 || Timer: 1.9289 sec.\n","===> Epoch[95](22/25): Loss: 0.0055 || Timer: 1.9511 sec.\n","===> Epoch[95](23/25): Loss: 0.0050 || Timer: 1.9293 sec.\n","===> Epoch[95](24/25): Loss: 0.0026 || Timer: 1.9352 sec.\n","===> Epoch[95](25/25): Loss: 0.0059 || Timer: 1.9290 sec.\n","===> Epoch 95 Complete: Avg. Loss: 0.0028\n","===> Epoch[96](1/25): Loss: 0.0038 || Timer: 1.9473 sec.\n","===> Epoch[96](2/25): Loss: 0.0044 || Timer: 1.9328 sec.\n","===> Epoch[96](3/25): Loss: 0.0039 || Timer: 1.9308 sec.\n","===> Epoch[96](4/25): Loss: 0.0031 || Timer: 1.9565 sec.\n","===> Epoch[96](5/25): Loss: 0.0040 || Timer: 1.9312 sec.\n","===> Epoch[96](6/25): Loss: 0.0022 || Timer: 1.9346 sec.\n","===> Epoch[96](7/25): Loss: 0.0016 || Timer: 1.9305 sec.\n","===> Epoch[96](8/25): Loss: 0.0020 || Timer: 1.9338 sec.\n","===> Epoch[96](9/25): Loss: 0.0022 || Timer: 1.9303 sec.\n","===> Epoch[96](10/25): Loss: 0.0026 || Timer: 1.9338 sec.\n","===> Epoch[96](11/25): Loss: 0.0017 || Timer: 1.9313 sec.\n","===> Epoch[96](12/25): Loss: 0.0034 || Timer: 1.9454 sec.\n","===> Epoch[96](13/25): Loss: 0.0021 || Timer: 1.9298 sec.\n","===> Epoch[96](14/25): Loss: 0.0026 || Timer: 1.9334 sec.\n","===> Epoch[96](15/25): Loss: 0.0024 || Timer: 1.9309 sec.\n","===> Epoch[96](16/25): Loss: 0.0020 || Timer: 1.9332 sec.\n","===> Epoch[96](17/25): Loss: 0.0036 || Timer: 1.9309 sec.\n","===> Epoch[96](18/25): Loss: 0.0020 || Timer: 1.9323 sec.\n","===> Epoch[96](19/25): Loss: 0.0022 || Timer: 1.9295 sec.\n","===> Epoch[96](20/25): Loss: 0.0042 || Timer: 1.9502 sec.\n","===> Epoch[96](21/25): Loss: 0.0020 || Timer: 1.9304 sec.\n","===> Epoch[96](22/25): Loss: 0.0021 || Timer: 1.9328 sec.\n","===> Epoch[96](23/25): Loss: 0.0048 || Timer: 1.9298 sec.\n","===> Epoch[96](24/25): Loss: 0.0031 || Timer: 1.9340 sec.\n","===> Epoch[96](25/25): Loss: 0.0021 || Timer: 1.9304 sec.\n","===> Epoch 96 Complete: Avg. Loss: 0.0028\n","===> Epoch[97](1/25): Loss: 0.0060 || Timer: 1.9556 sec.\n","===> Epoch[97](2/25): Loss: 0.0018 || Timer: 1.9461 sec.\n","===> Epoch[97](3/25): Loss: 0.0051 || Timer: 1.9351 sec.\n","===> Epoch[97](4/25): Loss: 0.0016 || Timer: 1.9285 sec.\n","===> Epoch[97](5/25): Loss: 0.0068 || Timer: 1.9339 sec.\n","===> Epoch[97](6/25): Loss: 0.0037 || Timer: 1.9293 sec.\n","===> Epoch[97](7/25): Loss: 0.0039 || Timer: 1.9336 sec.\n","===> Epoch[97](8/25): Loss: 0.0036 || Timer: 1.9299 sec.\n","===> Epoch[97](9/25): Loss: 0.0040 || Timer: 1.9345 sec.\n","===> Epoch[97](10/25): Loss: 0.0034 || Timer: 1.9434 sec.\n","===> Epoch[97](11/25): Loss: 0.0027 || Timer: 1.9367 sec.\n","===> Epoch[97](12/25): Loss: 0.0018 || Timer: 1.9286 sec.\n","===> Epoch[97](13/25): Loss: 0.0032 || Timer: 1.9347 sec.\n","===> Epoch[97](14/25): Loss: 0.0016 || Timer: 1.9286 sec.\n","===> Epoch[97](15/25): Loss: 0.0032 || Timer: 1.9364 sec.\n","===> Epoch[97](16/25): Loss: 0.0020 || Timer: 1.9296 sec.\n","===> Epoch[97](17/25): Loss: 0.0026 || Timer: 1.9345 sec.\n","===> Epoch[97](18/25): Loss: 0.0021 || Timer: 1.9393 sec.\n","===> Epoch[97](19/25): Loss: 0.0028 || Timer: 1.9369 sec.\n","===> Epoch[97](20/25): Loss: 0.0019 || Timer: 1.9296 sec.\n","===> Epoch[97](21/25): Loss: 0.0018 || Timer: 1.9359 sec.\n","===> Epoch[97](22/25): Loss: 0.0013 || Timer: 1.9288 sec.\n","===> Epoch[97](23/25): Loss: 0.0024 || Timer: 1.9348 sec.\n","===> Epoch[97](24/25): Loss: 0.0016 || Timer: 1.9297 sec.\n","===> Epoch[97](25/25): Loss: 0.0021 || Timer: 1.9345 sec.\n","===> Epoch 97 Complete: Avg. Loss: 0.0029\n","===> Epoch[98](1/25): Loss: 0.0016 || Timer: 1.9564 sec.\n","===> Epoch[98](2/25): Loss: 0.0014 || Timer: 1.9300 sec.\n","===> Epoch[98](3/25): Loss: 0.0017 || Timer: 1.9328 sec.\n","===> Epoch[98](4/25): Loss: 0.0018 || Timer: 1.9307 sec.\n","===> Epoch[98](5/25): Loss: 0.0019 || Timer: 1.9338 sec.\n","===> Epoch[98](6/25): Loss: 0.0019 || Timer: 1.9299 sec.\n","===> Epoch[98](7/25): Loss: 0.0018 || Timer: 1.9334 sec.\n","===> Epoch[98](8/25): Loss: 0.0019 || Timer: 1.9312 sec.\n","===> Epoch[98](9/25): Loss: 0.0029 || Timer: 1.9532 sec.\n","===> Epoch[98](10/25): Loss: 0.0025 || Timer: 1.9324 sec.\n","===> Epoch[98](11/25): Loss: 0.0014 || Timer: 1.9341 sec.\n","===> Epoch[98](12/25): Loss: 0.0016 || Timer: 1.9310 sec.\n","===> Epoch[98](13/25): Loss: 0.0025 || Timer: 1.9334 sec.\n","===> Epoch[98](14/25): Loss: 0.0020 || Timer: 1.9326 sec.\n","===> Epoch[98](15/25): Loss: 0.0021 || Timer: 1.9328 sec.\n","===> Epoch[98](16/25): Loss: 0.0017 || Timer: 1.9359 sec.\n","===> Epoch[98](17/25): Loss: 0.0016 || Timer: 1.9530 sec.\n","===> Epoch[98](18/25): Loss: 0.0028 || Timer: 1.9314 sec.\n","===> Epoch[98](19/25): Loss: 0.0013 || Timer: 1.9365 sec.\n","===> Epoch[98](20/25): Loss: 0.0015 || Timer: 1.9313 sec.\n","===> Epoch[98](21/25): Loss: 0.0020 || Timer: 1.9331 sec.\n","===> Epoch[98](22/25): Loss: 0.0018 || Timer: 1.9288 sec.\n","===> Epoch[98](23/25): Loss: 0.0025 || Timer: 1.9337 sec.\n","===> Epoch[98](24/25): Loss: 0.0018 || Timer: 1.9310 sec.\n","===> Epoch[98](25/25): Loss: 0.0012 || Timer: 1.9508 sec.\n","===> Epoch 98 Complete: Avg. Loss: 0.0019\n","===> Epoch[99](1/25): Loss: 0.0024 || Timer: 1.9424 sec.\n","===> Epoch[99](2/25): Loss: 0.0015 || Timer: 1.9372 sec.\n","===> Epoch[99](3/25): Loss: 0.0011 || Timer: 1.9287 sec.\n","===> Epoch[99](4/25): Loss: 0.0020 || Timer: 1.9351 sec.\n","===> Epoch[99](5/25): Loss: 0.0026 || Timer: 1.9291 sec.\n","===> Epoch[99](6/25): Loss: 0.0015 || Timer: 1.9356 sec.\n","===> Epoch[99](7/25): Loss: 0.0013 || Timer: 1.9452 sec.\n","===> Epoch[99](8/25): Loss: 0.0010 || Timer: 1.9420 sec.\n","===> Epoch[99](9/25): Loss: 0.0019 || Timer: 1.9291 sec.\n","===> Epoch[99](10/25): Loss: 0.0012 || Timer: 1.9367 sec.\n","===> Epoch[99](11/25): Loss: 0.0016 || Timer: 1.9304 sec.\n","===> Epoch[99](12/25): Loss: 0.0012 || Timer: 1.9358 sec.\n","===> Epoch[99](13/25): Loss: 0.0023 || Timer: 1.9289 sec.\n","===> Epoch[99](14/25): Loss: 0.0020 || Timer: 1.9353 sec.\n","===> Epoch[99](15/25): Loss: 0.0017 || Timer: 1.9511 sec.\n","===> Epoch[99](16/25): Loss: 0.0021 || Timer: 1.9364 sec.\n","===> Epoch[99](17/25): Loss: 0.0013 || Timer: 1.9295 sec.\n","===> Epoch[99](18/25): Loss: 0.0016 || Timer: 1.9359 sec.\n","===> Epoch[99](19/25): Loss: 0.0020 || Timer: 1.9301 sec.\n","===> Epoch[99](20/25): Loss: 0.0013 || Timer: 1.9368 sec.\n","===> Epoch[99](21/25): Loss: 0.0014 || Timer: 1.9332 sec.\n","===> Epoch[99](22/25): Loss: 0.0018 || Timer: 1.9369 sec.\n","===> Epoch[99](23/25): Loss: 0.0027 || Timer: 1.9435 sec.\n","===> Epoch[99](24/25): Loss: 0.0021 || Timer: 1.9358 sec.\n","===> Epoch[99](25/25): Loss: 0.0031 || Timer: 1.9297 sec.\n","===> Epoch 99 Complete: Avg. Loss: 0.0018\n","===> Epoch[100](1/25): Loss: 0.0021 || Timer: 1.9396 sec.\n","===> Epoch[100](2/25): Loss: 0.0015 || Timer: 1.9331 sec.\n","===> Epoch[100](3/25): Loss: 0.0021 || Timer: 1.9310 sec.\n","===> Epoch[100](4/25): Loss: 0.0015 || Timer: 1.9344 sec.\n","===> Epoch[100](5/25): Loss: 0.0019 || Timer: 1.9301 sec.\n","===> Epoch[100](6/25): Loss: 0.0019 || Timer: 1.9507 sec.\n","===> Epoch[100](7/25): Loss: 0.0015 || Timer: 1.9298 sec.\n","===> Epoch[100](8/25): Loss: 0.0018 || Timer: 1.9328 sec.\n","===> Epoch[100](9/25): Loss: 0.0018 || Timer: 1.9302 sec.\n","===> Epoch[100](10/25): Loss: 0.0013 || Timer: 1.9341 sec.\n","===> Epoch[100](11/25): Loss: 0.0021 || Timer: 1.9332 sec.\n","===> Epoch[100](12/25): Loss: 0.0036 || Timer: 1.9333 sec.\n","===> Epoch[100](13/25): Loss: 0.0019 || Timer: 1.9301 sec.\n","===> Epoch[100](14/25): Loss: 0.0023 || Timer: 1.9499 sec.\n","===> Epoch[100](15/25): Loss: 0.0033 || Timer: 1.9308 sec.\n","===> Epoch[100](16/25): Loss: 0.0019 || Timer: 1.9337 sec.\n","===> Epoch[100](17/25): Loss: 0.0041 || Timer: 1.9333 sec.\n","===> Epoch[100](18/25): Loss: 0.0062 || Timer: 1.9345 sec.\n","===> Epoch[100](19/25): Loss: 0.0021 || Timer: 1.9305 sec.\n","===> Epoch[100](20/25): Loss: 0.0044 || Timer: 1.9336 sec.\n","===> Epoch[100](21/25): Loss: 0.0033 || Timer: 1.9305 sec.\n","===> Epoch[100](22/25): Loss: 0.0073 || Timer: 1.9566 sec.\n","===> Epoch[100](23/25): Loss: 0.0027 || Timer: 1.9295 sec.\n","===> Epoch[100](24/25): Loss: 0.0049 || Timer: 1.9340 sec.\n","===> Epoch[100](25/25): Loss: 0.0036 || Timer: 1.9306 sec.\n","===> Epoch 100 Complete: Avg. Loss: 0.0028\n","Checkpoint saved to /content/gdrive/My Drive/졸업논문/졸업논문/scale=2/weights_scale=2/WCNN_epoch_100.pth\n","Finished Training\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IJZEGSHLlw9i","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620788082310,"user_tz":-540,"elapsed":15485,"user":{"displayName":"김정기","photoUrl":"","userId":"02654207523640478753"}},"outputId":"f246c0cf-7906-40d8-a84b-eac29f23c13e"},"source":["# Test\n","\n","from __future__ import print_function\n","import argparse\n","\n","import os\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.autograd import Variable\n","import torch.backends.cudnn as cudnn\n","from torch.utils.data import DataLoader\n","from functools import reduce\n","from math import log10\n","\n","# from scipy.misc import imsave\n","import scipy.io as sio\n","import time\n","import cv2\n","import easydict\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","\n","opt = easydict.EasyDict({ \n","    \"testBatchSize\": 1,     # 이미지를 1개씩불러옴 \n","    \"upscale_factor\": 2,    # Upscale 정도\n","    \"input_channel\": 3,     # WCNN model 입력의 Channel (color = 3, gray = 1)\n","\n","    \"model_type\": \"WCNN\",         # 모델이름\n","    \n","    \"input_dir\":\"/content/gdrive/My Drive/졸업논문/data_800개/test\",  # test dataset 불러올위치\n","    \"test_dataset\": \"low_color_test\",                             # test에 사용할 dataset 종류\n","    \"output\": \"/content/gdrive/My Drive/졸업논문/졸업논문/scale=2/results_scale=2/\", # 결과영상 저장위치\n","    \"model_type\": \"WCNN\",\n","    \"model\": \"/content/gdrive/My Drive/졸업논문/졸업논문/scale=2/weights_scale=2/WCNN_epoch_100.pth\",\n","    # test에 사용할 weight 불러올 파일 경로\n","    \n","    \"pretrained\": True,\n","    \"data_augmentation\": False,\n","    \"gpu_mode\": True,\n","    \"threads\": 0, \n","    \"gpus\": 1 # 사용할 gpu 번호\n","    })\n","\n","'''\n","1. GPU 설정 및 parameter print\n","'''\n","gpus_list = range(opt.gpus)\n","cudnn.benchmark = True\n","print(opt)\n","\n","cuda = opt.gpu_mode\n","if cuda and not torch.cuda.is_available():\n","    raise Exception(\"No GPU found, please run without --cuda\")\n","\n","'''\n","2. Test Data 로드\n","'''\n","print('===> Loading datasets')\n","test_set = get_eval_set(os.path.join(opt.input_dir,opt.test_dataset), opt.upscale_factor)\n","testing_data_loader = DataLoader(dataset=test_set, num_workers=opt.threads, batch_size=opt.testBatchSize, shuffle=False)\n","\n","'''\n","3. Criterion 정의 \n","  -> MSE loss 사용\n","'''\n","criterion = nn.MSELoss() \n","\n","'''\n","4. NN 정의\n","'''\n","model = WCNN()\n","\n","'''\n","5. pretrained model 및 GPU 사용 여부 설정\n","'''\n","if cuda:\n","    model = model.cuda(gpus_list[0])\n","    model = torch.nn.DataParallel(model, device_ids=gpus_list)\n","    criterion = criterion.cuda(gpus_list[0])\n","if opt.pretrained:\n","    model_name = os.path.join(opt.model)\n","    checkpoint = torch.load(model_name)\n","\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","    loss = checkpoint['loss']\n","    epoch = checkpoint['epoch']\n","    print('Pre-trained SR model is loaded.')\n","    # pretrained model 불러오기\n","    \n","'''\n","6. 이미지 저장 함수 -> 원본 이미지의 크기 그대로 저장 됨\n","'''\n","def save_img(img, img_name):\n","    save_img = img.squeeze().clamp(0, 1).numpy().transpose(1,2,0)\n","    # save img\n","    save_dir=os.path.join(opt.output,opt.test_dataset)\n","    if not os.path.exists(save_dir):\n","        os.makedirs(save_dir)\n","        \n","    save_fn = save_dir +'/'+ img_name\n","    cv2.imwrite(save_fn, cv2.cvtColor(save_img*255, cv2.COLOR_BGR2RGB),  [cv2.IMWRITE_PNG_COMPRESSION, 0])\n","    \n","'''\n","7. 한번의 epoch 에서 수행하는 과정 정의\n","'''\n","def eval():\n","    avg_psnr = 0\n","    psnr_sq = 0\n","    model.eval()\n","    count_image = 0\n","    # model.eval() 을 호출하여 평가(test) 모드로 변환 \n","    \n","    for batch_data in testing_data_loader:\n","        with torch.no_grad():\n","            input, bicubic, target, file_name = Variable(batch_data[0]), Variable(batch_data[1]), Variable(batch_data[2]), batch_data[3] \n","                                                                \n","        if cuda:\n","            input = input.cuda(gpus_list[0])\n","            bicubic = bicubic.cuda(gpus_list[0])\n","            target = target.cuda(gpus_list[0])\n","\n","        prediction = model(bicubic)\n","        print(prediction.shape, target.shape)\n","\n","        if prediction.shape == target.shape:\n","          mse = criterion(prediction, target)\n","          psnr = 10 * log10(1 / mse.item())\n","          avg_psnr += psnr\n","          psnr_sq += psnr*psnr\n","          count_image += 1\n","        # Image.BICUBIC 에서 이미지의 H나 W가 3의 배수가 아니면 나머지를 버려버리기 때문에 prediction 과 target 의 shape 이 맞지 않는 경우가 생김\n","        \n","\n","        save_img(prediction.cpu().data, 'SR_'+file_name[0])\n","        save_img(bicubic.cpu().data, 'blur_'+file_name[0])\n","        # save_img(target.cpu().data, file_name[0]+'/original')\n","       \n","    average = avg_psnr/count_image\n","    variance = psnr_sq/count_image-average*average\n","        \n","        # psnr 의 분산\n","    print('Image Amount: %d' %(count_image))\n","    print(\"===> epoch number : %d\" % (epoch)) \n","    print(\"===> Processing Done, Average PSNR : %.4f\" % (average))\n","    print(\"===>PSNR Variance : %.4f\" % (variance))\n","    \n","'''\n","우리는 훈련시에 128x128 이미지를 SR 하도록 훈련 했지만,\n","test 에서 입력 이미지의 크기는 상관이 없다\n","왜냐하면, 우리는 훈련하여 'filter' 를 얻었고,\n","입력의 크기가 128x128 가 아니더라도 훈련된 filter 를 stride 하면서 Conv. 연산 해 주면 되는 것이기 때문이다.\n","'''\n","\n","##Eval Start!!!!\n","if __name__ == '__main__':\n","    eval()\n","    \n","print('finish')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","{'testBatchSize': 1, 'upscale_factor': 2, 'input_channel': 3, 'model_type': 'WCNN', 'input_dir': '/content/gdrive/My Drive/졸업논문/data_800개/test', 'test_dataset': 'low_color_test', 'output': '/content/gdrive/My Drive/졸업논문/졸업논문/scale=2/results_scale=2/', 'model': '/content/gdrive/My Drive/졸업논문/졸업논문/scale=2/weights_scale=2/WCNN_epoch_100.pth', 'pretrained': True, 'data_augmentation': False, 'gpu_mode': True, 'threads': 0, 'gpus': 1}\n","===> Loading datasets\n","Pre-trained SR model is loaded.\n","torch.Size([1, 3, 436, 700]) torch.Size([1, 3, 437, 700])\n","torch.Size([1, 3, 534, 800]) torch.Size([1, 3, 534, 800])\n","torch.Size([1, 3, 532, 800]) torch.Size([1, 3, 532, 800])\n","Image Amount: 2\n","===> epoch number : 100\n","===> Processing Done, Average PSNR : 23.7153\n","===>PSNR Variance : 0.1042\n","finish\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZXs3luv82Tug","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617725335864,"user_tz":-540,"elapsed":20778,"user":{"displayName":"김정기","photoUrl":"","userId":"02654207523640478753"}},"outputId":"7ba59b2b-f67b-45b0-ecba-9e3a238f9995"},"source":["# Test - blur 되고 down scale 된 이미지가 아닌 원본 이미지를 입력으로 넣음\n","\n","from __future__ import print_function\n","import argparse\n","\n","import os\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.autograd import Variable\n","from torch.utils.data import DataLoader\n","import torch.backends.cudnn as cudnn\n","from functools import reduce\n","from math import log10\n","\n","# from scipy.misc import imsave\n","import scipy.io as sio\n","import time\n","import cv2\n","import easydict\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","opt = easydict.EasyDict({ \n","    \"testBatchSize\": 1,     # 이미지를 1개씩불러옴 \n","    \"upscale_factor\": 3,    # Upscale 정도\n","    \"input_channel\": 3,     # ESPCN model 입력의 Channel (color = 3, gray = 1)\n","\n","    \"model_type\": \"ESPCN\",         # 모델이름\n","    \n","    \"input_dir\":\"/content/gdrive/My Drive/졸업논문/data_800개/test\",  # test dataset 불러올위치\n","    \"test_dataset\": \"Color_test\",                             # test에 사용할 dataset 종류\n","    \"output\": \"/content/gdrive/My Drive/졸업논문/ESPCN/results/\", # 결과영상 저장위치\n","    \"model_type\": \"ESPCN\",\n","    \"model\": \"/content/gdrive/My Drive/졸업논문/ESPCN/weights/ESPCN_epoch_200.pth\",\n","    # test에 사용할 weight 불러올 파일 경로\n","    \n","    \"pretrained\": True,\n","    \"data_augmentation\": False,\n","    \"gpu_mode\": True,\n","    \"threads\": 0, \n","    \"gpus\": 1 # 사용할 gpu 번호\n","    })\n","\n","'''\n","1. GPU 설정 및 parameter print\n","'''\n","gpus_list = range(opt.gpus)\n","cudnn.benchmark = True\n","print(opt)\n","\n","cuda = opt.gpu_mode\n","if cuda and not torch.cuda.is_available():\n","    raise Exception(\"No GPU found, please run without --cuda\")\n","\n","'''\n","2. Test Data 로드\n","'''\n","print('===> Loading datasets')\n","test_set = get_eval_set(os.path.join(opt.input_dir,opt.test_dataset), opt.upscale_factor)\n","testing_data_loader = DataLoader(dataset=test_set, num_workers=opt.threads, batch_size=opt.testBatchSize, shuffle=False)\n","\n","'''\n","3. Criterion 정의 \n","  -> MSE loss 사용\n","'''\n","criterion = nn.MSELoss() \n","\n","'''\n","4. NN 정의\n","'''\n","model = model = ESPCN(input_channel=3, base_channel=64, upscale_factor=3, activation='tanh', norm='batch')\n","\n","'''\n","5. pretrained model 및 GPU 사용 여부 설정\n","'''\n","if cuda:\n","    model = model.cuda(gpus_list[0])\n","    model = torch.nn.DataParallel(model, device_ids=gpus_list)\n","    criterion = criterion.cuda(gpus_list[0])\n","if opt.pretrained:\n","    model_name = os.path.join(opt.model)\n","    checkpoint = torch.load(model_name)\n","\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","    loss = checkpoint['loss']\n","    opt.start_epoch = checkpoint['epoch']\n","    print('Pre-trained SR model is loaded.')\n","    # pretrained model 불러오기\n","    \n","'''\n","6. 이미지 저장 함수 -> 원본 이미지의 크기 그대로 저장 됨\n","'''\n","def save_img(img, img_name):\n","    save_img = img.squeeze().clamp(0, 1).numpy().transpose(1,2,0)\n","    # save img\n","    save_dir=os.path.join(opt.output,opt.test_dataset)\n","    if not os.path.exists(save_dir):\n","        os.makedirs(save_dir)\n","        \n","    save_fn = save_dir +'/'+ img_name\n","    cv2.imwrite(save_fn, cv2.cvtColor(save_img*255, cv2.COLOR_BGR2RGB),  [cv2.IMWRITE_PNG_COMPRESSION, 0])\n","    \n","'''\n","7. 한번의 epoch 에서 수행하는 과정 정의\n","'''\n","def eval():\n","    avg_psnr = 0\n","    psnr_sq = 0\n","    model.eval()\n","    # model.eval() 을 호출하여 평가(test) 모드로 변환 \n","    \n","    for batch_data in testing_data_loader:\n","        with torch.no_grad():\n","            input, blur_img, target, file_name = Variable(batch_data[0]), Variable(batch_data[1]), Variable(batch_data[2]), batch_data[3] \n","                                                                \n","        if cuda:\n","            input = input.cuda(gpus_list[0])\n","            blur_img = blur_img.cuda(gpus_list[0])\n","            target = target.cuda(gpus_list[0])\n","\n","        SR_img = model(target)\n","        # target = 원본 이미지 -> 그러므로 원본 이미지가 그대로 들어가서 3배 scale 됨\n","        print(SR_img.shape, target.shape)\n","      \n","      \n","        save_img(SR_img.cpu().data, 'Origin_SR_'+file_name[0])\n","    \n","'''\n","우리는 훈련시에 128x128 이미지를 SR 하도록 훈련 했지만,\n","test 에서 입력 이미지의 크기는 상관이 없다\n","왜냐하면, 우리는 훈련하여 'filter' 를 얻었고,\n","입력의 크기가 128x128 가 아니더라도 훈련된 filter 를 stride 하면서 Conv. 연산 해 주면 되는 것이기 때문이다.\n","'''\n","\n","##Eval Start!!!!\n","if __name__ == '__main__':\n","    eval()\n","    \n","print('finish')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","{'testBatchSize': 1, 'upscale_factor': 3, 'input_channel': 3, 'model_type': 'ESPCN', 'input_dir': '/content/gdrive/My Drive/졸업논문/data_800개/test', 'test_dataset': 'Color_test', 'output': '/content/gdrive/My Drive/졸업논문/ESPCN/results/', 'model': '/content/gdrive/My Drive/졸업논문/ESPCN/weights/ESPCN_epoch_200.pth', 'pretrained': True, 'data_augmentation': False, 'gpu_mode': True, 'threads': 0, 'gpus': 1}\n","===> Loading datasets\n","Pre-trained SR model is loaded.\n","torch.Size([1, 3, 6120, 4068]) torch.Size([1, 3, 2040, 1356])\n","torch.Size([1, 3, 4932, 6120]) torch.Size([1, 3, 1644, 2040])\n","torch.Size([1, 3, 4068, 6120]) torch.Size([1, 3, 1356, 2040])\n","torch.Size([1, 3, 4068, 6120]) torch.Size([1, 3, 1356, 2040])\n","finish\n"],"name":"stdout"}]}]}