{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"WCNN_scale=2_insize=3_lr=0.001_patch=64.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a8ZwrAfjd580","executionInfo":{"status":"ok","timestamp":1621532938875,"user_tz":-540,"elapsed":398,"user":{"displayName":"김정기","photoUrl":"","userId":"02654207523640478753"}},"outputId":"e1d12bf6-592e-48dd-dec3-ee330da74738"},"source":["# 모델 정의\n","\n","import os\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision.transforms import *\n","import torch\n","import math\n","from os.path import join\n","import torch.utils.data as data\n","import numpy as np\n","from os import listdir\n","from os.path import join\n","from PIL import Image, ImageOps\n","import random\n","from random import randrange\n","from math import sqrt\n","from torchsummary import summary\n","\n","'''\n","1. Channel_weighted_Conv\n","   어떤 '한개의' filter 에 대해, \n","   입력 [r^2, N, N] 인 feature map 의 각 channel 의 conv. 결과를 순차적으로 mapping 한 [1, rN, rN] 크기의 feature map 생성하고,\n","   생성한 feature map 에 rxr inner filtering 을 적용한 [1, N, N] 크기의 결과를 출력하는 함수 \n","'''\n","class Channel_weighted_Conv(nn.Module):\n","  def __init__(self, input_size, kernel_size, stride=1, bias=True):\n","    super(Channel_weighted_Conv, self).__init__()\n","    self.input_size = input_size \n","    # input_size = r^2\n","\n","    self.conv = torch.nn.Conv2d(1, 1, kernel_size, stride, padding=int((kernel_size-1)/2), bias=bias)\n","    # 입력 feature map [batch, r^2, N, N]에서 [batch, i, N, N] 을 입력으로 받아 1 개의 feature map 출력\n","    # 출력이 [batch, i, N, N] 가 되게 하기 위해 padding = int((kernel_size-1)/2)\n","    self.PS =  nn.PixelShuffle (upscale_factor = int(math.sqrt(input_size)))\n","    # upscale_factor = r\n","    self.inner_conv = torch.nn.Conv2d(1, 1, kernel_size=int(math.sqrt(input_size)), stride=int(math.sqrt(input_size)), padding=0, bias=bias)\n","\n","    '''\n","    apply 함수로 initialization 하기 힘들기 때문에 class 내에서 initialization 을 수행하도록 함\n","    '''\n","    for m in self.modules():\n","        # 이 class 에서 정의한 self.(변수)[인스턴스 변수] 목록 (conv, PS, inner_conv) 불러오기 \n","            classname = m.__class__.__name__\n","            # 불러온 module의 class 이름\n","            if classname.find('Conv2d') != -1:\n","                torch.nn.init.kaiming_normal_(m.weight)\n","                if m.bias is not None:\n","                    m.bias.data.zero_()\n","            # Conv2d Layer 라면 He 방법으로 해당 Layer 의 weight 들을 초기화, bias 가 True 면 bias 를 0 으로 초기화\n","            elif classname.find('ConvTranspose2d') != -1:\n","                torch.nn.init.kaiming_normal_(m.weight)\n","                if m.bias is not None:\n","                    m.bias.data.zero_()\n","           # ConvTranspose2d Layer 라면 He 방법으로 해당 Layer 의 weight 들을 초기화, bias 가 True 면 bias 를 0 으로 초기화\n","\n","  def forward(self, x):\n","    s = self.conv(x[:, 0:1, :, :])\n","\n","    for i in range(1, self.input_size):\n","      m = self.conv(x[:, i:i+1, :, :])\n","      s = torch.cat([s, m], dim=1)\n","      \n","    # s.shape = [batch, r^2, N, N]\n","    # s = 입력 feature map의 각 channel에 대해 한개의 filter 와의 단순 convolution 결과 feature map\n","    \n","    ps = self.PS(s)\n","    # ps.shape = [batch, 1, rN, rN]\n","    # ps = 한 filter에 대해 입력 feature map 의 각 channel 가중치를 학습하기 전 feature map\n","\n","    out = self.inner_conv(ps)\n","    # out.shape = [batch, 1, N, N]\n","    # out = 가중치를 학습하고 난 후 필터링 결과\n","    return out\n","\n","'''\n","2. WCNN_block \n","   기존의 Conv2d 와 같은 입력을 받아, 각 Channel 의 가중치 (inner_filter) 를 학습하는 과정을 추가하여\n","   입력과 동일한 크기의 output_size 개 만큼의 feature map 을 출력하는 New Conv2d layer\n","'''\n","class WCNN_block(nn.Module):\n","  def __init__(self, input_size, output_size, kernel_size):\n","    super(WCNN_block, self).__init__()\n","    self.filters = [0]*output_size\n","\n","    '''\n","    여기서 filter 갯수(=output_size)만큼 Channel_weighted_Conv 을 list 형태로 담고,\n","    '''\n","    self.filters = nn.ModuleList([Channel_weighted_Conv(input_size, kernel_size, stride=1, bias=True) for _ in range(0, output_size)])\n","    self.filter_num = output_size\n","  \n","  def forward(self, x):\n","    '''\n","    여기서 각 Channel_weighted_Conv에 x(입력) 를 대입하고 나온 출력을 concatenation 해 준다.\n","    -> ModuleList 는 list 안의 각 Module 을 하나씩 접근 할 수 있게 해 줌\n","    '''\n","    out = self.filters[0](x)\n","    for i in range(1, self.filter_num):\n","      filtering = self.filters[i](x)\n","      out = torch.cat([out, filtering], dim=1)\n","    # out.shape = [batch, K, N, N]\n","    # out = 각 filter 들의 WCNN 결과의 concatenation\n","    return out\n","\n","'''\n","3. ConvBlock\n","'''\n","class ConvBlock(nn.Module):\n","    def __init__(self, input_size, output_size, kernel_size=3, stride=1, padding=1, bias=True, activation='relu', norm=None):\n","        super(ConvBlock, self).__init__()\n","        self.conv = torch.nn.Conv2d(input_size, output_size, kernel_size, stride, padding, bias=bias)\n","\n","        self.norm = norm\n","        if self.norm =='batch':\n","            self.bn = torch.nn.BatchNorm2d(output_size)\n","        elif self.norm == 'instance':\n","            self.bn = torch.nn.InstanceNorm2d(output_size)\n","        \n","        # self.bn : Conv Layer 출력에서 normalization 을 Instance 로 할지 Batch 로 할지 선택\n","        \n","        self.activation = activation\n","        if self.activation == 'relu':\n","            self.act = torch.nn.ReLU(True)\n","        elif self.activation == 'prelu':\n","            self.act = torch.nn.PReLU()\n","        elif self.activation == 'lrelu':\n","            self.act = torch.nn.LeakyReLU(0.2, True)\n","        elif self.activation == 'tanh':\n","            self.act = torch.nn.Tanh()\n","        elif self.activation == 'sigmoid':\n","            self.act = torch.nn.Sigmoid()\n","        \n","        # self.act : Conv Layer 출력 Activation Function 선택\n","\n","        for m in self.modules():\n","            classname = m.__class__.__name__\n","            if classname.find('Conv2d') != -1:\n","                torch.nn.init.kaiming_normal_(m.weight)\n","                if m.bias is not None:\n","                    m.bias.data.zero_()\n","            # Conv2d Layer 라면 He 방법으로 해당 Layer 의 weight 들을 초기화, bias 가 True 면 bias 를 0 으로 초기화\n","            elif classname.find('ConvTranspose2d') != -1:\n","                torch.nn.init.kaiming_normal_(m.weight)\n","                if m.bias is not None:\n","                    m.bias.data.zero_()\n","           # ConvTranspose2d Layer 라면 He 방법으로 해당 Layer 의 weight 들을 초기화, bias 가 True 면 bias 를 0 으로 초기화\n","        \n","    def forward(self, x):\n","        if self.norm is not None:\n","            out = self.bn(self.conv(x))\n","        else:\n","            out = self.conv(x)\n","\n","        if self.activation is not None:\n","            return self.act(out)\n","        else:\n","            return out\n","\n","'''\n","4. WCNN\n","'''\n","class WCNN(nn.Module):\n","    def __init__(self):\n","        super(WCNN, self).__init__()\n","        \n","        '''\n","        1. layer2 만을 WCNN_block 으로 바꿈\n","        2. WCNN_block 의 input_size = r^2 이어야 하는 것을 유의함\n","        '''\n","        self.layer1 = ConvBlock(3, 64, kernel_size=9, stride=1, padding=4, activation='relu', norm=None)\n","        self.layer2 = nn.Sequential(\n","            WCNN_block(input_size=64, output_size=32, kernel_size=3),\n","            nn.ReLU(True),\n","        )\n","        # WCNN_block 의 Kernel_size = 홀수 여야 출력이미지의 size 가 입력과 같아진다\n","        self.layer3 = self.layer3 = ConvBlock(32, 3, kernel_size=5, stride=1, padding=2, activation=None, norm=None)\n","\n","    def forward(self, x):\n","        f1 = self.layer1(x)\n","        f2 = self.layer2(f1)\n","        y = self.layer3(f2)\n","        \n","        return y\n","print('finish')\n"],"execution_count":4,"outputs":[{"output_type":"stream","text":["finish\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LbuS2FoTv_Ai","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620736339270,"user_tz":-540,"elapsed":2006,"user":{"displayName":"김정기","photoUrl":"","userId":"02654207523640478753"}},"outputId":"32f1bde2-d27c-4070-a93d-0e7828d91ae7"},"source":["# 모델 확인\n","\n","import os\n","import torch\n","import torch.nn as nn\n","import torch.backends.cudnn as cudnn\n","from google.colab import drive\n","\n","\n","drive.mount('/content/gdrive')\n","\n","'''\n","1. GPU 설정 및 parameter print\n","'''\n","gpus_list = range(1)\n","cudnn.benchmark = True\n","\n","cuda = True\n","if cuda and not torch.cuda.is_available():\n","    raise Exception(\"No GPU found, please run without --cuda\")\n","\n","model = WCNN()\n","\n","'''\n","4. GPU 사용 여부 및 pretrained model 사용 여부 설정\n","'''\n","if cuda:\n","    model = model.cuda(gpus_list[0])\n","    model = torch.nn.DataParallel(model, device_ids=gpus_list)\n","    \n","summary(model, (3,32,32))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 64, 32, 32]          15,616\n","              ReLU-2           [-1, 64, 32, 32]               0\n","         ConvBlock-3           [-1, 64, 32, 32]               0\n","            Conv2d-4            [-1, 1, 32, 32]              10\n","            Conv2d-5            [-1, 1, 32, 32]              10\n","            Conv2d-6            [-1, 1, 32, 32]              10\n","            Conv2d-7            [-1, 1, 32, 32]              10\n","            Conv2d-8            [-1, 1, 32, 32]              10\n","            Conv2d-9            [-1, 1, 32, 32]              10\n","           Conv2d-10            [-1, 1, 32, 32]              10\n","           Conv2d-11            [-1, 1, 32, 32]              10\n","           Conv2d-12            [-1, 1, 32, 32]              10\n","           Conv2d-13            [-1, 1, 32, 32]              10\n","           Conv2d-14            [-1, 1, 32, 32]              10\n","           Conv2d-15            [-1, 1, 32, 32]              10\n","           Conv2d-16            [-1, 1, 32, 32]              10\n","           Conv2d-17            [-1, 1, 32, 32]              10\n","           Conv2d-18            [-1, 1, 32, 32]              10\n","           Conv2d-19            [-1, 1, 32, 32]              10\n","           Conv2d-20            [-1, 1, 32, 32]              10\n","           Conv2d-21            [-1, 1, 32, 32]              10\n","           Conv2d-22            [-1, 1, 32, 32]              10\n","           Conv2d-23            [-1, 1, 32, 32]              10\n","           Conv2d-24            [-1, 1, 32, 32]              10\n","           Conv2d-25            [-1, 1, 32, 32]              10\n","           Conv2d-26            [-1, 1, 32, 32]              10\n","           Conv2d-27            [-1, 1, 32, 32]              10\n","           Conv2d-28            [-1, 1, 32, 32]              10\n","           Conv2d-29            [-1, 1, 32, 32]              10\n","           Conv2d-30            [-1, 1, 32, 32]              10\n","           Conv2d-31            [-1, 1, 32, 32]              10\n","           Conv2d-32            [-1, 1, 32, 32]              10\n","           Conv2d-33            [-1, 1, 32, 32]              10\n","           Conv2d-34            [-1, 1, 32, 32]              10\n","           Conv2d-35            [-1, 1, 32, 32]              10\n","           Conv2d-36            [-1, 1, 32, 32]              10\n","           Conv2d-37            [-1, 1, 32, 32]              10\n","           Conv2d-38            [-1, 1, 32, 32]              10\n","           Conv2d-39            [-1, 1, 32, 32]              10\n","           Conv2d-40            [-1, 1, 32, 32]              10\n","           Conv2d-41            [-1, 1, 32, 32]              10\n","           Conv2d-42            [-1, 1, 32, 32]              10\n","           Conv2d-43            [-1, 1, 32, 32]              10\n","           Conv2d-44            [-1, 1, 32, 32]              10\n","           Conv2d-45            [-1, 1, 32, 32]              10\n","           Conv2d-46            [-1, 1, 32, 32]              10\n","           Conv2d-47            [-1, 1, 32, 32]              10\n","           Conv2d-48            [-1, 1, 32, 32]              10\n","           Conv2d-49            [-1, 1, 32, 32]              10\n","           Conv2d-50            [-1, 1, 32, 32]              10\n","           Conv2d-51            [-1, 1, 32, 32]              10\n","           Conv2d-52            [-1, 1, 32, 32]              10\n","           Conv2d-53            [-1, 1, 32, 32]              10\n","           Conv2d-54            [-1, 1, 32, 32]              10\n","           Conv2d-55            [-1, 1, 32, 32]              10\n","           Conv2d-56            [-1, 1, 32, 32]              10\n","           Conv2d-57            [-1, 1, 32, 32]              10\n","           Conv2d-58            [-1, 1, 32, 32]              10\n","           Conv2d-59            [-1, 1, 32, 32]              10\n","           Conv2d-60            [-1, 1, 32, 32]              10\n","           Conv2d-61            [-1, 1, 32, 32]              10\n","           Conv2d-62            [-1, 1, 32, 32]              10\n","           Conv2d-63            [-1, 1, 32, 32]              10\n","           Conv2d-64            [-1, 1, 32, 32]              10\n","           Conv2d-65            [-1, 1, 32, 32]              10\n","           Conv2d-66            [-1, 1, 32, 32]              10\n","           Conv2d-67            [-1, 1, 32, 32]              10\n","     PixelShuffle-68          [-1, 1, 256, 256]               0\n","           Conv2d-69            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-70            [-1, 1, 32, 32]               0\n","           Conv2d-71            [-1, 1, 32, 32]              10\n","           Conv2d-72            [-1, 1, 32, 32]              10\n","           Conv2d-73            [-1, 1, 32, 32]              10\n","           Conv2d-74            [-1, 1, 32, 32]              10\n","           Conv2d-75            [-1, 1, 32, 32]              10\n","           Conv2d-76            [-1, 1, 32, 32]              10\n","           Conv2d-77            [-1, 1, 32, 32]              10\n","           Conv2d-78            [-1, 1, 32, 32]              10\n","           Conv2d-79            [-1, 1, 32, 32]              10\n","           Conv2d-80            [-1, 1, 32, 32]              10\n","           Conv2d-81            [-1, 1, 32, 32]              10\n","           Conv2d-82            [-1, 1, 32, 32]              10\n","           Conv2d-83            [-1, 1, 32, 32]              10\n","           Conv2d-84            [-1, 1, 32, 32]              10\n","           Conv2d-85            [-1, 1, 32, 32]              10\n","           Conv2d-86            [-1, 1, 32, 32]              10\n","           Conv2d-87            [-1, 1, 32, 32]              10\n","           Conv2d-88            [-1, 1, 32, 32]              10\n","           Conv2d-89            [-1, 1, 32, 32]              10\n","           Conv2d-90            [-1, 1, 32, 32]              10\n","           Conv2d-91            [-1, 1, 32, 32]              10\n","           Conv2d-92            [-1, 1, 32, 32]              10\n","           Conv2d-93            [-1, 1, 32, 32]              10\n","           Conv2d-94            [-1, 1, 32, 32]              10\n","           Conv2d-95            [-1, 1, 32, 32]              10\n","           Conv2d-96            [-1, 1, 32, 32]              10\n","           Conv2d-97            [-1, 1, 32, 32]              10\n","           Conv2d-98            [-1, 1, 32, 32]              10\n","           Conv2d-99            [-1, 1, 32, 32]              10\n","          Conv2d-100            [-1, 1, 32, 32]              10\n","          Conv2d-101            [-1, 1, 32, 32]              10\n","          Conv2d-102            [-1, 1, 32, 32]              10\n","          Conv2d-103            [-1, 1, 32, 32]              10\n","          Conv2d-104            [-1, 1, 32, 32]              10\n","          Conv2d-105            [-1, 1, 32, 32]              10\n","          Conv2d-106            [-1, 1, 32, 32]              10\n","          Conv2d-107            [-1, 1, 32, 32]              10\n","          Conv2d-108            [-1, 1, 32, 32]              10\n","          Conv2d-109            [-1, 1, 32, 32]              10\n","          Conv2d-110            [-1, 1, 32, 32]              10\n","          Conv2d-111            [-1, 1, 32, 32]              10\n","          Conv2d-112            [-1, 1, 32, 32]              10\n","          Conv2d-113            [-1, 1, 32, 32]              10\n","          Conv2d-114            [-1, 1, 32, 32]              10\n","          Conv2d-115            [-1, 1, 32, 32]              10\n","          Conv2d-116            [-1, 1, 32, 32]              10\n","          Conv2d-117            [-1, 1, 32, 32]              10\n","          Conv2d-118            [-1, 1, 32, 32]              10\n","          Conv2d-119            [-1, 1, 32, 32]              10\n","          Conv2d-120            [-1, 1, 32, 32]              10\n","          Conv2d-121            [-1, 1, 32, 32]              10\n","          Conv2d-122            [-1, 1, 32, 32]              10\n","          Conv2d-123            [-1, 1, 32, 32]              10\n","          Conv2d-124            [-1, 1, 32, 32]              10\n","          Conv2d-125            [-1, 1, 32, 32]              10\n","          Conv2d-126            [-1, 1, 32, 32]              10\n","          Conv2d-127            [-1, 1, 32, 32]              10\n","          Conv2d-128            [-1, 1, 32, 32]              10\n","          Conv2d-129            [-1, 1, 32, 32]              10\n","          Conv2d-130            [-1, 1, 32, 32]              10\n","          Conv2d-131            [-1, 1, 32, 32]              10\n","          Conv2d-132            [-1, 1, 32, 32]              10\n","          Conv2d-133            [-1, 1, 32, 32]              10\n","          Conv2d-134            [-1, 1, 32, 32]              10\n","    PixelShuffle-135          [-1, 1, 256, 256]               0\n","          Conv2d-136            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-137            [-1, 1, 32, 32]               0\n","          Conv2d-138            [-1, 1, 32, 32]              10\n","          Conv2d-139            [-1, 1, 32, 32]              10\n","          Conv2d-140            [-1, 1, 32, 32]              10\n","          Conv2d-141            [-1, 1, 32, 32]              10\n","          Conv2d-142            [-1, 1, 32, 32]              10\n","          Conv2d-143            [-1, 1, 32, 32]              10\n","          Conv2d-144            [-1, 1, 32, 32]              10\n","          Conv2d-145            [-1, 1, 32, 32]              10\n","          Conv2d-146            [-1, 1, 32, 32]              10\n","          Conv2d-147            [-1, 1, 32, 32]              10\n","          Conv2d-148            [-1, 1, 32, 32]              10\n","          Conv2d-149            [-1, 1, 32, 32]              10\n","          Conv2d-150            [-1, 1, 32, 32]              10\n","          Conv2d-151            [-1, 1, 32, 32]              10\n","          Conv2d-152            [-1, 1, 32, 32]              10\n","          Conv2d-153            [-1, 1, 32, 32]              10\n","          Conv2d-154            [-1, 1, 32, 32]              10\n","          Conv2d-155            [-1, 1, 32, 32]              10\n","          Conv2d-156            [-1, 1, 32, 32]              10\n","          Conv2d-157            [-1, 1, 32, 32]              10\n","          Conv2d-158            [-1, 1, 32, 32]              10\n","          Conv2d-159            [-1, 1, 32, 32]              10\n","          Conv2d-160            [-1, 1, 32, 32]              10\n","          Conv2d-161            [-1, 1, 32, 32]              10\n","          Conv2d-162            [-1, 1, 32, 32]              10\n","          Conv2d-163            [-1, 1, 32, 32]              10\n","          Conv2d-164            [-1, 1, 32, 32]              10\n","          Conv2d-165            [-1, 1, 32, 32]              10\n","          Conv2d-166            [-1, 1, 32, 32]              10\n","          Conv2d-167            [-1, 1, 32, 32]              10\n","          Conv2d-168            [-1, 1, 32, 32]              10\n","          Conv2d-169            [-1, 1, 32, 32]              10\n","          Conv2d-170            [-1, 1, 32, 32]              10\n","          Conv2d-171            [-1, 1, 32, 32]              10\n","          Conv2d-172            [-1, 1, 32, 32]              10\n","          Conv2d-173            [-1, 1, 32, 32]              10\n","          Conv2d-174            [-1, 1, 32, 32]              10\n","          Conv2d-175            [-1, 1, 32, 32]              10\n","          Conv2d-176            [-1, 1, 32, 32]              10\n","          Conv2d-177            [-1, 1, 32, 32]              10\n","          Conv2d-178            [-1, 1, 32, 32]              10\n","          Conv2d-179            [-1, 1, 32, 32]              10\n","          Conv2d-180            [-1, 1, 32, 32]              10\n","          Conv2d-181            [-1, 1, 32, 32]              10\n","          Conv2d-182            [-1, 1, 32, 32]              10\n","          Conv2d-183            [-1, 1, 32, 32]              10\n","          Conv2d-184            [-1, 1, 32, 32]              10\n","          Conv2d-185            [-1, 1, 32, 32]              10\n","          Conv2d-186            [-1, 1, 32, 32]              10\n","          Conv2d-187            [-1, 1, 32, 32]              10\n","          Conv2d-188            [-1, 1, 32, 32]              10\n","          Conv2d-189            [-1, 1, 32, 32]              10\n","          Conv2d-190            [-1, 1, 32, 32]              10\n","          Conv2d-191            [-1, 1, 32, 32]              10\n","          Conv2d-192            [-1, 1, 32, 32]              10\n","          Conv2d-193            [-1, 1, 32, 32]              10\n","          Conv2d-194            [-1, 1, 32, 32]              10\n","          Conv2d-195            [-1, 1, 32, 32]              10\n","          Conv2d-196            [-1, 1, 32, 32]              10\n","          Conv2d-197            [-1, 1, 32, 32]              10\n","          Conv2d-198            [-1, 1, 32, 32]              10\n","          Conv2d-199            [-1, 1, 32, 32]              10\n","          Conv2d-200            [-1, 1, 32, 32]              10\n","          Conv2d-201            [-1, 1, 32, 32]              10\n","    PixelShuffle-202          [-1, 1, 256, 256]               0\n","          Conv2d-203            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-204            [-1, 1, 32, 32]               0\n","          Conv2d-205            [-1, 1, 32, 32]              10\n","          Conv2d-206            [-1, 1, 32, 32]              10\n","          Conv2d-207            [-1, 1, 32, 32]              10\n","          Conv2d-208            [-1, 1, 32, 32]              10\n","          Conv2d-209            [-1, 1, 32, 32]              10\n","          Conv2d-210            [-1, 1, 32, 32]              10\n","          Conv2d-211            [-1, 1, 32, 32]              10\n","          Conv2d-212            [-1, 1, 32, 32]              10\n","          Conv2d-213            [-1, 1, 32, 32]              10\n","          Conv2d-214            [-1, 1, 32, 32]              10\n","          Conv2d-215            [-1, 1, 32, 32]              10\n","          Conv2d-216            [-1, 1, 32, 32]              10\n","          Conv2d-217            [-1, 1, 32, 32]              10\n","          Conv2d-218            [-1, 1, 32, 32]              10\n","          Conv2d-219            [-1, 1, 32, 32]              10\n","          Conv2d-220            [-1, 1, 32, 32]              10\n","          Conv2d-221            [-1, 1, 32, 32]              10\n","          Conv2d-222            [-1, 1, 32, 32]              10\n","          Conv2d-223            [-1, 1, 32, 32]              10\n","          Conv2d-224            [-1, 1, 32, 32]              10\n","          Conv2d-225            [-1, 1, 32, 32]              10\n","          Conv2d-226            [-1, 1, 32, 32]              10\n","          Conv2d-227            [-1, 1, 32, 32]              10\n","          Conv2d-228            [-1, 1, 32, 32]              10\n","          Conv2d-229            [-1, 1, 32, 32]              10\n","          Conv2d-230            [-1, 1, 32, 32]              10\n","          Conv2d-231            [-1, 1, 32, 32]              10\n","          Conv2d-232            [-1, 1, 32, 32]              10\n","          Conv2d-233            [-1, 1, 32, 32]              10\n","          Conv2d-234            [-1, 1, 32, 32]              10\n","          Conv2d-235            [-1, 1, 32, 32]              10\n","          Conv2d-236            [-1, 1, 32, 32]              10\n","          Conv2d-237            [-1, 1, 32, 32]              10\n","          Conv2d-238            [-1, 1, 32, 32]              10\n","          Conv2d-239            [-1, 1, 32, 32]              10\n","          Conv2d-240            [-1, 1, 32, 32]              10\n","          Conv2d-241            [-1, 1, 32, 32]              10\n","          Conv2d-242            [-1, 1, 32, 32]              10\n","          Conv2d-243            [-1, 1, 32, 32]              10\n","          Conv2d-244            [-1, 1, 32, 32]              10\n","          Conv2d-245            [-1, 1, 32, 32]              10\n","          Conv2d-246            [-1, 1, 32, 32]              10\n","          Conv2d-247            [-1, 1, 32, 32]              10\n","          Conv2d-248            [-1, 1, 32, 32]              10\n","          Conv2d-249            [-1, 1, 32, 32]              10\n","          Conv2d-250            [-1, 1, 32, 32]              10\n","          Conv2d-251            [-1, 1, 32, 32]              10\n","          Conv2d-252            [-1, 1, 32, 32]              10\n","          Conv2d-253            [-1, 1, 32, 32]              10\n","          Conv2d-254            [-1, 1, 32, 32]              10\n","          Conv2d-255            [-1, 1, 32, 32]              10\n","          Conv2d-256            [-1, 1, 32, 32]              10\n","          Conv2d-257            [-1, 1, 32, 32]              10\n","          Conv2d-258            [-1, 1, 32, 32]              10\n","          Conv2d-259            [-1, 1, 32, 32]              10\n","          Conv2d-260            [-1, 1, 32, 32]              10\n","          Conv2d-261            [-1, 1, 32, 32]              10\n","          Conv2d-262            [-1, 1, 32, 32]              10\n","          Conv2d-263            [-1, 1, 32, 32]              10\n","          Conv2d-264            [-1, 1, 32, 32]              10\n","          Conv2d-265            [-1, 1, 32, 32]              10\n","          Conv2d-266            [-1, 1, 32, 32]              10\n","          Conv2d-267            [-1, 1, 32, 32]              10\n","          Conv2d-268            [-1, 1, 32, 32]              10\n","    PixelShuffle-269          [-1, 1, 256, 256]               0\n","          Conv2d-270            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-271            [-1, 1, 32, 32]               0\n","          Conv2d-272            [-1, 1, 32, 32]              10\n","          Conv2d-273            [-1, 1, 32, 32]              10\n","          Conv2d-274            [-1, 1, 32, 32]              10\n","          Conv2d-275            [-1, 1, 32, 32]              10\n","          Conv2d-276            [-1, 1, 32, 32]              10\n","          Conv2d-277            [-1, 1, 32, 32]              10\n","          Conv2d-278            [-1, 1, 32, 32]              10\n","          Conv2d-279            [-1, 1, 32, 32]              10\n","          Conv2d-280            [-1, 1, 32, 32]              10\n","          Conv2d-281            [-1, 1, 32, 32]              10\n","          Conv2d-282            [-1, 1, 32, 32]              10\n","          Conv2d-283            [-1, 1, 32, 32]              10\n","          Conv2d-284            [-1, 1, 32, 32]              10\n","          Conv2d-285            [-1, 1, 32, 32]              10\n","          Conv2d-286            [-1, 1, 32, 32]              10\n","          Conv2d-287            [-1, 1, 32, 32]              10\n","          Conv2d-288            [-1, 1, 32, 32]              10\n","          Conv2d-289            [-1, 1, 32, 32]              10\n","          Conv2d-290            [-1, 1, 32, 32]              10\n","          Conv2d-291            [-1, 1, 32, 32]              10\n","          Conv2d-292            [-1, 1, 32, 32]              10\n","          Conv2d-293            [-1, 1, 32, 32]              10\n","          Conv2d-294            [-1, 1, 32, 32]              10\n","          Conv2d-295            [-1, 1, 32, 32]              10\n","          Conv2d-296            [-1, 1, 32, 32]              10\n","          Conv2d-297            [-1, 1, 32, 32]              10\n","          Conv2d-298            [-1, 1, 32, 32]              10\n","          Conv2d-299            [-1, 1, 32, 32]              10\n","          Conv2d-300            [-1, 1, 32, 32]              10\n","          Conv2d-301            [-1, 1, 32, 32]              10\n","          Conv2d-302            [-1, 1, 32, 32]              10\n","          Conv2d-303            [-1, 1, 32, 32]              10\n","          Conv2d-304            [-1, 1, 32, 32]              10\n","          Conv2d-305            [-1, 1, 32, 32]              10\n","          Conv2d-306            [-1, 1, 32, 32]              10\n","          Conv2d-307            [-1, 1, 32, 32]              10\n","          Conv2d-308            [-1, 1, 32, 32]              10\n","          Conv2d-309            [-1, 1, 32, 32]              10\n","          Conv2d-310            [-1, 1, 32, 32]              10\n","          Conv2d-311            [-1, 1, 32, 32]              10\n","          Conv2d-312            [-1, 1, 32, 32]              10\n","          Conv2d-313            [-1, 1, 32, 32]              10\n","          Conv2d-314            [-1, 1, 32, 32]              10\n","          Conv2d-315            [-1, 1, 32, 32]              10\n","          Conv2d-316            [-1, 1, 32, 32]              10\n","          Conv2d-317            [-1, 1, 32, 32]              10\n","          Conv2d-318            [-1, 1, 32, 32]              10\n","          Conv2d-319            [-1, 1, 32, 32]              10\n","          Conv2d-320            [-1, 1, 32, 32]              10\n","          Conv2d-321            [-1, 1, 32, 32]              10\n","          Conv2d-322            [-1, 1, 32, 32]              10\n","          Conv2d-323            [-1, 1, 32, 32]              10\n","          Conv2d-324            [-1, 1, 32, 32]              10\n","          Conv2d-325            [-1, 1, 32, 32]              10\n","          Conv2d-326            [-1, 1, 32, 32]              10\n","          Conv2d-327            [-1, 1, 32, 32]              10\n","          Conv2d-328            [-1, 1, 32, 32]              10\n","          Conv2d-329            [-1, 1, 32, 32]              10\n","          Conv2d-330            [-1, 1, 32, 32]              10\n","          Conv2d-331            [-1, 1, 32, 32]              10\n","          Conv2d-332            [-1, 1, 32, 32]              10\n","          Conv2d-333            [-1, 1, 32, 32]              10\n","          Conv2d-334            [-1, 1, 32, 32]              10\n","          Conv2d-335            [-1, 1, 32, 32]              10\n","    PixelShuffle-336          [-1, 1, 256, 256]               0\n","          Conv2d-337            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-338            [-1, 1, 32, 32]               0\n","          Conv2d-339            [-1, 1, 32, 32]              10\n","          Conv2d-340            [-1, 1, 32, 32]              10\n","          Conv2d-341            [-1, 1, 32, 32]              10\n","          Conv2d-342            [-1, 1, 32, 32]              10\n","          Conv2d-343            [-1, 1, 32, 32]              10\n","          Conv2d-344            [-1, 1, 32, 32]              10\n","          Conv2d-345            [-1, 1, 32, 32]              10\n","          Conv2d-346            [-1, 1, 32, 32]              10\n","          Conv2d-347            [-1, 1, 32, 32]              10\n","          Conv2d-348            [-1, 1, 32, 32]              10\n","          Conv2d-349            [-1, 1, 32, 32]              10\n","          Conv2d-350            [-1, 1, 32, 32]              10\n","          Conv2d-351            [-1, 1, 32, 32]              10\n","          Conv2d-352            [-1, 1, 32, 32]              10\n","          Conv2d-353            [-1, 1, 32, 32]              10\n","          Conv2d-354            [-1, 1, 32, 32]              10\n","          Conv2d-355            [-1, 1, 32, 32]              10\n","          Conv2d-356            [-1, 1, 32, 32]              10\n","          Conv2d-357            [-1, 1, 32, 32]              10\n","          Conv2d-358            [-1, 1, 32, 32]              10\n","          Conv2d-359            [-1, 1, 32, 32]              10\n","          Conv2d-360            [-1, 1, 32, 32]              10\n","          Conv2d-361            [-1, 1, 32, 32]              10\n","          Conv2d-362            [-1, 1, 32, 32]              10\n","          Conv2d-363            [-1, 1, 32, 32]              10\n","          Conv2d-364            [-1, 1, 32, 32]              10\n","          Conv2d-365            [-1, 1, 32, 32]              10\n","          Conv2d-366            [-1, 1, 32, 32]              10\n","          Conv2d-367            [-1, 1, 32, 32]              10\n","          Conv2d-368            [-1, 1, 32, 32]              10\n","          Conv2d-369            [-1, 1, 32, 32]              10\n","          Conv2d-370            [-1, 1, 32, 32]              10\n","          Conv2d-371            [-1, 1, 32, 32]              10\n","          Conv2d-372            [-1, 1, 32, 32]              10\n","          Conv2d-373            [-1, 1, 32, 32]              10\n","          Conv2d-374            [-1, 1, 32, 32]              10\n","          Conv2d-375            [-1, 1, 32, 32]              10\n","          Conv2d-376            [-1, 1, 32, 32]              10\n","          Conv2d-377            [-1, 1, 32, 32]              10\n","          Conv2d-378            [-1, 1, 32, 32]              10\n","          Conv2d-379            [-1, 1, 32, 32]              10\n","          Conv2d-380            [-1, 1, 32, 32]              10\n","          Conv2d-381            [-1, 1, 32, 32]              10\n","          Conv2d-382            [-1, 1, 32, 32]              10\n","          Conv2d-383            [-1, 1, 32, 32]              10\n","          Conv2d-384            [-1, 1, 32, 32]              10\n","          Conv2d-385            [-1, 1, 32, 32]              10\n","          Conv2d-386            [-1, 1, 32, 32]              10\n","          Conv2d-387            [-1, 1, 32, 32]              10\n","          Conv2d-388            [-1, 1, 32, 32]              10\n","          Conv2d-389            [-1, 1, 32, 32]              10\n","          Conv2d-390            [-1, 1, 32, 32]              10\n","          Conv2d-391            [-1, 1, 32, 32]              10\n","          Conv2d-392            [-1, 1, 32, 32]              10\n","          Conv2d-393            [-1, 1, 32, 32]              10\n","          Conv2d-394            [-1, 1, 32, 32]              10\n","          Conv2d-395            [-1, 1, 32, 32]              10\n","          Conv2d-396            [-1, 1, 32, 32]              10\n","          Conv2d-397            [-1, 1, 32, 32]              10\n","          Conv2d-398            [-1, 1, 32, 32]              10\n","          Conv2d-399            [-1, 1, 32, 32]              10\n","          Conv2d-400            [-1, 1, 32, 32]              10\n","          Conv2d-401            [-1, 1, 32, 32]              10\n","          Conv2d-402            [-1, 1, 32, 32]              10\n","    PixelShuffle-403          [-1, 1, 256, 256]               0\n","          Conv2d-404            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-405            [-1, 1, 32, 32]               0\n","          Conv2d-406            [-1, 1, 32, 32]              10\n","          Conv2d-407            [-1, 1, 32, 32]              10\n","          Conv2d-408            [-1, 1, 32, 32]              10\n","          Conv2d-409            [-1, 1, 32, 32]              10\n","          Conv2d-410            [-1, 1, 32, 32]              10\n","          Conv2d-411            [-1, 1, 32, 32]              10\n","          Conv2d-412            [-1, 1, 32, 32]              10\n","          Conv2d-413            [-1, 1, 32, 32]              10\n","          Conv2d-414            [-1, 1, 32, 32]              10\n","          Conv2d-415            [-1, 1, 32, 32]              10\n","          Conv2d-416            [-1, 1, 32, 32]              10\n","          Conv2d-417            [-1, 1, 32, 32]              10\n","          Conv2d-418            [-1, 1, 32, 32]              10\n","          Conv2d-419            [-1, 1, 32, 32]              10\n","          Conv2d-420            [-1, 1, 32, 32]              10\n","          Conv2d-421            [-1, 1, 32, 32]              10\n","          Conv2d-422            [-1, 1, 32, 32]              10\n","          Conv2d-423            [-1, 1, 32, 32]              10\n","          Conv2d-424            [-1, 1, 32, 32]              10\n","          Conv2d-425            [-1, 1, 32, 32]              10\n","          Conv2d-426            [-1, 1, 32, 32]              10\n","          Conv2d-427            [-1, 1, 32, 32]              10\n","          Conv2d-428            [-1, 1, 32, 32]              10\n","          Conv2d-429            [-1, 1, 32, 32]              10\n","          Conv2d-430            [-1, 1, 32, 32]              10\n","          Conv2d-431            [-1, 1, 32, 32]              10\n","          Conv2d-432            [-1, 1, 32, 32]              10\n","          Conv2d-433            [-1, 1, 32, 32]              10\n","          Conv2d-434            [-1, 1, 32, 32]              10\n","          Conv2d-435            [-1, 1, 32, 32]              10\n","          Conv2d-436            [-1, 1, 32, 32]              10\n","          Conv2d-437            [-1, 1, 32, 32]              10\n","          Conv2d-438            [-1, 1, 32, 32]              10\n","          Conv2d-439            [-1, 1, 32, 32]              10\n","          Conv2d-440            [-1, 1, 32, 32]              10\n","          Conv2d-441            [-1, 1, 32, 32]              10\n","          Conv2d-442            [-1, 1, 32, 32]              10\n","          Conv2d-443            [-1, 1, 32, 32]              10\n","          Conv2d-444            [-1, 1, 32, 32]              10\n","          Conv2d-445            [-1, 1, 32, 32]              10\n","          Conv2d-446            [-1, 1, 32, 32]              10\n","          Conv2d-447            [-1, 1, 32, 32]              10\n","          Conv2d-448            [-1, 1, 32, 32]              10\n","          Conv2d-449            [-1, 1, 32, 32]              10\n","          Conv2d-450            [-1, 1, 32, 32]              10\n","          Conv2d-451            [-1, 1, 32, 32]              10\n","          Conv2d-452            [-1, 1, 32, 32]              10\n","          Conv2d-453            [-1, 1, 32, 32]              10\n","          Conv2d-454            [-1, 1, 32, 32]              10\n","          Conv2d-455            [-1, 1, 32, 32]              10\n","          Conv2d-456            [-1, 1, 32, 32]              10\n","          Conv2d-457            [-1, 1, 32, 32]              10\n","          Conv2d-458            [-1, 1, 32, 32]              10\n","          Conv2d-459            [-1, 1, 32, 32]              10\n","          Conv2d-460            [-1, 1, 32, 32]              10\n","          Conv2d-461            [-1, 1, 32, 32]              10\n","          Conv2d-462            [-1, 1, 32, 32]              10\n","          Conv2d-463            [-1, 1, 32, 32]              10\n","          Conv2d-464            [-1, 1, 32, 32]              10\n","          Conv2d-465            [-1, 1, 32, 32]              10\n","          Conv2d-466            [-1, 1, 32, 32]              10\n","          Conv2d-467            [-1, 1, 32, 32]              10\n","          Conv2d-468            [-1, 1, 32, 32]              10\n","          Conv2d-469            [-1, 1, 32, 32]              10\n","    PixelShuffle-470          [-1, 1, 256, 256]               0\n","          Conv2d-471            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-472            [-1, 1, 32, 32]               0\n","          Conv2d-473            [-1, 1, 32, 32]              10\n","          Conv2d-474            [-1, 1, 32, 32]              10\n","          Conv2d-475            [-1, 1, 32, 32]              10\n","          Conv2d-476            [-1, 1, 32, 32]              10\n","          Conv2d-477            [-1, 1, 32, 32]              10\n","          Conv2d-478            [-1, 1, 32, 32]              10\n","          Conv2d-479            [-1, 1, 32, 32]              10\n","          Conv2d-480            [-1, 1, 32, 32]              10\n","          Conv2d-481            [-1, 1, 32, 32]              10\n","          Conv2d-482            [-1, 1, 32, 32]              10\n","          Conv2d-483            [-1, 1, 32, 32]              10\n","          Conv2d-484            [-1, 1, 32, 32]              10\n","          Conv2d-485            [-1, 1, 32, 32]              10\n","          Conv2d-486            [-1, 1, 32, 32]              10\n","          Conv2d-487            [-1, 1, 32, 32]              10\n","          Conv2d-488            [-1, 1, 32, 32]              10\n","          Conv2d-489            [-1, 1, 32, 32]              10\n","          Conv2d-490            [-1, 1, 32, 32]              10\n","          Conv2d-491            [-1, 1, 32, 32]              10\n","          Conv2d-492            [-1, 1, 32, 32]              10\n","          Conv2d-493            [-1, 1, 32, 32]              10\n","          Conv2d-494            [-1, 1, 32, 32]              10\n","          Conv2d-495            [-1, 1, 32, 32]              10\n","          Conv2d-496            [-1, 1, 32, 32]              10\n","          Conv2d-497            [-1, 1, 32, 32]              10\n","          Conv2d-498            [-1, 1, 32, 32]              10\n","          Conv2d-499            [-1, 1, 32, 32]              10\n","          Conv2d-500            [-1, 1, 32, 32]              10\n","          Conv2d-501            [-1, 1, 32, 32]              10\n","          Conv2d-502            [-1, 1, 32, 32]              10\n","          Conv2d-503            [-1, 1, 32, 32]              10\n","          Conv2d-504            [-1, 1, 32, 32]              10\n","          Conv2d-505            [-1, 1, 32, 32]              10\n","          Conv2d-506            [-1, 1, 32, 32]              10\n","          Conv2d-507            [-1, 1, 32, 32]              10\n","          Conv2d-508            [-1, 1, 32, 32]              10\n","          Conv2d-509            [-1, 1, 32, 32]              10\n","          Conv2d-510            [-1, 1, 32, 32]              10\n","          Conv2d-511            [-1, 1, 32, 32]              10\n","          Conv2d-512            [-1, 1, 32, 32]              10\n","          Conv2d-513            [-1, 1, 32, 32]              10\n","          Conv2d-514            [-1, 1, 32, 32]              10\n","          Conv2d-515            [-1, 1, 32, 32]              10\n","          Conv2d-516            [-1, 1, 32, 32]              10\n","          Conv2d-517            [-1, 1, 32, 32]              10\n","          Conv2d-518            [-1, 1, 32, 32]              10\n","          Conv2d-519            [-1, 1, 32, 32]              10\n","          Conv2d-520            [-1, 1, 32, 32]              10\n","          Conv2d-521            [-1, 1, 32, 32]              10\n","          Conv2d-522            [-1, 1, 32, 32]              10\n","          Conv2d-523            [-1, 1, 32, 32]              10\n","          Conv2d-524            [-1, 1, 32, 32]              10\n","          Conv2d-525            [-1, 1, 32, 32]              10\n","          Conv2d-526            [-1, 1, 32, 32]              10\n","          Conv2d-527            [-1, 1, 32, 32]              10\n","          Conv2d-528            [-1, 1, 32, 32]              10\n","          Conv2d-529            [-1, 1, 32, 32]              10\n","          Conv2d-530            [-1, 1, 32, 32]              10\n","          Conv2d-531            [-1, 1, 32, 32]              10\n","          Conv2d-532            [-1, 1, 32, 32]              10\n","          Conv2d-533            [-1, 1, 32, 32]              10\n","          Conv2d-534            [-1, 1, 32, 32]              10\n","          Conv2d-535            [-1, 1, 32, 32]              10\n","          Conv2d-536            [-1, 1, 32, 32]              10\n","    PixelShuffle-537          [-1, 1, 256, 256]               0\n","          Conv2d-538            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-539            [-1, 1, 32, 32]               0\n","          Conv2d-540            [-1, 1, 32, 32]              10\n","          Conv2d-541            [-1, 1, 32, 32]              10\n","          Conv2d-542            [-1, 1, 32, 32]              10\n","          Conv2d-543            [-1, 1, 32, 32]              10\n","          Conv2d-544            [-1, 1, 32, 32]              10\n","          Conv2d-545            [-1, 1, 32, 32]              10\n","          Conv2d-546            [-1, 1, 32, 32]              10\n","          Conv2d-547            [-1, 1, 32, 32]              10\n","          Conv2d-548            [-1, 1, 32, 32]              10\n","          Conv2d-549            [-1, 1, 32, 32]              10\n","          Conv2d-550            [-1, 1, 32, 32]              10\n","          Conv2d-551            [-1, 1, 32, 32]              10\n","          Conv2d-552            [-1, 1, 32, 32]              10\n","          Conv2d-553            [-1, 1, 32, 32]              10\n","          Conv2d-554            [-1, 1, 32, 32]              10\n","          Conv2d-555            [-1, 1, 32, 32]              10\n","          Conv2d-556            [-1, 1, 32, 32]              10\n","          Conv2d-557            [-1, 1, 32, 32]              10\n","          Conv2d-558            [-1, 1, 32, 32]              10\n","          Conv2d-559            [-1, 1, 32, 32]              10\n","          Conv2d-560            [-1, 1, 32, 32]              10\n","          Conv2d-561            [-1, 1, 32, 32]              10\n","          Conv2d-562            [-1, 1, 32, 32]              10\n","          Conv2d-563            [-1, 1, 32, 32]              10\n","          Conv2d-564            [-1, 1, 32, 32]              10\n","          Conv2d-565            [-1, 1, 32, 32]              10\n","          Conv2d-566            [-1, 1, 32, 32]              10\n","          Conv2d-567            [-1, 1, 32, 32]              10\n","          Conv2d-568            [-1, 1, 32, 32]              10\n","          Conv2d-569            [-1, 1, 32, 32]              10\n","          Conv2d-570            [-1, 1, 32, 32]              10\n","          Conv2d-571            [-1, 1, 32, 32]              10\n","          Conv2d-572            [-1, 1, 32, 32]              10\n","          Conv2d-573            [-1, 1, 32, 32]              10\n","          Conv2d-574            [-1, 1, 32, 32]              10\n","          Conv2d-575            [-1, 1, 32, 32]              10\n","          Conv2d-576            [-1, 1, 32, 32]              10\n","          Conv2d-577            [-1, 1, 32, 32]              10\n","          Conv2d-578            [-1, 1, 32, 32]              10\n","          Conv2d-579            [-1, 1, 32, 32]              10\n","          Conv2d-580            [-1, 1, 32, 32]              10\n","          Conv2d-581            [-1, 1, 32, 32]              10\n","          Conv2d-582            [-1, 1, 32, 32]              10\n","          Conv2d-583            [-1, 1, 32, 32]              10\n","          Conv2d-584            [-1, 1, 32, 32]              10\n","          Conv2d-585            [-1, 1, 32, 32]              10\n","          Conv2d-586            [-1, 1, 32, 32]              10\n","          Conv2d-587            [-1, 1, 32, 32]              10\n","          Conv2d-588            [-1, 1, 32, 32]              10\n","          Conv2d-589            [-1, 1, 32, 32]              10\n","          Conv2d-590            [-1, 1, 32, 32]              10\n","          Conv2d-591            [-1, 1, 32, 32]              10\n","          Conv2d-592            [-1, 1, 32, 32]              10\n","          Conv2d-593            [-1, 1, 32, 32]              10\n","          Conv2d-594            [-1, 1, 32, 32]              10\n","          Conv2d-595            [-1, 1, 32, 32]              10\n","          Conv2d-596            [-1, 1, 32, 32]              10\n","          Conv2d-597            [-1, 1, 32, 32]              10\n","          Conv2d-598            [-1, 1, 32, 32]              10\n","          Conv2d-599            [-1, 1, 32, 32]              10\n","          Conv2d-600            [-1, 1, 32, 32]              10\n","          Conv2d-601            [-1, 1, 32, 32]              10\n","          Conv2d-602            [-1, 1, 32, 32]              10\n","          Conv2d-603            [-1, 1, 32, 32]              10\n","    PixelShuffle-604          [-1, 1, 256, 256]               0\n","          Conv2d-605            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-606            [-1, 1, 32, 32]               0\n","          Conv2d-607            [-1, 1, 32, 32]              10\n","          Conv2d-608            [-1, 1, 32, 32]              10\n","          Conv2d-609            [-1, 1, 32, 32]              10\n","          Conv2d-610            [-1, 1, 32, 32]              10\n","          Conv2d-611            [-1, 1, 32, 32]              10\n","          Conv2d-612            [-1, 1, 32, 32]              10\n","          Conv2d-613            [-1, 1, 32, 32]              10\n","          Conv2d-614            [-1, 1, 32, 32]              10\n","          Conv2d-615            [-1, 1, 32, 32]              10\n","          Conv2d-616            [-1, 1, 32, 32]              10\n","          Conv2d-617            [-1, 1, 32, 32]              10\n","          Conv2d-618            [-1, 1, 32, 32]              10\n","          Conv2d-619            [-1, 1, 32, 32]              10\n","          Conv2d-620            [-1, 1, 32, 32]              10\n","          Conv2d-621            [-1, 1, 32, 32]              10\n","          Conv2d-622            [-1, 1, 32, 32]              10\n","          Conv2d-623            [-1, 1, 32, 32]              10\n","          Conv2d-624            [-1, 1, 32, 32]              10\n","          Conv2d-625            [-1, 1, 32, 32]              10\n","          Conv2d-626            [-1, 1, 32, 32]              10\n","          Conv2d-627            [-1, 1, 32, 32]              10\n","          Conv2d-628            [-1, 1, 32, 32]              10\n","          Conv2d-629            [-1, 1, 32, 32]              10\n","          Conv2d-630            [-1, 1, 32, 32]              10\n","          Conv2d-631            [-1, 1, 32, 32]              10\n","          Conv2d-632            [-1, 1, 32, 32]              10\n","          Conv2d-633            [-1, 1, 32, 32]              10\n","          Conv2d-634            [-1, 1, 32, 32]              10\n","          Conv2d-635            [-1, 1, 32, 32]              10\n","          Conv2d-636            [-1, 1, 32, 32]              10\n","          Conv2d-637            [-1, 1, 32, 32]              10\n","          Conv2d-638            [-1, 1, 32, 32]              10\n","          Conv2d-639            [-1, 1, 32, 32]              10\n","          Conv2d-640            [-1, 1, 32, 32]              10\n","          Conv2d-641            [-1, 1, 32, 32]              10\n","          Conv2d-642            [-1, 1, 32, 32]              10\n","          Conv2d-643            [-1, 1, 32, 32]              10\n","          Conv2d-644            [-1, 1, 32, 32]              10\n","          Conv2d-645            [-1, 1, 32, 32]              10\n","          Conv2d-646            [-1, 1, 32, 32]              10\n","          Conv2d-647            [-1, 1, 32, 32]              10\n","          Conv2d-648            [-1, 1, 32, 32]              10\n","          Conv2d-649            [-1, 1, 32, 32]              10\n","          Conv2d-650            [-1, 1, 32, 32]              10\n","          Conv2d-651            [-1, 1, 32, 32]              10\n","          Conv2d-652            [-1, 1, 32, 32]              10\n","          Conv2d-653            [-1, 1, 32, 32]              10\n","          Conv2d-654            [-1, 1, 32, 32]              10\n","          Conv2d-655            [-1, 1, 32, 32]              10\n","          Conv2d-656            [-1, 1, 32, 32]              10\n","          Conv2d-657            [-1, 1, 32, 32]              10\n","          Conv2d-658            [-1, 1, 32, 32]              10\n","          Conv2d-659            [-1, 1, 32, 32]              10\n","          Conv2d-660            [-1, 1, 32, 32]              10\n","          Conv2d-661            [-1, 1, 32, 32]              10\n","          Conv2d-662            [-1, 1, 32, 32]              10\n","          Conv2d-663            [-1, 1, 32, 32]              10\n","          Conv2d-664            [-1, 1, 32, 32]              10\n","          Conv2d-665            [-1, 1, 32, 32]              10\n","          Conv2d-666            [-1, 1, 32, 32]              10\n","          Conv2d-667            [-1, 1, 32, 32]              10\n","          Conv2d-668            [-1, 1, 32, 32]              10\n","          Conv2d-669            [-1, 1, 32, 32]              10\n","          Conv2d-670            [-1, 1, 32, 32]              10\n","    PixelShuffle-671          [-1, 1, 256, 256]               0\n","          Conv2d-672            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-673            [-1, 1, 32, 32]               0\n","          Conv2d-674            [-1, 1, 32, 32]              10\n","          Conv2d-675            [-1, 1, 32, 32]              10\n","          Conv2d-676            [-1, 1, 32, 32]              10\n","          Conv2d-677            [-1, 1, 32, 32]              10\n","          Conv2d-678            [-1, 1, 32, 32]              10\n","          Conv2d-679            [-1, 1, 32, 32]              10\n","          Conv2d-680            [-1, 1, 32, 32]              10\n","          Conv2d-681            [-1, 1, 32, 32]              10\n","          Conv2d-682            [-1, 1, 32, 32]              10\n","          Conv2d-683            [-1, 1, 32, 32]              10\n","          Conv2d-684            [-1, 1, 32, 32]              10\n","          Conv2d-685            [-1, 1, 32, 32]              10\n","          Conv2d-686            [-1, 1, 32, 32]              10\n","          Conv2d-687            [-1, 1, 32, 32]              10\n","          Conv2d-688            [-1, 1, 32, 32]              10\n","          Conv2d-689            [-1, 1, 32, 32]              10\n","          Conv2d-690            [-1, 1, 32, 32]              10\n","          Conv2d-691            [-1, 1, 32, 32]              10\n","          Conv2d-692            [-1, 1, 32, 32]              10\n","          Conv2d-693            [-1, 1, 32, 32]              10\n","          Conv2d-694            [-1, 1, 32, 32]              10\n","          Conv2d-695            [-1, 1, 32, 32]              10\n","          Conv2d-696            [-1, 1, 32, 32]              10\n","          Conv2d-697            [-1, 1, 32, 32]              10\n","          Conv2d-698            [-1, 1, 32, 32]              10\n","          Conv2d-699            [-1, 1, 32, 32]              10\n","          Conv2d-700            [-1, 1, 32, 32]              10\n","          Conv2d-701            [-1, 1, 32, 32]              10\n","          Conv2d-702            [-1, 1, 32, 32]              10\n","          Conv2d-703            [-1, 1, 32, 32]              10\n","          Conv2d-704            [-1, 1, 32, 32]              10\n","          Conv2d-705            [-1, 1, 32, 32]              10\n","          Conv2d-706            [-1, 1, 32, 32]              10\n","          Conv2d-707            [-1, 1, 32, 32]              10\n","          Conv2d-708            [-1, 1, 32, 32]              10\n","          Conv2d-709            [-1, 1, 32, 32]              10\n","          Conv2d-710            [-1, 1, 32, 32]              10\n","          Conv2d-711            [-1, 1, 32, 32]              10\n","          Conv2d-712            [-1, 1, 32, 32]              10\n","          Conv2d-713            [-1, 1, 32, 32]              10\n","          Conv2d-714            [-1, 1, 32, 32]              10\n","          Conv2d-715            [-1, 1, 32, 32]              10\n","          Conv2d-716            [-1, 1, 32, 32]              10\n","          Conv2d-717            [-1, 1, 32, 32]              10\n","          Conv2d-718            [-1, 1, 32, 32]              10\n","          Conv2d-719            [-1, 1, 32, 32]              10\n","          Conv2d-720            [-1, 1, 32, 32]              10\n","          Conv2d-721            [-1, 1, 32, 32]              10\n","          Conv2d-722            [-1, 1, 32, 32]              10\n","          Conv2d-723            [-1, 1, 32, 32]              10\n","          Conv2d-724            [-1, 1, 32, 32]              10\n","          Conv2d-725            [-1, 1, 32, 32]              10\n","          Conv2d-726            [-1, 1, 32, 32]              10\n","          Conv2d-727            [-1, 1, 32, 32]              10\n","          Conv2d-728            [-1, 1, 32, 32]              10\n","          Conv2d-729            [-1, 1, 32, 32]              10\n","          Conv2d-730            [-1, 1, 32, 32]              10\n","          Conv2d-731            [-1, 1, 32, 32]              10\n","          Conv2d-732            [-1, 1, 32, 32]              10\n","          Conv2d-733            [-1, 1, 32, 32]              10\n","          Conv2d-734            [-1, 1, 32, 32]              10\n","          Conv2d-735            [-1, 1, 32, 32]              10\n","          Conv2d-736            [-1, 1, 32, 32]              10\n","          Conv2d-737            [-1, 1, 32, 32]              10\n","    PixelShuffle-738          [-1, 1, 256, 256]               0\n","          Conv2d-739            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-740            [-1, 1, 32, 32]               0\n","          Conv2d-741            [-1, 1, 32, 32]              10\n","          Conv2d-742            [-1, 1, 32, 32]              10\n","          Conv2d-743            [-1, 1, 32, 32]              10\n","          Conv2d-744            [-1, 1, 32, 32]              10\n","          Conv2d-745            [-1, 1, 32, 32]              10\n","          Conv2d-746            [-1, 1, 32, 32]              10\n","          Conv2d-747            [-1, 1, 32, 32]              10\n","          Conv2d-748            [-1, 1, 32, 32]              10\n","          Conv2d-749            [-1, 1, 32, 32]              10\n","          Conv2d-750            [-1, 1, 32, 32]              10\n","          Conv2d-751            [-1, 1, 32, 32]              10\n","          Conv2d-752            [-1, 1, 32, 32]              10\n","          Conv2d-753            [-1, 1, 32, 32]              10\n","          Conv2d-754            [-1, 1, 32, 32]              10\n","          Conv2d-755            [-1, 1, 32, 32]              10\n","          Conv2d-756            [-1, 1, 32, 32]              10\n","          Conv2d-757            [-1, 1, 32, 32]              10\n","          Conv2d-758            [-1, 1, 32, 32]              10\n","          Conv2d-759            [-1, 1, 32, 32]              10\n","          Conv2d-760            [-1, 1, 32, 32]              10\n","          Conv2d-761            [-1, 1, 32, 32]              10\n","          Conv2d-762            [-1, 1, 32, 32]              10\n","          Conv2d-763            [-1, 1, 32, 32]              10\n","          Conv2d-764            [-1, 1, 32, 32]              10\n","          Conv2d-765            [-1, 1, 32, 32]              10\n","          Conv2d-766            [-1, 1, 32, 32]              10\n","          Conv2d-767            [-1, 1, 32, 32]              10\n","          Conv2d-768            [-1, 1, 32, 32]              10\n","          Conv2d-769            [-1, 1, 32, 32]              10\n","          Conv2d-770            [-1, 1, 32, 32]              10\n","          Conv2d-771            [-1, 1, 32, 32]              10\n","          Conv2d-772            [-1, 1, 32, 32]              10\n","          Conv2d-773            [-1, 1, 32, 32]              10\n","          Conv2d-774            [-1, 1, 32, 32]              10\n","          Conv2d-775            [-1, 1, 32, 32]              10\n","          Conv2d-776            [-1, 1, 32, 32]              10\n","          Conv2d-777            [-1, 1, 32, 32]              10\n","          Conv2d-778            [-1, 1, 32, 32]              10\n","          Conv2d-779            [-1, 1, 32, 32]              10\n","          Conv2d-780            [-1, 1, 32, 32]              10\n","          Conv2d-781            [-1, 1, 32, 32]              10\n","          Conv2d-782            [-1, 1, 32, 32]              10\n","          Conv2d-783            [-1, 1, 32, 32]              10\n","          Conv2d-784            [-1, 1, 32, 32]              10\n","          Conv2d-785            [-1, 1, 32, 32]              10\n","          Conv2d-786            [-1, 1, 32, 32]              10\n","          Conv2d-787            [-1, 1, 32, 32]              10\n","          Conv2d-788            [-1, 1, 32, 32]              10\n","          Conv2d-789            [-1, 1, 32, 32]              10\n","          Conv2d-790            [-1, 1, 32, 32]              10\n","          Conv2d-791            [-1, 1, 32, 32]              10\n","          Conv2d-792            [-1, 1, 32, 32]              10\n","          Conv2d-793            [-1, 1, 32, 32]              10\n","          Conv2d-794            [-1, 1, 32, 32]              10\n","          Conv2d-795            [-1, 1, 32, 32]              10\n","          Conv2d-796            [-1, 1, 32, 32]              10\n","          Conv2d-797            [-1, 1, 32, 32]              10\n","          Conv2d-798            [-1, 1, 32, 32]              10\n","          Conv2d-799            [-1, 1, 32, 32]              10\n","          Conv2d-800            [-1, 1, 32, 32]              10\n","          Conv2d-801            [-1, 1, 32, 32]              10\n","          Conv2d-802            [-1, 1, 32, 32]              10\n","          Conv2d-803            [-1, 1, 32, 32]              10\n","          Conv2d-804            [-1, 1, 32, 32]              10\n","    PixelShuffle-805          [-1, 1, 256, 256]               0\n","          Conv2d-806            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-807            [-1, 1, 32, 32]               0\n","          Conv2d-808            [-1, 1, 32, 32]              10\n","          Conv2d-809            [-1, 1, 32, 32]              10\n","          Conv2d-810            [-1, 1, 32, 32]              10\n","          Conv2d-811            [-1, 1, 32, 32]              10\n","          Conv2d-812            [-1, 1, 32, 32]              10\n","          Conv2d-813            [-1, 1, 32, 32]              10\n","          Conv2d-814            [-1, 1, 32, 32]              10\n","          Conv2d-815            [-1, 1, 32, 32]              10\n","          Conv2d-816            [-1, 1, 32, 32]              10\n","          Conv2d-817            [-1, 1, 32, 32]              10\n","          Conv2d-818            [-1, 1, 32, 32]              10\n","          Conv2d-819            [-1, 1, 32, 32]              10\n","          Conv2d-820            [-1, 1, 32, 32]              10\n","          Conv2d-821            [-1, 1, 32, 32]              10\n","          Conv2d-822            [-1, 1, 32, 32]              10\n","          Conv2d-823            [-1, 1, 32, 32]              10\n","          Conv2d-824            [-1, 1, 32, 32]              10\n","          Conv2d-825            [-1, 1, 32, 32]              10\n","          Conv2d-826            [-1, 1, 32, 32]              10\n","          Conv2d-827            [-1, 1, 32, 32]              10\n","          Conv2d-828            [-1, 1, 32, 32]              10\n","          Conv2d-829            [-1, 1, 32, 32]              10\n","          Conv2d-830            [-1, 1, 32, 32]              10\n","          Conv2d-831            [-1, 1, 32, 32]              10\n","          Conv2d-832            [-1, 1, 32, 32]              10\n","          Conv2d-833            [-1, 1, 32, 32]              10\n","          Conv2d-834            [-1, 1, 32, 32]              10\n","          Conv2d-835            [-1, 1, 32, 32]              10\n","          Conv2d-836            [-1, 1, 32, 32]              10\n","          Conv2d-837            [-1, 1, 32, 32]              10\n","          Conv2d-838            [-1, 1, 32, 32]              10\n","          Conv2d-839            [-1, 1, 32, 32]              10\n","          Conv2d-840            [-1, 1, 32, 32]              10\n","          Conv2d-841            [-1, 1, 32, 32]              10\n","          Conv2d-842            [-1, 1, 32, 32]              10\n","          Conv2d-843            [-1, 1, 32, 32]              10\n","          Conv2d-844            [-1, 1, 32, 32]              10\n","          Conv2d-845            [-1, 1, 32, 32]              10\n","          Conv2d-846            [-1, 1, 32, 32]              10\n","          Conv2d-847            [-1, 1, 32, 32]              10\n","          Conv2d-848            [-1, 1, 32, 32]              10\n","          Conv2d-849            [-1, 1, 32, 32]              10\n","          Conv2d-850            [-1, 1, 32, 32]              10\n","          Conv2d-851            [-1, 1, 32, 32]              10\n","          Conv2d-852            [-1, 1, 32, 32]              10\n","          Conv2d-853            [-1, 1, 32, 32]              10\n","          Conv2d-854            [-1, 1, 32, 32]              10\n","          Conv2d-855            [-1, 1, 32, 32]              10\n","          Conv2d-856            [-1, 1, 32, 32]              10\n","          Conv2d-857            [-1, 1, 32, 32]              10\n","          Conv2d-858            [-1, 1, 32, 32]              10\n","          Conv2d-859            [-1, 1, 32, 32]              10\n","          Conv2d-860            [-1, 1, 32, 32]              10\n","          Conv2d-861            [-1, 1, 32, 32]              10\n","          Conv2d-862            [-1, 1, 32, 32]              10\n","          Conv2d-863            [-1, 1, 32, 32]              10\n","          Conv2d-864            [-1, 1, 32, 32]              10\n","          Conv2d-865            [-1, 1, 32, 32]              10\n","          Conv2d-866            [-1, 1, 32, 32]              10\n","          Conv2d-867            [-1, 1, 32, 32]              10\n","          Conv2d-868            [-1, 1, 32, 32]              10\n","          Conv2d-869            [-1, 1, 32, 32]              10\n","          Conv2d-870            [-1, 1, 32, 32]              10\n","          Conv2d-871            [-1, 1, 32, 32]              10\n","    PixelShuffle-872          [-1, 1, 256, 256]               0\n","          Conv2d-873            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-874            [-1, 1, 32, 32]               0\n","          Conv2d-875            [-1, 1, 32, 32]              10\n","          Conv2d-876            [-1, 1, 32, 32]              10\n","          Conv2d-877            [-1, 1, 32, 32]              10\n","          Conv2d-878            [-1, 1, 32, 32]              10\n","          Conv2d-879            [-1, 1, 32, 32]              10\n","          Conv2d-880            [-1, 1, 32, 32]              10\n","          Conv2d-881            [-1, 1, 32, 32]              10\n","          Conv2d-882            [-1, 1, 32, 32]              10\n","          Conv2d-883            [-1, 1, 32, 32]              10\n","          Conv2d-884            [-1, 1, 32, 32]              10\n","          Conv2d-885            [-1, 1, 32, 32]              10\n","          Conv2d-886            [-1, 1, 32, 32]              10\n","          Conv2d-887            [-1, 1, 32, 32]              10\n","          Conv2d-888            [-1, 1, 32, 32]              10\n","          Conv2d-889            [-1, 1, 32, 32]              10\n","          Conv2d-890            [-1, 1, 32, 32]              10\n","          Conv2d-891            [-1, 1, 32, 32]              10\n","          Conv2d-892            [-1, 1, 32, 32]              10\n","          Conv2d-893            [-1, 1, 32, 32]              10\n","          Conv2d-894            [-1, 1, 32, 32]              10\n","          Conv2d-895            [-1, 1, 32, 32]              10\n","          Conv2d-896            [-1, 1, 32, 32]              10\n","          Conv2d-897            [-1, 1, 32, 32]              10\n","          Conv2d-898            [-1, 1, 32, 32]              10\n","          Conv2d-899            [-1, 1, 32, 32]              10\n","          Conv2d-900            [-1, 1, 32, 32]              10\n","          Conv2d-901            [-1, 1, 32, 32]              10\n","          Conv2d-902            [-1, 1, 32, 32]              10\n","          Conv2d-903            [-1, 1, 32, 32]              10\n","          Conv2d-904            [-1, 1, 32, 32]              10\n","          Conv2d-905            [-1, 1, 32, 32]              10\n","          Conv2d-906            [-1, 1, 32, 32]              10\n","          Conv2d-907            [-1, 1, 32, 32]              10\n","          Conv2d-908            [-1, 1, 32, 32]              10\n","          Conv2d-909            [-1, 1, 32, 32]              10\n","          Conv2d-910            [-1, 1, 32, 32]              10\n","          Conv2d-911            [-1, 1, 32, 32]              10\n","          Conv2d-912            [-1, 1, 32, 32]              10\n","          Conv2d-913            [-1, 1, 32, 32]              10\n","          Conv2d-914            [-1, 1, 32, 32]              10\n","          Conv2d-915            [-1, 1, 32, 32]              10\n","          Conv2d-916            [-1, 1, 32, 32]              10\n","          Conv2d-917            [-1, 1, 32, 32]              10\n","          Conv2d-918            [-1, 1, 32, 32]              10\n","          Conv2d-919            [-1, 1, 32, 32]              10\n","          Conv2d-920            [-1, 1, 32, 32]              10\n","          Conv2d-921            [-1, 1, 32, 32]              10\n","          Conv2d-922            [-1, 1, 32, 32]              10\n","          Conv2d-923            [-1, 1, 32, 32]              10\n","          Conv2d-924            [-1, 1, 32, 32]              10\n","          Conv2d-925            [-1, 1, 32, 32]              10\n","          Conv2d-926            [-1, 1, 32, 32]              10\n","          Conv2d-927            [-1, 1, 32, 32]              10\n","          Conv2d-928            [-1, 1, 32, 32]              10\n","          Conv2d-929            [-1, 1, 32, 32]              10\n","          Conv2d-930            [-1, 1, 32, 32]              10\n","          Conv2d-931            [-1, 1, 32, 32]              10\n","          Conv2d-932            [-1, 1, 32, 32]              10\n","          Conv2d-933            [-1, 1, 32, 32]              10\n","          Conv2d-934            [-1, 1, 32, 32]              10\n","          Conv2d-935            [-1, 1, 32, 32]              10\n","          Conv2d-936            [-1, 1, 32, 32]              10\n","          Conv2d-937            [-1, 1, 32, 32]              10\n","          Conv2d-938            [-1, 1, 32, 32]              10\n","    PixelShuffle-939          [-1, 1, 256, 256]               0\n","          Conv2d-940            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-941            [-1, 1, 32, 32]               0\n","          Conv2d-942            [-1, 1, 32, 32]              10\n","          Conv2d-943            [-1, 1, 32, 32]              10\n","          Conv2d-944            [-1, 1, 32, 32]              10\n","          Conv2d-945            [-1, 1, 32, 32]              10\n","          Conv2d-946            [-1, 1, 32, 32]              10\n","          Conv2d-947            [-1, 1, 32, 32]              10\n","          Conv2d-948            [-1, 1, 32, 32]              10\n","          Conv2d-949            [-1, 1, 32, 32]              10\n","          Conv2d-950            [-1, 1, 32, 32]              10\n","          Conv2d-951            [-1, 1, 32, 32]              10\n","          Conv2d-952            [-1, 1, 32, 32]              10\n","          Conv2d-953            [-1, 1, 32, 32]              10\n","          Conv2d-954            [-1, 1, 32, 32]              10\n","          Conv2d-955            [-1, 1, 32, 32]              10\n","          Conv2d-956            [-1, 1, 32, 32]              10\n","          Conv2d-957            [-1, 1, 32, 32]              10\n","          Conv2d-958            [-1, 1, 32, 32]              10\n","          Conv2d-959            [-1, 1, 32, 32]              10\n","          Conv2d-960            [-1, 1, 32, 32]              10\n","          Conv2d-961            [-1, 1, 32, 32]              10\n","          Conv2d-962            [-1, 1, 32, 32]              10\n","          Conv2d-963            [-1, 1, 32, 32]              10\n","          Conv2d-964            [-1, 1, 32, 32]              10\n","          Conv2d-965            [-1, 1, 32, 32]              10\n","          Conv2d-966            [-1, 1, 32, 32]              10\n","          Conv2d-967            [-1, 1, 32, 32]              10\n","          Conv2d-968            [-1, 1, 32, 32]              10\n","          Conv2d-969            [-1, 1, 32, 32]              10\n","          Conv2d-970            [-1, 1, 32, 32]              10\n","          Conv2d-971            [-1, 1, 32, 32]              10\n","          Conv2d-972            [-1, 1, 32, 32]              10\n","          Conv2d-973            [-1, 1, 32, 32]              10\n","          Conv2d-974            [-1, 1, 32, 32]              10\n","          Conv2d-975            [-1, 1, 32, 32]              10\n","          Conv2d-976            [-1, 1, 32, 32]              10\n","          Conv2d-977            [-1, 1, 32, 32]              10\n","          Conv2d-978            [-1, 1, 32, 32]              10\n","          Conv2d-979            [-1, 1, 32, 32]              10\n","          Conv2d-980            [-1, 1, 32, 32]              10\n","          Conv2d-981            [-1, 1, 32, 32]              10\n","          Conv2d-982            [-1, 1, 32, 32]              10\n","          Conv2d-983            [-1, 1, 32, 32]              10\n","          Conv2d-984            [-1, 1, 32, 32]              10\n","          Conv2d-985            [-1, 1, 32, 32]              10\n","          Conv2d-986            [-1, 1, 32, 32]              10\n","          Conv2d-987            [-1, 1, 32, 32]              10\n","          Conv2d-988            [-1, 1, 32, 32]              10\n","          Conv2d-989            [-1, 1, 32, 32]              10\n","          Conv2d-990            [-1, 1, 32, 32]              10\n","          Conv2d-991            [-1, 1, 32, 32]              10\n","          Conv2d-992            [-1, 1, 32, 32]              10\n","          Conv2d-993            [-1, 1, 32, 32]              10\n","          Conv2d-994            [-1, 1, 32, 32]              10\n","          Conv2d-995            [-1, 1, 32, 32]              10\n","          Conv2d-996            [-1, 1, 32, 32]              10\n","          Conv2d-997            [-1, 1, 32, 32]              10\n","          Conv2d-998            [-1, 1, 32, 32]              10\n","          Conv2d-999            [-1, 1, 32, 32]              10\n","         Conv2d-1000            [-1, 1, 32, 32]              10\n","         Conv2d-1001            [-1, 1, 32, 32]              10\n","         Conv2d-1002            [-1, 1, 32, 32]              10\n","         Conv2d-1003            [-1, 1, 32, 32]              10\n","         Conv2d-1004            [-1, 1, 32, 32]              10\n","         Conv2d-1005            [-1, 1, 32, 32]              10\n","   PixelShuffle-1006          [-1, 1, 256, 256]               0\n","         Conv2d-1007            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-1008            [-1, 1, 32, 32]               0\n","         Conv2d-1009            [-1, 1, 32, 32]              10\n","         Conv2d-1010            [-1, 1, 32, 32]              10\n","         Conv2d-1011            [-1, 1, 32, 32]              10\n","         Conv2d-1012            [-1, 1, 32, 32]              10\n","         Conv2d-1013            [-1, 1, 32, 32]              10\n","         Conv2d-1014            [-1, 1, 32, 32]              10\n","         Conv2d-1015            [-1, 1, 32, 32]              10\n","         Conv2d-1016            [-1, 1, 32, 32]              10\n","         Conv2d-1017            [-1, 1, 32, 32]              10\n","         Conv2d-1018            [-1, 1, 32, 32]              10\n","         Conv2d-1019            [-1, 1, 32, 32]              10\n","         Conv2d-1020            [-1, 1, 32, 32]              10\n","         Conv2d-1021            [-1, 1, 32, 32]              10\n","         Conv2d-1022            [-1, 1, 32, 32]              10\n","         Conv2d-1023            [-1, 1, 32, 32]              10\n","         Conv2d-1024            [-1, 1, 32, 32]              10\n","         Conv2d-1025            [-1, 1, 32, 32]              10\n","         Conv2d-1026            [-1, 1, 32, 32]              10\n","         Conv2d-1027            [-1, 1, 32, 32]              10\n","         Conv2d-1028            [-1, 1, 32, 32]              10\n","         Conv2d-1029            [-1, 1, 32, 32]              10\n","         Conv2d-1030            [-1, 1, 32, 32]              10\n","         Conv2d-1031            [-1, 1, 32, 32]              10\n","         Conv2d-1032            [-1, 1, 32, 32]              10\n","         Conv2d-1033            [-1, 1, 32, 32]              10\n","         Conv2d-1034            [-1, 1, 32, 32]              10\n","         Conv2d-1035            [-1, 1, 32, 32]              10\n","         Conv2d-1036            [-1, 1, 32, 32]              10\n","         Conv2d-1037            [-1, 1, 32, 32]              10\n","         Conv2d-1038            [-1, 1, 32, 32]              10\n","         Conv2d-1039            [-1, 1, 32, 32]              10\n","         Conv2d-1040            [-1, 1, 32, 32]              10\n","         Conv2d-1041            [-1, 1, 32, 32]              10\n","         Conv2d-1042            [-1, 1, 32, 32]              10\n","         Conv2d-1043            [-1, 1, 32, 32]              10\n","         Conv2d-1044            [-1, 1, 32, 32]              10\n","         Conv2d-1045            [-1, 1, 32, 32]              10\n","         Conv2d-1046            [-1, 1, 32, 32]              10\n","         Conv2d-1047            [-1, 1, 32, 32]              10\n","         Conv2d-1048            [-1, 1, 32, 32]              10\n","         Conv2d-1049            [-1, 1, 32, 32]              10\n","         Conv2d-1050            [-1, 1, 32, 32]              10\n","         Conv2d-1051            [-1, 1, 32, 32]              10\n","         Conv2d-1052            [-1, 1, 32, 32]              10\n","         Conv2d-1053            [-1, 1, 32, 32]              10\n","         Conv2d-1054            [-1, 1, 32, 32]              10\n","         Conv2d-1055            [-1, 1, 32, 32]              10\n","         Conv2d-1056            [-1, 1, 32, 32]              10\n","         Conv2d-1057            [-1, 1, 32, 32]              10\n","         Conv2d-1058            [-1, 1, 32, 32]              10\n","         Conv2d-1059            [-1, 1, 32, 32]              10\n","         Conv2d-1060            [-1, 1, 32, 32]              10\n","         Conv2d-1061            [-1, 1, 32, 32]              10\n","         Conv2d-1062            [-1, 1, 32, 32]              10\n","         Conv2d-1063            [-1, 1, 32, 32]              10\n","         Conv2d-1064            [-1, 1, 32, 32]              10\n","         Conv2d-1065            [-1, 1, 32, 32]              10\n","         Conv2d-1066            [-1, 1, 32, 32]              10\n","         Conv2d-1067            [-1, 1, 32, 32]              10\n","         Conv2d-1068            [-1, 1, 32, 32]              10\n","         Conv2d-1069            [-1, 1, 32, 32]              10\n","         Conv2d-1070            [-1, 1, 32, 32]              10\n","         Conv2d-1071            [-1, 1, 32, 32]              10\n","         Conv2d-1072            [-1, 1, 32, 32]              10\n","   PixelShuffle-1073          [-1, 1, 256, 256]               0\n","         Conv2d-1074            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-1075            [-1, 1, 32, 32]               0\n","         Conv2d-1076            [-1, 1, 32, 32]              10\n","         Conv2d-1077            [-1, 1, 32, 32]              10\n","         Conv2d-1078            [-1, 1, 32, 32]              10\n","         Conv2d-1079            [-1, 1, 32, 32]              10\n","         Conv2d-1080            [-1, 1, 32, 32]              10\n","         Conv2d-1081            [-1, 1, 32, 32]              10\n","         Conv2d-1082            [-1, 1, 32, 32]              10\n","         Conv2d-1083            [-1, 1, 32, 32]              10\n","         Conv2d-1084            [-1, 1, 32, 32]              10\n","         Conv2d-1085            [-1, 1, 32, 32]              10\n","         Conv2d-1086            [-1, 1, 32, 32]              10\n","         Conv2d-1087            [-1, 1, 32, 32]              10\n","         Conv2d-1088            [-1, 1, 32, 32]              10\n","         Conv2d-1089            [-1, 1, 32, 32]              10\n","         Conv2d-1090            [-1, 1, 32, 32]              10\n","         Conv2d-1091            [-1, 1, 32, 32]              10\n","         Conv2d-1092            [-1, 1, 32, 32]              10\n","         Conv2d-1093            [-1, 1, 32, 32]              10\n","         Conv2d-1094            [-1, 1, 32, 32]              10\n","         Conv2d-1095            [-1, 1, 32, 32]              10\n","         Conv2d-1096            [-1, 1, 32, 32]              10\n","         Conv2d-1097            [-1, 1, 32, 32]              10\n","         Conv2d-1098            [-1, 1, 32, 32]              10\n","         Conv2d-1099            [-1, 1, 32, 32]              10\n","         Conv2d-1100            [-1, 1, 32, 32]              10\n","         Conv2d-1101            [-1, 1, 32, 32]              10\n","         Conv2d-1102            [-1, 1, 32, 32]              10\n","         Conv2d-1103            [-1, 1, 32, 32]              10\n","         Conv2d-1104            [-1, 1, 32, 32]              10\n","         Conv2d-1105            [-1, 1, 32, 32]              10\n","         Conv2d-1106            [-1, 1, 32, 32]              10\n","         Conv2d-1107            [-1, 1, 32, 32]              10\n","         Conv2d-1108            [-1, 1, 32, 32]              10\n","         Conv2d-1109            [-1, 1, 32, 32]              10\n","         Conv2d-1110            [-1, 1, 32, 32]              10\n","         Conv2d-1111            [-1, 1, 32, 32]              10\n","         Conv2d-1112            [-1, 1, 32, 32]              10\n","         Conv2d-1113            [-1, 1, 32, 32]              10\n","         Conv2d-1114            [-1, 1, 32, 32]              10\n","         Conv2d-1115            [-1, 1, 32, 32]              10\n","         Conv2d-1116            [-1, 1, 32, 32]              10\n","         Conv2d-1117            [-1, 1, 32, 32]              10\n","         Conv2d-1118            [-1, 1, 32, 32]              10\n","         Conv2d-1119            [-1, 1, 32, 32]              10\n","         Conv2d-1120            [-1, 1, 32, 32]              10\n","         Conv2d-1121            [-1, 1, 32, 32]              10\n","         Conv2d-1122            [-1, 1, 32, 32]              10\n","         Conv2d-1123            [-1, 1, 32, 32]              10\n","         Conv2d-1124            [-1, 1, 32, 32]              10\n","         Conv2d-1125            [-1, 1, 32, 32]              10\n","         Conv2d-1126            [-1, 1, 32, 32]              10\n","         Conv2d-1127            [-1, 1, 32, 32]              10\n","         Conv2d-1128            [-1, 1, 32, 32]              10\n","         Conv2d-1129            [-1, 1, 32, 32]              10\n","         Conv2d-1130            [-1, 1, 32, 32]              10\n","         Conv2d-1131            [-1, 1, 32, 32]              10\n","         Conv2d-1132            [-1, 1, 32, 32]              10\n","         Conv2d-1133            [-1, 1, 32, 32]              10\n","         Conv2d-1134            [-1, 1, 32, 32]              10\n","         Conv2d-1135            [-1, 1, 32, 32]              10\n","         Conv2d-1136            [-1, 1, 32, 32]              10\n","         Conv2d-1137            [-1, 1, 32, 32]              10\n","         Conv2d-1138            [-1, 1, 32, 32]              10\n","         Conv2d-1139            [-1, 1, 32, 32]              10\n","   PixelShuffle-1140          [-1, 1, 256, 256]               0\n","         Conv2d-1141            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-1142            [-1, 1, 32, 32]               0\n","         Conv2d-1143            [-1, 1, 32, 32]              10\n","         Conv2d-1144            [-1, 1, 32, 32]              10\n","         Conv2d-1145            [-1, 1, 32, 32]              10\n","         Conv2d-1146            [-1, 1, 32, 32]              10\n","         Conv2d-1147            [-1, 1, 32, 32]              10\n","         Conv2d-1148            [-1, 1, 32, 32]              10\n","         Conv2d-1149            [-1, 1, 32, 32]              10\n","         Conv2d-1150            [-1, 1, 32, 32]              10\n","         Conv2d-1151            [-1, 1, 32, 32]              10\n","         Conv2d-1152            [-1, 1, 32, 32]              10\n","         Conv2d-1153            [-1, 1, 32, 32]              10\n","         Conv2d-1154            [-1, 1, 32, 32]              10\n","         Conv2d-1155            [-1, 1, 32, 32]              10\n","         Conv2d-1156            [-1, 1, 32, 32]              10\n","         Conv2d-1157            [-1, 1, 32, 32]              10\n","         Conv2d-1158            [-1, 1, 32, 32]              10\n","         Conv2d-1159            [-1, 1, 32, 32]              10\n","         Conv2d-1160            [-1, 1, 32, 32]              10\n","         Conv2d-1161            [-1, 1, 32, 32]              10\n","         Conv2d-1162            [-1, 1, 32, 32]              10\n","         Conv2d-1163            [-1, 1, 32, 32]              10\n","         Conv2d-1164            [-1, 1, 32, 32]              10\n","         Conv2d-1165            [-1, 1, 32, 32]              10\n","         Conv2d-1166            [-1, 1, 32, 32]              10\n","         Conv2d-1167            [-1, 1, 32, 32]              10\n","         Conv2d-1168            [-1, 1, 32, 32]              10\n","         Conv2d-1169            [-1, 1, 32, 32]              10\n","         Conv2d-1170            [-1, 1, 32, 32]              10\n","         Conv2d-1171            [-1, 1, 32, 32]              10\n","         Conv2d-1172            [-1, 1, 32, 32]              10\n","         Conv2d-1173            [-1, 1, 32, 32]              10\n","         Conv2d-1174            [-1, 1, 32, 32]              10\n","         Conv2d-1175            [-1, 1, 32, 32]              10\n","         Conv2d-1176            [-1, 1, 32, 32]              10\n","         Conv2d-1177            [-1, 1, 32, 32]              10\n","         Conv2d-1178            [-1, 1, 32, 32]              10\n","         Conv2d-1179            [-1, 1, 32, 32]              10\n","         Conv2d-1180            [-1, 1, 32, 32]              10\n","         Conv2d-1181            [-1, 1, 32, 32]              10\n","         Conv2d-1182            [-1, 1, 32, 32]              10\n","         Conv2d-1183            [-1, 1, 32, 32]              10\n","         Conv2d-1184            [-1, 1, 32, 32]              10\n","         Conv2d-1185            [-1, 1, 32, 32]              10\n","         Conv2d-1186            [-1, 1, 32, 32]              10\n","         Conv2d-1187            [-1, 1, 32, 32]              10\n","         Conv2d-1188            [-1, 1, 32, 32]              10\n","         Conv2d-1189            [-1, 1, 32, 32]              10\n","         Conv2d-1190            [-1, 1, 32, 32]              10\n","         Conv2d-1191            [-1, 1, 32, 32]              10\n","         Conv2d-1192            [-1, 1, 32, 32]              10\n","         Conv2d-1193            [-1, 1, 32, 32]              10\n","         Conv2d-1194            [-1, 1, 32, 32]              10\n","         Conv2d-1195            [-1, 1, 32, 32]              10\n","         Conv2d-1196            [-1, 1, 32, 32]              10\n","         Conv2d-1197            [-1, 1, 32, 32]              10\n","         Conv2d-1198            [-1, 1, 32, 32]              10\n","         Conv2d-1199            [-1, 1, 32, 32]              10\n","         Conv2d-1200            [-1, 1, 32, 32]              10\n","         Conv2d-1201            [-1, 1, 32, 32]              10\n","         Conv2d-1202            [-1, 1, 32, 32]              10\n","         Conv2d-1203            [-1, 1, 32, 32]              10\n","         Conv2d-1204            [-1, 1, 32, 32]              10\n","         Conv2d-1205            [-1, 1, 32, 32]              10\n","         Conv2d-1206            [-1, 1, 32, 32]              10\n","   PixelShuffle-1207          [-1, 1, 256, 256]               0\n","         Conv2d-1208            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-1209            [-1, 1, 32, 32]               0\n","         Conv2d-1210            [-1, 1, 32, 32]              10\n","         Conv2d-1211            [-1, 1, 32, 32]              10\n","         Conv2d-1212            [-1, 1, 32, 32]              10\n","         Conv2d-1213            [-1, 1, 32, 32]              10\n","         Conv2d-1214            [-1, 1, 32, 32]              10\n","         Conv2d-1215            [-1, 1, 32, 32]              10\n","         Conv2d-1216            [-1, 1, 32, 32]              10\n","         Conv2d-1217            [-1, 1, 32, 32]              10\n","         Conv2d-1218            [-1, 1, 32, 32]              10\n","         Conv2d-1219            [-1, 1, 32, 32]              10\n","         Conv2d-1220            [-1, 1, 32, 32]              10\n","         Conv2d-1221            [-1, 1, 32, 32]              10\n","         Conv2d-1222            [-1, 1, 32, 32]              10\n","         Conv2d-1223            [-1, 1, 32, 32]              10\n","         Conv2d-1224            [-1, 1, 32, 32]              10\n","         Conv2d-1225            [-1, 1, 32, 32]              10\n","         Conv2d-1226            [-1, 1, 32, 32]              10\n","         Conv2d-1227            [-1, 1, 32, 32]              10\n","         Conv2d-1228            [-1, 1, 32, 32]              10\n","         Conv2d-1229            [-1, 1, 32, 32]              10\n","         Conv2d-1230            [-1, 1, 32, 32]              10\n","         Conv2d-1231            [-1, 1, 32, 32]              10\n","         Conv2d-1232            [-1, 1, 32, 32]              10\n","         Conv2d-1233            [-1, 1, 32, 32]              10\n","         Conv2d-1234            [-1, 1, 32, 32]              10\n","         Conv2d-1235            [-1, 1, 32, 32]              10\n","         Conv2d-1236            [-1, 1, 32, 32]              10\n","         Conv2d-1237            [-1, 1, 32, 32]              10\n","         Conv2d-1238            [-1, 1, 32, 32]              10\n","         Conv2d-1239            [-1, 1, 32, 32]              10\n","         Conv2d-1240            [-1, 1, 32, 32]              10\n","         Conv2d-1241            [-1, 1, 32, 32]              10\n","         Conv2d-1242            [-1, 1, 32, 32]              10\n","         Conv2d-1243            [-1, 1, 32, 32]              10\n","         Conv2d-1244            [-1, 1, 32, 32]              10\n","         Conv2d-1245            [-1, 1, 32, 32]              10\n","         Conv2d-1246            [-1, 1, 32, 32]              10\n","         Conv2d-1247            [-1, 1, 32, 32]              10\n","         Conv2d-1248            [-1, 1, 32, 32]              10\n","         Conv2d-1249            [-1, 1, 32, 32]              10\n","         Conv2d-1250            [-1, 1, 32, 32]              10\n","         Conv2d-1251            [-1, 1, 32, 32]              10\n","         Conv2d-1252            [-1, 1, 32, 32]              10\n","         Conv2d-1253            [-1, 1, 32, 32]              10\n","         Conv2d-1254            [-1, 1, 32, 32]              10\n","         Conv2d-1255            [-1, 1, 32, 32]              10\n","         Conv2d-1256            [-1, 1, 32, 32]              10\n","         Conv2d-1257            [-1, 1, 32, 32]              10\n","         Conv2d-1258            [-1, 1, 32, 32]              10\n","         Conv2d-1259            [-1, 1, 32, 32]              10\n","         Conv2d-1260            [-1, 1, 32, 32]              10\n","         Conv2d-1261            [-1, 1, 32, 32]              10\n","         Conv2d-1262            [-1, 1, 32, 32]              10\n","         Conv2d-1263            [-1, 1, 32, 32]              10\n","         Conv2d-1264            [-1, 1, 32, 32]              10\n","         Conv2d-1265            [-1, 1, 32, 32]              10\n","         Conv2d-1266            [-1, 1, 32, 32]              10\n","         Conv2d-1267            [-1, 1, 32, 32]              10\n","         Conv2d-1268            [-1, 1, 32, 32]              10\n","         Conv2d-1269            [-1, 1, 32, 32]              10\n","         Conv2d-1270            [-1, 1, 32, 32]              10\n","         Conv2d-1271            [-1, 1, 32, 32]              10\n","         Conv2d-1272            [-1, 1, 32, 32]              10\n","         Conv2d-1273            [-1, 1, 32, 32]              10\n","   PixelShuffle-1274          [-1, 1, 256, 256]               0\n","         Conv2d-1275            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-1276            [-1, 1, 32, 32]               0\n","         Conv2d-1277            [-1, 1, 32, 32]              10\n","         Conv2d-1278            [-1, 1, 32, 32]              10\n","         Conv2d-1279            [-1, 1, 32, 32]              10\n","         Conv2d-1280            [-1, 1, 32, 32]              10\n","         Conv2d-1281            [-1, 1, 32, 32]              10\n","         Conv2d-1282            [-1, 1, 32, 32]              10\n","         Conv2d-1283            [-1, 1, 32, 32]              10\n","         Conv2d-1284            [-1, 1, 32, 32]              10\n","         Conv2d-1285            [-1, 1, 32, 32]              10\n","         Conv2d-1286            [-1, 1, 32, 32]              10\n","         Conv2d-1287            [-1, 1, 32, 32]              10\n","         Conv2d-1288            [-1, 1, 32, 32]              10\n","         Conv2d-1289            [-1, 1, 32, 32]              10\n","         Conv2d-1290            [-1, 1, 32, 32]              10\n","         Conv2d-1291            [-1, 1, 32, 32]              10\n","         Conv2d-1292            [-1, 1, 32, 32]              10\n","         Conv2d-1293            [-1, 1, 32, 32]              10\n","         Conv2d-1294            [-1, 1, 32, 32]              10\n","         Conv2d-1295            [-1, 1, 32, 32]              10\n","         Conv2d-1296            [-1, 1, 32, 32]              10\n","         Conv2d-1297            [-1, 1, 32, 32]              10\n","         Conv2d-1298            [-1, 1, 32, 32]              10\n","         Conv2d-1299            [-1, 1, 32, 32]              10\n","         Conv2d-1300            [-1, 1, 32, 32]              10\n","         Conv2d-1301            [-1, 1, 32, 32]              10\n","         Conv2d-1302            [-1, 1, 32, 32]              10\n","         Conv2d-1303            [-1, 1, 32, 32]              10\n","         Conv2d-1304            [-1, 1, 32, 32]              10\n","         Conv2d-1305            [-1, 1, 32, 32]              10\n","         Conv2d-1306            [-1, 1, 32, 32]              10\n","         Conv2d-1307            [-1, 1, 32, 32]              10\n","         Conv2d-1308            [-1, 1, 32, 32]              10\n","         Conv2d-1309            [-1, 1, 32, 32]              10\n","         Conv2d-1310            [-1, 1, 32, 32]              10\n","         Conv2d-1311            [-1, 1, 32, 32]              10\n","         Conv2d-1312            [-1, 1, 32, 32]              10\n","         Conv2d-1313            [-1, 1, 32, 32]              10\n","         Conv2d-1314            [-1, 1, 32, 32]              10\n","         Conv2d-1315            [-1, 1, 32, 32]              10\n","         Conv2d-1316            [-1, 1, 32, 32]              10\n","         Conv2d-1317            [-1, 1, 32, 32]              10\n","         Conv2d-1318            [-1, 1, 32, 32]              10\n","         Conv2d-1319            [-1, 1, 32, 32]              10\n","         Conv2d-1320            [-1, 1, 32, 32]              10\n","         Conv2d-1321            [-1, 1, 32, 32]              10\n","         Conv2d-1322            [-1, 1, 32, 32]              10\n","         Conv2d-1323            [-1, 1, 32, 32]              10\n","         Conv2d-1324            [-1, 1, 32, 32]              10\n","         Conv2d-1325            [-1, 1, 32, 32]              10\n","         Conv2d-1326            [-1, 1, 32, 32]              10\n","         Conv2d-1327            [-1, 1, 32, 32]              10\n","         Conv2d-1328            [-1, 1, 32, 32]              10\n","         Conv2d-1329            [-1, 1, 32, 32]              10\n","         Conv2d-1330            [-1, 1, 32, 32]              10\n","         Conv2d-1331            [-1, 1, 32, 32]              10\n","         Conv2d-1332            [-1, 1, 32, 32]              10\n","         Conv2d-1333            [-1, 1, 32, 32]              10\n","         Conv2d-1334            [-1, 1, 32, 32]              10\n","         Conv2d-1335            [-1, 1, 32, 32]              10\n","         Conv2d-1336            [-1, 1, 32, 32]              10\n","         Conv2d-1337            [-1, 1, 32, 32]              10\n","         Conv2d-1338            [-1, 1, 32, 32]              10\n","         Conv2d-1339            [-1, 1, 32, 32]              10\n","         Conv2d-1340            [-1, 1, 32, 32]              10\n","   PixelShuffle-1341          [-1, 1, 256, 256]               0\n","         Conv2d-1342            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-1343            [-1, 1, 32, 32]               0\n","         Conv2d-1344            [-1, 1, 32, 32]              10\n","         Conv2d-1345            [-1, 1, 32, 32]              10\n","         Conv2d-1346            [-1, 1, 32, 32]              10\n","         Conv2d-1347            [-1, 1, 32, 32]              10\n","         Conv2d-1348            [-1, 1, 32, 32]              10\n","         Conv2d-1349            [-1, 1, 32, 32]              10\n","         Conv2d-1350            [-1, 1, 32, 32]              10\n","         Conv2d-1351            [-1, 1, 32, 32]              10\n","         Conv2d-1352            [-1, 1, 32, 32]              10\n","         Conv2d-1353            [-1, 1, 32, 32]              10\n","         Conv2d-1354            [-1, 1, 32, 32]              10\n","         Conv2d-1355            [-1, 1, 32, 32]              10\n","         Conv2d-1356            [-1, 1, 32, 32]              10\n","         Conv2d-1357            [-1, 1, 32, 32]              10\n","         Conv2d-1358            [-1, 1, 32, 32]              10\n","         Conv2d-1359            [-1, 1, 32, 32]              10\n","         Conv2d-1360            [-1, 1, 32, 32]              10\n","         Conv2d-1361            [-1, 1, 32, 32]              10\n","         Conv2d-1362            [-1, 1, 32, 32]              10\n","         Conv2d-1363            [-1, 1, 32, 32]              10\n","         Conv2d-1364            [-1, 1, 32, 32]              10\n","         Conv2d-1365            [-1, 1, 32, 32]              10\n","         Conv2d-1366            [-1, 1, 32, 32]              10\n","         Conv2d-1367            [-1, 1, 32, 32]              10\n","         Conv2d-1368            [-1, 1, 32, 32]              10\n","         Conv2d-1369            [-1, 1, 32, 32]              10\n","         Conv2d-1370            [-1, 1, 32, 32]              10\n","         Conv2d-1371            [-1, 1, 32, 32]              10\n","         Conv2d-1372            [-1, 1, 32, 32]              10\n","         Conv2d-1373            [-1, 1, 32, 32]              10\n","         Conv2d-1374            [-1, 1, 32, 32]              10\n","         Conv2d-1375            [-1, 1, 32, 32]              10\n","         Conv2d-1376            [-1, 1, 32, 32]              10\n","         Conv2d-1377            [-1, 1, 32, 32]              10\n","         Conv2d-1378            [-1, 1, 32, 32]              10\n","         Conv2d-1379            [-1, 1, 32, 32]              10\n","         Conv2d-1380            [-1, 1, 32, 32]              10\n","         Conv2d-1381            [-1, 1, 32, 32]              10\n","         Conv2d-1382            [-1, 1, 32, 32]              10\n","         Conv2d-1383            [-1, 1, 32, 32]              10\n","         Conv2d-1384            [-1, 1, 32, 32]              10\n","         Conv2d-1385            [-1, 1, 32, 32]              10\n","         Conv2d-1386            [-1, 1, 32, 32]              10\n","         Conv2d-1387            [-1, 1, 32, 32]              10\n","         Conv2d-1388            [-1, 1, 32, 32]              10\n","         Conv2d-1389            [-1, 1, 32, 32]              10\n","         Conv2d-1390            [-1, 1, 32, 32]              10\n","         Conv2d-1391            [-1, 1, 32, 32]              10\n","         Conv2d-1392            [-1, 1, 32, 32]              10\n","         Conv2d-1393            [-1, 1, 32, 32]              10\n","         Conv2d-1394            [-1, 1, 32, 32]              10\n","         Conv2d-1395            [-1, 1, 32, 32]              10\n","         Conv2d-1396            [-1, 1, 32, 32]              10\n","         Conv2d-1397            [-1, 1, 32, 32]              10\n","         Conv2d-1398            [-1, 1, 32, 32]              10\n","         Conv2d-1399            [-1, 1, 32, 32]              10\n","         Conv2d-1400            [-1, 1, 32, 32]              10\n","         Conv2d-1401            [-1, 1, 32, 32]              10\n","         Conv2d-1402            [-1, 1, 32, 32]              10\n","         Conv2d-1403            [-1, 1, 32, 32]              10\n","         Conv2d-1404            [-1, 1, 32, 32]              10\n","         Conv2d-1405            [-1, 1, 32, 32]              10\n","         Conv2d-1406            [-1, 1, 32, 32]              10\n","         Conv2d-1407            [-1, 1, 32, 32]              10\n","   PixelShuffle-1408          [-1, 1, 256, 256]               0\n","         Conv2d-1409            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-1410            [-1, 1, 32, 32]               0\n","         Conv2d-1411            [-1, 1, 32, 32]              10\n","         Conv2d-1412            [-1, 1, 32, 32]              10\n","         Conv2d-1413            [-1, 1, 32, 32]              10\n","         Conv2d-1414            [-1, 1, 32, 32]              10\n","         Conv2d-1415            [-1, 1, 32, 32]              10\n","         Conv2d-1416            [-1, 1, 32, 32]              10\n","         Conv2d-1417            [-1, 1, 32, 32]              10\n","         Conv2d-1418            [-1, 1, 32, 32]              10\n","         Conv2d-1419            [-1, 1, 32, 32]              10\n","         Conv2d-1420            [-1, 1, 32, 32]              10\n","         Conv2d-1421            [-1, 1, 32, 32]              10\n","         Conv2d-1422            [-1, 1, 32, 32]              10\n","         Conv2d-1423            [-1, 1, 32, 32]              10\n","         Conv2d-1424            [-1, 1, 32, 32]              10\n","         Conv2d-1425            [-1, 1, 32, 32]              10\n","         Conv2d-1426            [-1, 1, 32, 32]              10\n","         Conv2d-1427            [-1, 1, 32, 32]              10\n","         Conv2d-1428            [-1, 1, 32, 32]              10\n","         Conv2d-1429            [-1, 1, 32, 32]              10\n","         Conv2d-1430            [-1, 1, 32, 32]              10\n","         Conv2d-1431            [-1, 1, 32, 32]              10\n","         Conv2d-1432            [-1, 1, 32, 32]              10\n","         Conv2d-1433            [-1, 1, 32, 32]              10\n","         Conv2d-1434            [-1, 1, 32, 32]              10\n","         Conv2d-1435            [-1, 1, 32, 32]              10\n","         Conv2d-1436            [-1, 1, 32, 32]              10\n","         Conv2d-1437            [-1, 1, 32, 32]              10\n","         Conv2d-1438            [-1, 1, 32, 32]              10\n","         Conv2d-1439            [-1, 1, 32, 32]              10\n","         Conv2d-1440            [-1, 1, 32, 32]              10\n","         Conv2d-1441            [-1, 1, 32, 32]              10\n","         Conv2d-1442            [-1, 1, 32, 32]              10\n","         Conv2d-1443            [-1, 1, 32, 32]              10\n","         Conv2d-1444            [-1, 1, 32, 32]              10\n","         Conv2d-1445            [-1, 1, 32, 32]              10\n","         Conv2d-1446            [-1, 1, 32, 32]              10\n","         Conv2d-1447            [-1, 1, 32, 32]              10\n","         Conv2d-1448            [-1, 1, 32, 32]              10\n","         Conv2d-1449            [-1, 1, 32, 32]              10\n","         Conv2d-1450            [-1, 1, 32, 32]              10\n","         Conv2d-1451            [-1, 1, 32, 32]              10\n","         Conv2d-1452            [-1, 1, 32, 32]              10\n","         Conv2d-1453            [-1, 1, 32, 32]              10\n","         Conv2d-1454            [-1, 1, 32, 32]              10\n","         Conv2d-1455            [-1, 1, 32, 32]              10\n","         Conv2d-1456            [-1, 1, 32, 32]              10\n","         Conv2d-1457            [-1, 1, 32, 32]              10\n","         Conv2d-1458            [-1, 1, 32, 32]              10\n","         Conv2d-1459            [-1, 1, 32, 32]              10\n","         Conv2d-1460            [-1, 1, 32, 32]              10\n","         Conv2d-1461            [-1, 1, 32, 32]              10\n","         Conv2d-1462            [-1, 1, 32, 32]              10\n","         Conv2d-1463            [-1, 1, 32, 32]              10\n","         Conv2d-1464            [-1, 1, 32, 32]              10\n","         Conv2d-1465            [-1, 1, 32, 32]              10\n","         Conv2d-1466            [-1, 1, 32, 32]              10\n","         Conv2d-1467            [-1, 1, 32, 32]              10\n","         Conv2d-1468            [-1, 1, 32, 32]              10\n","         Conv2d-1469            [-1, 1, 32, 32]              10\n","         Conv2d-1470            [-1, 1, 32, 32]              10\n","         Conv2d-1471            [-1, 1, 32, 32]              10\n","         Conv2d-1472            [-1, 1, 32, 32]              10\n","         Conv2d-1473            [-1, 1, 32, 32]              10\n","         Conv2d-1474            [-1, 1, 32, 32]              10\n","   PixelShuffle-1475          [-1, 1, 256, 256]               0\n","         Conv2d-1476            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-1477            [-1, 1, 32, 32]               0\n","         Conv2d-1478            [-1, 1, 32, 32]              10\n","         Conv2d-1479            [-1, 1, 32, 32]              10\n","         Conv2d-1480            [-1, 1, 32, 32]              10\n","         Conv2d-1481            [-1, 1, 32, 32]              10\n","         Conv2d-1482            [-1, 1, 32, 32]              10\n","         Conv2d-1483            [-1, 1, 32, 32]              10\n","         Conv2d-1484            [-1, 1, 32, 32]              10\n","         Conv2d-1485            [-1, 1, 32, 32]              10\n","         Conv2d-1486            [-1, 1, 32, 32]              10\n","         Conv2d-1487            [-1, 1, 32, 32]              10\n","         Conv2d-1488            [-1, 1, 32, 32]              10\n","         Conv2d-1489            [-1, 1, 32, 32]              10\n","         Conv2d-1490            [-1, 1, 32, 32]              10\n","         Conv2d-1491            [-1, 1, 32, 32]              10\n","         Conv2d-1492            [-1, 1, 32, 32]              10\n","         Conv2d-1493            [-1, 1, 32, 32]              10\n","         Conv2d-1494            [-1, 1, 32, 32]              10\n","         Conv2d-1495            [-1, 1, 32, 32]              10\n","         Conv2d-1496            [-1, 1, 32, 32]              10\n","         Conv2d-1497            [-1, 1, 32, 32]              10\n","         Conv2d-1498            [-1, 1, 32, 32]              10\n","         Conv2d-1499            [-1, 1, 32, 32]              10\n","         Conv2d-1500            [-1, 1, 32, 32]              10\n","         Conv2d-1501            [-1, 1, 32, 32]              10\n","         Conv2d-1502            [-1, 1, 32, 32]              10\n","         Conv2d-1503            [-1, 1, 32, 32]              10\n","         Conv2d-1504            [-1, 1, 32, 32]              10\n","         Conv2d-1505            [-1, 1, 32, 32]              10\n","         Conv2d-1506            [-1, 1, 32, 32]              10\n","         Conv2d-1507            [-1, 1, 32, 32]              10\n","         Conv2d-1508            [-1, 1, 32, 32]              10\n","         Conv2d-1509            [-1, 1, 32, 32]              10\n","         Conv2d-1510            [-1, 1, 32, 32]              10\n","         Conv2d-1511            [-1, 1, 32, 32]              10\n","         Conv2d-1512            [-1, 1, 32, 32]              10\n","         Conv2d-1513            [-1, 1, 32, 32]              10\n","         Conv2d-1514            [-1, 1, 32, 32]              10\n","         Conv2d-1515            [-1, 1, 32, 32]              10\n","         Conv2d-1516            [-1, 1, 32, 32]              10\n","         Conv2d-1517            [-1, 1, 32, 32]              10\n","         Conv2d-1518            [-1, 1, 32, 32]              10\n","         Conv2d-1519            [-1, 1, 32, 32]              10\n","         Conv2d-1520            [-1, 1, 32, 32]              10\n","         Conv2d-1521            [-1, 1, 32, 32]              10\n","         Conv2d-1522            [-1, 1, 32, 32]              10\n","         Conv2d-1523            [-1, 1, 32, 32]              10\n","         Conv2d-1524            [-1, 1, 32, 32]              10\n","         Conv2d-1525            [-1, 1, 32, 32]              10\n","         Conv2d-1526            [-1, 1, 32, 32]              10\n","         Conv2d-1527            [-1, 1, 32, 32]              10\n","         Conv2d-1528            [-1, 1, 32, 32]              10\n","         Conv2d-1529            [-1, 1, 32, 32]              10\n","         Conv2d-1530            [-1, 1, 32, 32]              10\n","         Conv2d-1531            [-1, 1, 32, 32]              10\n","         Conv2d-1532            [-1, 1, 32, 32]              10\n","         Conv2d-1533            [-1, 1, 32, 32]              10\n","         Conv2d-1534            [-1, 1, 32, 32]              10\n","         Conv2d-1535            [-1, 1, 32, 32]              10\n","         Conv2d-1536            [-1, 1, 32, 32]              10\n","         Conv2d-1537            [-1, 1, 32, 32]              10\n","         Conv2d-1538            [-1, 1, 32, 32]              10\n","         Conv2d-1539            [-1, 1, 32, 32]              10\n","         Conv2d-1540            [-1, 1, 32, 32]              10\n","         Conv2d-1541            [-1, 1, 32, 32]              10\n","   PixelShuffle-1542          [-1, 1, 256, 256]               0\n","         Conv2d-1543            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-1544            [-1, 1, 32, 32]               0\n","         Conv2d-1545            [-1, 1, 32, 32]              10\n","         Conv2d-1546            [-1, 1, 32, 32]              10\n","         Conv2d-1547            [-1, 1, 32, 32]              10\n","         Conv2d-1548            [-1, 1, 32, 32]              10\n","         Conv2d-1549            [-1, 1, 32, 32]              10\n","         Conv2d-1550            [-1, 1, 32, 32]              10\n","         Conv2d-1551            [-1, 1, 32, 32]              10\n","         Conv2d-1552            [-1, 1, 32, 32]              10\n","         Conv2d-1553            [-1, 1, 32, 32]              10\n","         Conv2d-1554            [-1, 1, 32, 32]              10\n","         Conv2d-1555            [-1, 1, 32, 32]              10\n","         Conv2d-1556            [-1, 1, 32, 32]              10\n","         Conv2d-1557            [-1, 1, 32, 32]              10\n","         Conv2d-1558            [-1, 1, 32, 32]              10\n","         Conv2d-1559            [-1, 1, 32, 32]              10\n","         Conv2d-1560            [-1, 1, 32, 32]              10\n","         Conv2d-1561            [-1, 1, 32, 32]              10\n","         Conv2d-1562            [-1, 1, 32, 32]              10\n","         Conv2d-1563            [-1, 1, 32, 32]              10\n","         Conv2d-1564            [-1, 1, 32, 32]              10\n","         Conv2d-1565            [-1, 1, 32, 32]              10\n","         Conv2d-1566            [-1, 1, 32, 32]              10\n","         Conv2d-1567            [-1, 1, 32, 32]              10\n","         Conv2d-1568            [-1, 1, 32, 32]              10\n","         Conv2d-1569            [-1, 1, 32, 32]              10\n","         Conv2d-1570            [-1, 1, 32, 32]              10\n","         Conv2d-1571            [-1, 1, 32, 32]              10\n","         Conv2d-1572            [-1, 1, 32, 32]              10\n","         Conv2d-1573            [-1, 1, 32, 32]              10\n","         Conv2d-1574            [-1, 1, 32, 32]              10\n","         Conv2d-1575            [-1, 1, 32, 32]              10\n","         Conv2d-1576            [-1, 1, 32, 32]              10\n","         Conv2d-1577            [-1, 1, 32, 32]              10\n","         Conv2d-1578            [-1, 1, 32, 32]              10\n","         Conv2d-1579            [-1, 1, 32, 32]              10\n","         Conv2d-1580            [-1, 1, 32, 32]              10\n","         Conv2d-1581            [-1, 1, 32, 32]              10\n","         Conv2d-1582            [-1, 1, 32, 32]              10\n","         Conv2d-1583            [-1, 1, 32, 32]              10\n","         Conv2d-1584            [-1, 1, 32, 32]              10\n","         Conv2d-1585            [-1, 1, 32, 32]              10\n","         Conv2d-1586            [-1, 1, 32, 32]              10\n","         Conv2d-1587            [-1, 1, 32, 32]              10\n","         Conv2d-1588            [-1, 1, 32, 32]              10\n","         Conv2d-1589            [-1, 1, 32, 32]              10\n","         Conv2d-1590            [-1, 1, 32, 32]              10\n","         Conv2d-1591            [-1, 1, 32, 32]              10\n","         Conv2d-1592            [-1, 1, 32, 32]              10\n","         Conv2d-1593            [-1, 1, 32, 32]              10\n","         Conv2d-1594            [-1, 1, 32, 32]              10\n","         Conv2d-1595            [-1, 1, 32, 32]              10\n","         Conv2d-1596            [-1, 1, 32, 32]              10\n","         Conv2d-1597            [-1, 1, 32, 32]              10\n","         Conv2d-1598            [-1, 1, 32, 32]              10\n","         Conv2d-1599            [-1, 1, 32, 32]              10\n","         Conv2d-1600            [-1, 1, 32, 32]              10\n","         Conv2d-1601            [-1, 1, 32, 32]              10\n","         Conv2d-1602            [-1, 1, 32, 32]              10\n","         Conv2d-1603            [-1, 1, 32, 32]              10\n","         Conv2d-1604            [-1, 1, 32, 32]              10\n","         Conv2d-1605            [-1, 1, 32, 32]              10\n","         Conv2d-1606            [-1, 1, 32, 32]              10\n","         Conv2d-1607            [-1, 1, 32, 32]              10\n","         Conv2d-1608            [-1, 1, 32, 32]              10\n","   PixelShuffle-1609          [-1, 1, 256, 256]               0\n","         Conv2d-1610            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-1611            [-1, 1, 32, 32]               0\n","         Conv2d-1612            [-1, 1, 32, 32]              10\n","         Conv2d-1613            [-1, 1, 32, 32]              10\n","         Conv2d-1614            [-1, 1, 32, 32]              10\n","         Conv2d-1615            [-1, 1, 32, 32]              10\n","         Conv2d-1616            [-1, 1, 32, 32]              10\n","         Conv2d-1617            [-1, 1, 32, 32]              10\n","         Conv2d-1618            [-1, 1, 32, 32]              10\n","         Conv2d-1619            [-1, 1, 32, 32]              10\n","         Conv2d-1620            [-1, 1, 32, 32]              10\n","         Conv2d-1621            [-1, 1, 32, 32]              10\n","         Conv2d-1622            [-1, 1, 32, 32]              10\n","         Conv2d-1623            [-1, 1, 32, 32]              10\n","         Conv2d-1624            [-1, 1, 32, 32]              10\n","         Conv2d-1625            [-1, 1, 32, 32]              10\n","         Conv2d-1626            [-1, 1, 32, 32]              10\n","         Conv2d-1627            [-1, 1, 32, 32]              10\n","         Conv2d-1628            [-1, 1, 32, 32]              10\n","         Conv2d-1629            [-1, 1, 32, 32]              10\n","         Conv2d-1630            [-1, 1, 32, 32]              10\n","         Conv2d-1631            [-1, 1, 32, 32]              10\n","         Conv2d-1632            [-1, 1, 32, 32]              10\n","         Conv2d-1633            [-1, 1, 32, 32]              10\n","         Conv2d-1634            [-1, 1, 32, 32]              10\n","         Conv2d-1635            [-1, 1, 32, 32]              10\n","         Conv2d-1636            [-1, 1, 32, 32]              10\n","         Conv2d-1637            [-1, 1, 32, 32]              10\n","         Conv2d-1638            [-1, 1, 32, 32]              10\n","         Conv2d-1639            [-1, 1, 32, 32]              10\n","         Conv2d-1640            [-1, 1, 32, 32]              10\n","         Conv2d-1641            [-1, 1, 32, 32]              10\n","         Conv2d-1642            [-1, 1, 32, 32]              10\n","         Conv2d-1643            [-1, 1, 32, 32]              10\n","         Conv2d-1644            [-1, 1, 32, 32]              10\n","         Conv2d-1645            [-1, 1, 32, 32]              10\n","         Conv2d-1646            [-1, 1, 32, 32]              10\n","         Conv2d-1647            [-1, 1, 32, 32]              10\n","         Conv2d-1648            [-1, 1, 32, 32]              10\n","         Conv2d-1649            [-1, 1, 32, 32]              10\n","         Conv2d-1650            [-1, 1, 32, 32]              10\n","         Conv2d-1651            [-1, 1, 32, 32]              10\n","         Conv2d-1652            [-1, 1, 32, 32]              10\n","         Conv2d-1653            [-1, 1, 32, 32]              10\n","         Conv2d-1654            [-1, 1, 32, 32]              10\n","         Conv2d-1655            [-1, 1, 32, 32]              10\n","         Conv2d-1656            [-1, 1, 32, 32]              10\n","         Conv2d-1657            [-1, 1, 32, 32]              10\n","         Conv2d-1658            [-1, 1, 32, 32]              10\n","         Conv2d-1659            [-1, 1, 32, 32]              10\n","         Conv2d-1660            [-1, 1, 32, 32]              10\n","         Conv2d-1661            [-1, 1, 32, 32]              10\n","         Conv2d-1662            [-1, 1, 32, 32]              10\n","         Conv2d-1663            [-1, 1, 32, 32]              10\n","         Conv2d-1664            [-1, 1, 32, 32]              10\n","         Conv2d-1665            [-1, 1, 32, 32]              10\n","         Conv2d-1666            [-1, 1, 32, 32]              10\n","         Conv2d-1667            [-1, 1, 32, 32]              10\n","         Conv2d-1668            [-1, 1, 32, 32]              10\n","         Conv2d-1669            [-1, 1, 32, 32]              10\n","         Conv2d-1670            [-1, 1, 32, 32]              10\n","         Conv2d-1671            [-1, 1, 32, 32]              10\n","         Conv2d-1672            [-1, 1, 32, 32]              10\n","         Conv2d-1673            [-1, 1, 32, 32]              10\n","         Conv2d-1674            [-1, 1, 32, 32]              10\n","         Conv2d-1675            [-1, 1, 32, 32]              10\n","   PixelShuffle-1676          [-1, 1, 256, 256]               0\n","         Conv2d-1677            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-1678            [-1, 1, 32, 32]               0\n","         Conv2d-1679            [-1, 1, 32, 32]              10\n","         Conv2d-1680            [-1, 1, 32, 32]              10\n","         Conv2d-1681            [-1, 1, 32, 32]              10\n","         Conv2d-1682            [-1, 1, 32, 32]              10\n","         Conv2d-1683            [-1, 1, 32, 32]              10\n","         Conv2d-1684            [-1, 1, 32, 32]              10\n","         Conv2d-1685            [-1, 1, 32, 32]              10\n","         Conv2d-1686            [-1, 1, 32, 32]              10\n","         Conv2d-1687            [-1, 1, 32, 32]              10\n","         Conv2d-1688            [-1, 1, 32, 32]              10\n","         Conv2d-1689            [-1, 1, 32, 32]              10\n","         Conv2d-1690            [-1, 1, 32, 32]              10\n","         Conv2d-1691            [-1, 1, 32, 32]              10\n","         Conv2d-1692            [-1, 1, 32, 32]              10\n","         Conv2d-1693            [-1, 1, 32, 32]              10\n","         Conv2d-1694            [-1, 1, 32, 32]              10\n","         Conv2d-1695            [-1, 1, 32, 32]              10\n","         Conv2d-1696            [-1, 1, 32, 32]              10\n","         Conv2d-1697            [-1, 1, 32, 32]              10\n","         Conv2d-1698            [-1, 1, 32, 32]              10\n","         Conv2d-1699            [-1, 1, 32, 32]              10\n","         Conv2d-1700            [-1, 1, 32, 32]              10\n","         Conv2d-1701            [-1, 1, 32, 32]              10\n","         Conv2d-1702            [-1, 1, 32, 32]              10\n","         Conv2d-1703            [-1, 1, 32, 32]              10\n","         Conv2d-1704            [-1, 1, 32, 32]              10\n","         Conv2d-1705            [-1, 1, 32, 32]              10\n","         Conv2d-1706            [-1, 1, 32, 32]              10\n","         Conv2d-1707            [-1, 1, 32, 32]              10\n","         Conv2d-1708            [-1, 1, 32, 32]              10\n","         Conv2d-1709            [-1, 1, 32, 32]              10\n","         Conv2d-1710            [-1, 1, 32, 32]              10\n","         Conv2d-1711            [-1, 1, 32, 32]              10\n","         Conv2d-1712            [-1, 1, 32, 32]              10\n","         Conv2d-1713            [-1, 1, 32, 32]              10\n","         Conv2d-1714            [-1, 1, 32, 32]              10\n","         Conv2d-1715            [-1, 1, 32, 32]              10\n","         Conv2d-1716            [-1, 1, 32, 32]              10\n","         Conv2d-1717            [-1, 1, 32, 32]              10\n","         Conv2d-1718            [-1, 1, 32, 32]              10\n","         Conv2d-1719            [-1, 1, 32, 32]              10\n","         Conv2d-1720            [-1, 1, 32, 32]              10\n","         Conv2d-1721            [-1, 1, 32, 32]              10\n","         Conv2d-1722            [-1, 1, 32, 32]              10\n","         Conv2d-1723            [-1, 1, 32, 32]              10\n","         Conv2d-1724            [-1, 1, 32, 32]              10\n","         Conv2d-1725            [-1, 1, 32, 32]              10\n","         Conv2d-1726            [-1, 1, 32, 32]              10\n","         Conv2d-1727            [-1, 1, 32, 32]              10\n","         Conv2d-1728            [-1, 1, 32, 32]              10\n","         Conv2d-1729            [-1, 1, 32, 32]              10\n","         Conv2d-1730            [-1, 1, 32, 32]              10\n","         Conv2d-1731            [-1, 1, 32, 32]              10\n","         Conv2d-1732            [-1, 1, 32, 32]              10\n","         Conv2d-1733            [-1, 1, 32, 32]              10\n","         Conv2d-1734            [-1, 1, 32, 32]              10\n","         Conv2d-1735            [-1, 1, 32, 32]              10\n","         Conv2d-1736            [-1, 1, 32, 32]              10\n","         Conv2d-1737            [-1, 1, 32, 32]              10\n","         Conv2d-1738            [-1, 1, 32, 32]              10\n","         Conv2d-1739            [-1, 1, 32, 32]              10\n","         Conv2d-1740            [-1, 1, 32, 32]              10\n","         Conv2d-1741            [-1, 1, 32, 32]              10\n","         Conv2d-1742            [-1, 1, 32, 32]              10\n","   PixelShuffle-1743          [-1, 1, 256, 256]               0\n","         Conv2d-1744            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-1745            [-1, 1, 32, 32]               0\n","         Conv2d-1746            [-1, 1, 32, 32]              10\n","         Conv2d-1747            [-1, 1, 32, 32]              10\n","         Conv2d-1748            [-1, 1, 32, 32]              10\n","         Conv2d-1749            [-1, 1, 32, 32]              10\n","         Conv2d-1750            [-1, 1, 32, 32]              10\n","         Conv2d-1751            [-1, 1, 32, 32]              10\n","         Conv2d-1752            [-1, 1, 32, 32]              10\n","         Conv2d-1753            [-1, 1, 32, 32]              10\n","         Conv2d-1754            [-1, 1, 32, 32]              10\n","         Conv2d-1755            [-1, 1, 32, 32]              10\n","         Conv2d-1756            [-1, 1, 32, 32]              10\n","         Conv2d-1757            [-1, 1, 32, 32]              10\n","         Conv2d-1758            [-1, 1, 32, 32]              10\n","         Conv2d-1759            [-1, 1, 32, 32]              10\n","         Conv2d-1760            [-1, 1, 32, 32]              10\n","         Conv2d-1761            [-1, 1, 32, 32]              10\n","         Conv2d-1762            [-1, 1, 32, 32]              10\n","         Conv2d-1763            [-1, 1, 32, 32]              10\n","         Conv2d-1764            [-1, 1, 32, 32]              10\n","         Conv2d-1765            [-1, 1, 32, 32]              10\n","         Conv2d-1766            [-1, 1, 32, 32]              10\n","         Conv2d-1767            [-1, 1, 32, 32]              10\n","         Conv2d-1768            [-1, 1, 32, 32]              10\n","         Conv2d-1769            [-1, 1, 32, 32]              10\n","         Conv2d-1770            [-1, 1, 32, 32]              10\n","         Conv2d-1771            [-1, 1, 32, 32]              10\n","         Conv2d-1772            [-1, 1, 32, 32]              10\n","         Conv2d-1773            [-1, 1, 32, 32]              10\n","         Conv2d-1774            [-1, 1, 32, 32]              10\n","         Conv2d-1775            [-1, 1, 32, 32]              10\n","         Conv2d-1776            [-1, 1, 32, 32]              10\n","         Conv2d-1777            [-1, 1, 32, 32]              10\n","         Conv2d-1778            [-1, 1, 32, 32]              10\n","         Conv2d-1779            [-1, 1, 32, 32]              10\n","         Conv2d-1780            [-1, 1, 32, 32]              10\n","         Conv2d-1781            [-1, 1, 32, 32]              10\n","         Conv2d-1782            [-1, 1, 32, 32]              10\n","         Conv2d-1783            [-1, 1, 32, 32]              10\n","         Conv2d-1784            [-1, 1, 32, 32]              10\n","         Conv2d-1785            [-1, 1, 32, 32]              10\n","         Conv2d-1786            [-1, 1, 32, 32]              10\n","         Conv2d-1787            [-1, 1, 32, 32]              10\n","         Conv2d-1788            [-1, 1, 32, 32]              10\n","         Conv2d-1789            [-1, 1, 32, 32]              10\n","         Conv2d-1790            [-1, 1, 32, 32]              10\n","         Conv2d-1791            [-1, 1, 32, 32]              10\n","         Conv2d-1792            [-1, 1, 32, 32]              10\n","         Conv2d-1793            [-1, 1, 32, 32]              10\n","         Conv2d-1794            [-1, 1, 32, 32]              10\n","         Conv2d-1795            [-1, 1, 32, 32]              10\n","         Conv2d-1796            [-1, 1, 32, 32]              10\n","         Conv2d-1797            [-1, 1, 32, 32]              10\n","         Conv2d-1798            [-1, 1, 32, 32]              10\n","         Conv2d-1799            [-1, 1, 32, 32]              10\n","         Conv2d-1800            [-1, 1, 32, 32]              10\n","         Conv2d-1801            [-1, 1, 32, 32]              10\n","         Conv2d-1802            [-1, 1, 32, 32]              10\n","         Conv2d-1803            [-1, 1, 32, 32]              10\n","         Conv2d-1804            [-1, 1, 32, 32]              10\n","         Conv2d-1805            [-1, 1, 32, 32]              10\n","         Conv2d-1806            [-1, 1, 32, 32]              10\n","         Conv2d-1807            [-1, 1, 32, 32]              10\n","         Conv2d-1808            [-1, 1, 32, 32]              10\n","         Conv2d-1809            [-1, 1, 32, 32]              10\n","   PixelShuffle-1810          [-1, 1, 256, 256]               0\n","         Conv2d-1811            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-1812            [-1, 1, 32, 32]               0\n","         Conv2d-1813            [-1, 1, 32, 32]              10\n","         Conv2d-1814            [-1, 1, 32, 32]              10\n","         Conv2d-1815            [-1, 1, 32, 32]              10\n","         Conv2d-1816            [-1, 1, 32, 32]              10\n","         Conv2d-1817            [-1, 1, 32, 32]              10\n","         Conv2d-1818            [-1, 1, 32, 32]              10\n","         Conv2d-1819            [-1, 1, 32, 32]              10\n","         Conv2d-1820            [-1, 1, 32, 32]              10\n","         Conv2d-1821            [-1, 1, 32, 32]              10\n","         Conv2d-1822            [-1, 1, 32, 32]              10\n","         Conv2d-1823            [-1, 1, 32, 32]              10\n","         Conv2d-1824            [-1, 1, 32, 32]              10\n","         Conv2d-1825            [-1, 1, 32, 32]              10\n","         Conv2d-1826            [-1, 1, 32, 32]              10\n","         Conv2d-1827            [-1, 1, 32, 32]              10\n","         Conv2d-1828            [-1, 1, 32, 32]              10\n","         Conv2d-1829            [-1, 1, 32, 32]              10\n","         Conv2d-1830            [-1, 1, 32, 32]              10\n","         Conv2d-1831            [-1, 1, 32, 32]              10\n","         Conv2d-1832            [-1, 1, 32, 32]              10\n","         Conv2d-1833            [-1, 1, 32, 32]              10\n","         Conv2d-1834            [-1, 1, 32, 32]              10\n","         Conv2d-1835            [-1, 1, 32, 32]              10\n","         Conv2d-1836            [-1, 1, 32, 32]              10\n","         Conv2d-1837            [-1, 1, 32, 32]              10\n","         Conv2d-1838            [-1, 1, 32, 32]              10\n","         Conv2d-1839            [-1, 1, 32, 32]              10\n","         Conv2d-1840            [-1, 1, 32, 32]              10\n","         Conv2d-1841            [-1, 1, 32, 32]              10\n","         Conv2d-1842            [-1, 1, 32, 32]              10\n","         Conv2d-1843            [-1, 1, 32, 32]              10\n","         Conv2d-1844            [-1, 1, 32, 32]              10\n","         Conv2d-1845            [-1, 1, 32, 32]              10\n","         Conv2d-1846            [-1, 1, 32, 32]              10\n","         Conv2d-1847            [-1, 1, 32, 32]              10\n","         Conv2d-1848            [-1, 1, 32, 32]              10\n","         Conv2d-1849            [-1, 1, 32, 32]              10\n","         Conv2d-1850            [-1, 1, 32, 32]              10\n","         Conv2d-1851            [-1, 1, 32, 32]              10\n","         Conv2d-1852            [-1, 1, 32, 32]              10\n","         Conv2d-1853            [-1, 1, 32, 32]              10\n","         Conv2d-1854            [-1, 1, 32, 32]              10\n","         Conv2d-1855            [-1, 1, 32, 32]              10\n","         Conv2d-1856            [-1, 1, 32, 32]              10\n","         Conv2d-1857            [-1, 1, 32, 32]              10\n","         Conv2d-1858            [-1, 1, 32, 32]              10\n","         Conv2d-1859            [-1, 1, 32, 32]              10\n","         Conv2d-1860            [-1, 1, 32, 32]              10\n","         Conv2d-1861            [-1, 1, 32, 32]              10\n","         Conv2d-1862            [-1, 1, 32, 32]              10\n","         Conv2d-1863            [-1, 1, 32, 32]              10\n","         Conv2d-1864            [-1, 1, 32, 32]              10\n","         Conv2d-1865            [-1, 1, 32, 32]              10\n","         Conv2d-1866            [-1, 1, 32, 32]              10\n","         Conv2d-1867            [-1, 1, 32, 32]              10\n","         Conv2d-1868            [-1, 1, 32, 32]              10\n","         Conv2d-1869            [-1, 1, 32, 32]              10\n","         Conv2d-1870            [-1, 1, 32, 32]              10\n","         Conv2d-1871            [-1, 1, 32, 32]              10\n","         Conv2d-1872            [-1, 1, 32, 32]              10\n","         Conv2d-1873            [-1, 1, 32, 32]              10\n","         Conv2d-1874            [-1, 1, 32, 32]              10\n","         Conv2d-1875            [-1, 1, 32, 32]              10\n","         Conv2d-1876            [-1, 1, 32, 32]              10\n","   PixelShuffle-1877          [-1, 1, 256, 256]               0\n","         Conv2d-1878            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-1879            [-1, 1, 32, 32]               0\n","         Conv2d-1880            [-1, 1, 32, 32]              10\n","         Conv2d-1881            [-1, 1, 32, 32]              10\n","         Conv2d-1882            [-1, 1, 32, 32]              10\n","         Conv2d-1883            [-1, 1, 32, 32]              10\n","         Conv2d-1884            [-1, 1, 32, 32]              10\n","         Conv2d-1885            [-1, 1, 32, 32]              10\n","         Conv2d-1886            [-1, 1, 32, 32]              10\n","         Conv2d-1887            [-1, 1, 32, 32]              10\n","         Conv2d-1888            [-1, 1, 32, 32]              10\n","         Conv2d-1889            [-1, 1, 32, 32]              10\n","         Conv2d-1890            [-1, 1, 32, 32]              10\n","         Conv2d-1891            [-1, 1, 32, 32]              10\n","         Conv2d-1892            [-1, 1, 32, 32]              10\n","         Conv2d-1893            [-1, 1, 32, 32]              10\n","         Conv2d-1894            [-1, 1, 32, 32]              10\n","         Conv2d-1895            [-1, 1, 32, 32]              10\n","         Conv2d-1896            [-1, 1, 32, 32]              10\n","         Conv2d-1897            [-1, 1, 32, 32]              10\n","         Conv2d-1898            [-1, 1, 32, 32]              10\n","         Conv2d-1899            [-1, 1, 32, 32]              10\n","         Conv2d-1900            [-1, 1, 32, 32]              10\n","         Conv2d-1901            [-1, 1, 32, 32]              10\n","         Conv2d-1902            [-1, 1, 32, 32]              10\n","         Conv2d-1903            [-1, 1, 32, 32]              10\n","         Conv2d-1904            [-1, 1, 32, 32]              10\n","         Conv2d-1905            [-1, 1, 32, 32]              10\n","         Conv2d-1906            [-1, 1, 32, 32]              10\n","         Conv2d-1907            [-1, 1, 32, 32]              10\n","         Conv2d-1908            [-1, 1, 32, 32]              10\n","         Conv2d-1909            [-1, 1, 32, 32]              10\n","         Conv2d-1910            [-1, 1, 32, 32]              10\n","         Conv2d-1911            [-1, 1, 32, 32]              10\n","         Conv2d-1912            [-1, 1, 32, 32]              10\n","         Conv2d-1913            [-1, 1, 32, 32]              10\n","         Conv2d-1914            [-1, 1, 32, 32]              10\n","         Conv2d-1915            [-1, 1, 32, 32]              10\n","         Conv2d-1916            [-1, 1, 32, 32]              10\n","         Conv2d-1917            [-1, 1, 32, 32]              10\n","         Conv2d-1918            [-1, 1, 32, 32]              10\n","         Conv2d-1919            [-1, 1, 32, 32]              10\n","         Conv2d-1920            [-1, 1, 32, 32]              10\n","         Conv2d-1921            [-1, 1, 32, 32]              10\n","         Conv2d-1922            [-1, 1, 32, 32]              10\n","         Conv2d-1923            [-1, 1, 32, 32]              10\n","         Conv2d-1924            [-1, 1, 32, 32]              10\n","         Conv2d-1925            [-1, 1, 32, 32]              10\n","         Conv2d-1926            [-1, 1, 32, 32]              10\n","         Conv2d-1927            [-1, 1, 32, 32]              10\n","         Conv2d-1928            [-1, 1, 32, 32]              10\n","         Conv2d-1929            [-1, 1, 32, 32]              10\n","         Conv2d-1930            [-1, 1, 32, 32]              10\n","         Conv2d-1931            [-1, 1, 32, 32]              10\n","         Conv2d-1932            [-1, 1, 32, 32]              10\n","         Conv2d-1933            [-1, 1, 32, 32]              10\n","         Conv2d-1934            [-1, 1, 32, 32]              10\n","         Conv2d-1935            [-1, 1, 32, 32]              10\n","         Conv2d-1936            [-1, 1, 32, 32]              10\n","         Conv2d-1937            [-1, 1, 32, 32]              10\n","         Conv2d-1938            [-1, 1, 32, 32]              10\n","         Conv2d-1939            [-1, 1, 32, 32]              10\n","         Conv2d-1940            [-1, 1, 32, 32]              10\n","         Conv2d-1941            [-1, 1, 32, 32]              10\n","         Conv2d-1942            [-1, 1, 32, 32]              10\n","         Conv2d-1943            [-1, 1, 32, 32]              10\n","   PixelShuffle-1944          [-1, 1, 256, 256]               0\n","         Conv2d-1945            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-1946            [-1, 1, 32, 32]               0\n","         Conv2d-1947            [-1, 1, 32, 32]              10\n","         Conv2d-1948            [-1, 1, 32, 32]              10\n","         Conv2d-1949            [-1, 1, 32, 32]              10\n","         Conv2d-1950            [-1, 1, 32, 32]              10\n","         Conv2d-1951            [-1, 1, 32, 32]              10\n","         Conv2d-1952            [-1, 1, 32, 32]              10\n","         Conv2d-1953            [-1, 1, 32, 32]              10\n","         Conv2d-1954            [-1, 1, 32, 32]              10\n","         Conv2d-1955            [-1, 1, 32, 32]              10\n","         Conv2d-1956            [-1, 1, 32, 32]              10\n","         Conv2d-1957            [-1, 1, 32, 32]              10\n","         Conv2d-1958            [-1, 1, 32, 32]              10\n","         Conv2d-1959            [-1, 1, 32, 32]              10\n","         Conv2d-1960            [-1, 1, 32, 32]              10\n","         Conv2d-1961            [-1, 1, 32, 32]              10\n","         Conv2d-1962            [-1, 1, 32, 32]              10\n","         Conv2d-1963            [-1, 1, 32, 32]              10\n","         Conv2d-1964            [-1, 1, 32, 32]              10\n","         Conv2d-1965            [-1, 1, 32, 32]              10\n","         Conv2d-1966            [-1, 1, 32, 32]              10\n","         Conv2d-1967            [-1, 1, 32, 32]              10\n","         Conv2d-1968            [-1, 1, 32, 32]              10\n","         Conv2d-1969            [-1, 1, 32, 32]              10\n","         Conv2d-1970            [-1, 1, 32, 32]              10\n","         Conv2d-1971            [-1, 1, 32, 32]              10\n","         Conv2d-1972            [-1, 1, 32, 32]              10\n","         Conv2d-1973            [-1, 1, 32, 32]              10\n","         Conv2d-1974            [-1, 1, 32, 32]              10\n","         Conv2d-1975            [-1, 1, 32, 32]              10\n","         Conv2d-1976            [-1, 1, 32, 32]              10\n","         Conv2d-1977            [-1, 1, 32, 32]              10\n","         Conv2d-1978            [-1, 1, 32, 32]              10\n","         Conv2d-1979            [-1, 1, 32, 32]              10\n","         Conv2d-1980            [-1, 1, 32, 32]              10\n","         Conv2d-1981            [-1, 1, 32, 32]              10\n","         Conv2d-1982            [-1, 1, 32, 32]              10\n","         Conv2d-1983            [-1, 1, 32, 32]              10\n","         Conv2d-1984            [-1, 1, 32, 32]              10\n","         Conv2d-1985            [-1, 1, 32, 32]              10\n","         Conv2d-1986            [-1, 1, 32, 32]              10\n","         Conv2d-1987            [-1, 1, 32, 32]              10\n","         Conv2d-1988            [-1, 1, 32, 32]              10\n","         Conv2d-1989            [-1, 1, 32, 32]              10\n","         Conv2d-1990            [-1, 1, 32, 32]              10\n","         Conv2d-1991            [-1, 1, 32, 32]              10\n","         Conv2d-1992            [-1, 1, 32, 32]              10\n","         Conv2d-1993            [-1, 1, 32, 32]              10\n","         Conv2d-1994            [-1, 1, 32, 32]              10\n","         Conv2d-1995            [-1, 1, 32, 32]              10\n","         Conv2d-1996            [-1, 1, 32, 32]              10\n","         Conv2d-1997            [-1, 1, 32, 32]              10\n","         Conv2d-1998            [-1, 1, 32, 32]              10\n","         Conv2d-1999            [-1, 1, 32, 32]              10\n","         Conv2d-2000            [-1, 1, 32, 32]              10\n","         Conv2d-2001            [-1, 1, 32, 32]              10\n","         Conv2d-2002            [-1, 1, 32, 32]              10\n","         Conv2d-2003            [-1, 1, 32, 32]              10\n","         Conv2d-2004            [-1, 1, 32, 32]              10\n","         Conv2d-2005            [-1, 1, 32, 32]              10\n","         Conv2d-2006            [-1, 1, 32, 32]              10\n","         Conv2d-2007            [-1, 1, 32, 32]              10\n","         Conv2d-2008            [-1, 1, 32, 32]              10\n","         Conv2d-2009            [-1, 1, 32, 32]              10\n","         Conv2d-2010            [-1, 1, 32, 32]              10\n","   PixelShuffle-2011          [-1, 1, 256, 256]               0\n","         Conv2d-2012            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-2013            [-1, 1, 32, 32]               0\n","         Conv2d-2014            [-1, 1, 32, 32]              10\n","         Conv2d-2015            [-1, 1, 32, 32]              10\n","         Conv2d-2016            [-1, 1, 32, 32]              10\n","         Conv2d-2017            [-1, 1, 32, 32]              10\n","         Conv2d-2018            [-1, 1, 32, 32]              10\n","         Conv2d-2019            [-1, 1, 32, 32]              10\n","         Conv2d-2020            [-1, 1, 32, 32]              10\n","         Conv2d-2021            [-1, 1, 32, 32]              10\n","         Conv2d-2022            [-1, 1, 32, 32]              10\n","         Conv2d-2023            [-1, 1, 32, 32]              10\n","         Conv2d-2024            [-1, 1, 32, 32]              10\n","         Conv2d-2025            [-1, 1, 32, 32]              10\n","         Conv2d-2026            [-1, 1, 32, 32]              10\n","         Conv2d-2027            [-1, 1, 32, 32]              10\n","         Conv2d-2028            [-1, 1, 32, 32]              10\n","         Conv2d-2029            [-1, 1, 32, 32]              10\n","         Conv2d-2030            [-1, 1, 32, 32]              10\n","         Conv2d-2031            [-1, 1, 32, 32]              10\n","         Conv2d-2032            [-1, 1, 32, 32]              10\n","         Conv2d-2033            [-1, 1, 32, 32]              10\n","         Conv2d-2034            [-1, 1, 32, 32]              10\n","         Conv2d-2035            [-1, 1, 32, 32]              10\n","         Conv2d-2036            [-1, 1, 32, 32]              10\n","         Conv2d-2037            [-1, 1, 32, 32]              10\n","         Conv2d-2038            [-1, 1, 32, 32]              10\n","         Conv2d-2039            [-1, 1, 32, 32]              10\n","         Conv2d-2040            [-1, 1, 32, 32]              10\n","         Conv2d-2041            [-1, 1, 32, 32]              10\n","         Conv2d-2042            [-1, 1, 32, 32]              10\n","         Conv2d-2043            [-1, 1, 32, 32]              10\n","         Conv2d-2044            [-1, 1, 32, 32]              10\n","         Conv2d-2045            [-1, 1, 32, 32]              10\n","         Conv2d-2046            [-1, 1, 32, 32]              10\n","         Conv2d-2047            [-1, 1, 32, 32]              10\n","         Conv2d-2048            [-1, 1, 32, 32]              10\n","         Conv2d-2049            [-1, 1, 32, 32]              10\n","         Conv2d-2050            [-1, 1, 32, 32]              10\n","         Conv2d-2051            [-1, 1, 32, 32]              10\n","         Conv2d-2052            [-1, 1, 32, 32]              10\n","         Conv2d-2053            [-1, 1, 32, 32]              10\n","         Conv2d-2054            [-1, 1, 32, 32]              10\n","         Conv2d-2055            [-1, 1, 32, 32]              10\n","         Conv2d-2056            [-1, 1, 32, 32]              10\n","         Conv2d-2057            [-1, 1, 32, 32]              10\n","         Conv2d-2058            [-1, 1, 32, 32]              10\n","         Conv2d-2059            [-1, 1, 32, 32]              10\n","         Conv2d-2060            [-1, 1, 32, 32]              10\n","         Conv2d-2061            [-1, 1, 32, 32]              10\n","         Conv2d-2062            [-1, 1, 32, 32]              10\n","         Conv2d-2063            [-1, 1, 32, 32]              10\n","         Conv2d-2064            [-1, 1, 32, 32]              10\n","         Conv2d-2065            [-1, 1, 32, 32]              10\n","         Conv2d-2066            [-1, 1, 32, 32]              10\n","         Conv2d-2067            [-1, 1, 32, 32]              10\n","         Conv2d-2068            [-1, 1, 32, 32]              10\n","         Conv2d-2069            [-1, 1, 32, 32]              10\n","         Conv2d-2070            [-1, 1, 32, 32]              10\n","         Conv2d-2071            [-1, 1, 32, 32]              10\n","         Conv2d-2072            [-1, 1, 32, 32]              10\n","         Conv2d-2073            [-1, 1, 32, 32]              10\n","         Conv2d-2074            [-1, 1, 32, 32]              10\n","         Conv2d-2075            [-1, 1, 32, 32]              10\n","         Conv2d-2076            [-1, 1, 32, 32]              10\n","         Conv2d-2077            [-1, 1, 32, 32]              10\n","   PixelShuffle-2078          [-1, 1, 256, 256]               0\n","         Conv2d-2079            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-2080            [-1, 1, 32, 32]               0\n","         Conv2d-2081            [-1, 1, 32, 32]              10\n","         Conv2d-2082            [-1, 1, 32, 32]              10\n","         Conv2d-2083            [-1, 1, 32, 32]              10\n","         Conv2d-2084            [-1, 1, 32, 32]              10\n","         Conv2d-2085            [-1, 1, 32, 32]              10\n","         Conv2d-2086            [-1, 1, 32, 32]              10\n","         Conv2d-2087            [-1, 1, 32, 32]              10\n","         Conv2d-2088            [-1, 1, 32, 32]              10\n","         Conv2d-2089            [-1, 1, 32, 32]              10\n","         Conv2d-2090            [-1, 1, 32, 32]              10\n","         Conv2d-2091            [-1, 1, 32, 32]              10\n","         Conv2d-2092            [-1, 1, 32, 32]              10\n","         Conv2d-2093            [-1, 1, 32, 32]              10\n","         Conv2d-2094            [-1, 1, 32, 32]              10\n","         Conv2d-2095            [-1, 1, 32, 32]              10\n","         Conv2d-2096            [-1, 1, 32, 32]              10\n","         Conv2d-2097            [-1, 1, 32, 32]              10\n","         Conv2d-2098            [-1, 1, 32, 32]              10\n","         Conv2d-2099            [-1, 1, 32, 32]              10\n","         Conv2d-2100            [-1, 1, 32, 32]              10\n","         Conv2d-2101            [-1, 1, 32, 32]              10\n","         Conv2d-2102            [-1, 1, 32, 32]              10\n","         Conv2d-2103            [-1, 1, 32, 32]              10\n","         Conv2d-2104            [-1, 1, 32, 32]              10\n","         Conv2d-2105            [-1, 1, 32, 32]              10\n","         Conv2d-2106            [-1, 1, 32, 32]              10\n","         Conv2d-2107            [-1, 1, 32, 32]              10\n","         Conv2d-2108            [-1, 1, 32, 32]              10\n","         Conv2d-2109            [-1, 1, 32, 32]              10\n","         Conv2d-2110            [-1, 1, 32, 32]              10\n","         Conv2d-2111            [-1, 1, 32, 32]              10\n","         Conv2d-2112            [-1, 1, 32, 32]              10\n","         Conv2d-2113            [-1, 1, 32, 32]              10\n","         Conv2d-2114            [-1, 1, 32, 32]              10\n","         Conv2d-2115            [-1, 1, 32, 32]              10\n","         Conv2d-2116            [-1, 1, 32, 32]              10\n","         Conv2d-2117            [-1, 1, 32, 32]              10\n","         Conv2d-2118            [-1, 1, 32, 32]              10\n","         Conv2d-2119            [-1, 1, 32, 32]              10\n","         Conv2d-2120            [-1, 1, 32, 32]              10\n","         Conv2d-2121            [-1, 1, 32, 32]              10\n","         Conv2d-2122            [-1, 1, 32, 32]              10\n","         Conv2d-2123            [-1, 1, 32, 32]              10\n","         Conv2d-2124            [-1, 1, 32, 32]              10\n","         Conv2d-2125            [-1, 1, 32, 32]              10\n","         Conv2d-2126            [-1, 1, 32, 32]              10\n","         Conv2d-2127            [-1, 1, 32, 32]              10\n","         Conv2d-2128            [-1, 1, 32, 32]              10\n","         Conv2d-2129            [-1, 1, 32, 32]              10\n","         Conv2d-2130            [-1, 1, 32, 32]              10\n","         Conv2d-2131            [-1, 1, 32, 32]              10\n","         Conv2d-2132            [-1, 1, 32, 32]              10\n","         Conv2d-2133            [-1, 1, 32, 32]              10\n","         Conv2d-2134            [-1, 1, 32, 32]              10\n","         Conv2d-2135            [-1, 1, 32, 32]              10\n","         Conv2d-2136            [-1, 1, 32, 32]              10\n","         Conv2d-2137            [-1, 1, 32, 32]              10\n","         Conv2d-2138            [-1, 1, 32, 32]              10\n","         Conv2d-2139            [-1, 1, 32, 32]              10\n","         Conv2d-2140            [-1, 1, 32, 32]              10\n","         Conv2d-2141            [-1, 1, 32, 32]              10\n","         Conv2d-2142            [-1, 1, 32, 32]              10\n","         Conv2d-2143            [-1, 1, 32, 32]              10\n","         Conv2d-2144            [-1, 1, 32, 32]              10\n","   PixelShuffle-2145          [-1, 1, 256, 256]               0\n","         Conv2d-2146            [-1, 1, 32, 32]              65\n","Channel_weighted_Conv-2147            [-1, 1, 32, 32]               0\n","     WCNN_block-2148           [-1, 32, 32, 32]               0\n","           ReLU-2149           [-1, 32, 32, 32]               0\n","         Conv2d-2150            [-1, 3, 32, 32]           2,403\n","      ConvBlock-2151            [-1, 3, 32, 32]               0\n","           WCNN-2152            [-1, 3, 32, 32]               0\n","================================================================\n","Total params: 40,579\n","Trainable params: 40,579\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.01\n","Forward/backward pass size (MB): 34.57\n","Params size (MB): 0.15\n","Estimated Total Size (MB): 34.74\n","----------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EQghodZmvqRp","executionInfo":{"status":"ok","timestamp":1621532941480,"user_tz":-540,"elapsed":4,"user":{"displayName":"김정기","photoUrl":"","userId":"02654207523640478753"}},"outputId":"5caf187b-735d-40f6-9ebe-0b105029d45e"},"source":["# 데이터 전처리 & 사용자 정의 data\n","\n","from __future__ import print_function\n","import argparse\n","\n","import os\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision.transforms import *\n","import torch\n","import math\n","from os.path import join\n","import torch.utils.data as data\n","import numpy as np\n","from os import listdir\n","from os.path import join\n","from PIL import Image, ImageOps, ImageFilter\n","import random\n","from random import randrange\n","from math import sqrt\n","\n","'''\n","1. filename 에 .png, .jpg, .jpeg 중 하나라도 있으면 True 를 반환하는 함수\n","'''\n","def is_image_file(filename):\n","    return any(filename.endswith(extension) for extension in [\".png\", \".jpg\", \".jpeg\"])\n","\n","'''\n","2. PIL 을 이용하여 filepath에서 이미지를 불러오고 RGB 로 convert 하여 반환하는 함수\n","'''\n","def load_img(filepath):\n","    img = Image.open(filepath).convert('RGB')\n","    return img\n","\n","'''\n","3. PIL 을 이용하여 이미지를 Bicubic 으로 scale 만큼 High Resolution 으로 만드는 함수\n","'''\n","def rescale_img(img_in, scale):\n","    size_in = img_in.size\n","    # size_in = img_in 의 (width, height) tuple\n","    new_size_in = tuple([int(x * scale) for x in size_in])\n","    # new_size_in = (width * scale, height * scale)\n","    img_in = img_in.resize(new_size_in, resample=Image.BICUBIC)\n","    return img_in\n","\n","'''\n","4. img_tar = load_img 함수를 이용하여 index 번째 image 를 RGB 로 불러온 이미지 \n","   img_in = target 으로 불러온 이미지를 Bicubic 으로 downscale 한 이미지 -> (사용할 일 없음)\n","   img_bic = rescale_img 함수로 input 을 다시 같은 비율로 upscale 한 이미지\n","\n","   training 에는 img_tar, img_bic 을 사용할 것이고, 이들 이미지 임의의 영역을\n","   upscale_factor*n x upscale_factor*n 크기로 잘라 이미지 크기를 같게 만들어 줌\n","   \n","   잘린 이미지는 같은 random point 에서 시작하여 잘리므로 이미지가 나타내는 임의의 영역이 같음\n","'''\n","def get_patch(img_in, img_tar, img_bic, patch_size, scale, ix=-1, iy=-1):\n","    (ih, iw) = img_in.size\n","    (th, tw) = (scale * ih, scale * iw)\n","\n","    patch_mult = scale #if len(scale) > 1 else 1\n","    tp = patch_mult * patch_size\n","    # tp = upscale_factor*n (n = patch_size)\n","    ip = tp // scale\n","    # ip = n (n = patch_size)\n","    \n","    if ix == -1:\n","        ix = random.randrange(0, iw - ip + 1)\n","    if iy == -1:\n","        iy = random.randrange(0, ih - ip + 1)\n","\n","    (tx, ty) = (scale * ix, scale * iy)\n","\n","    img_in = img_in.crop((iy,ix,iy + ip, ix + ip))\n","    # 원본이미지 임의의 영역을 n x n 크기로 자름\n","    img_tar = img_tar.crop((ty,tx,ty + tp, tx + tp))\n","    # downscale 한 이미지 임의의 영역을 upscale_factor*n x upscale_factor*n 크기로 자름\n","    img_bic = img_bic.crop((ty,tx,ty + tp, tx + tp))\n","    # upscale 한 이미지 임의의 영역을 upscale_factor*n x upscale_factor*n 크기로 자름            \n","    info_patch = {\n","        'ix': ix, 'iy': iy, 'ip': ip, 'tx': tx, 'ty': ty, 'tp': tp}\n","    # info_patch 에는 어떤 크기로 crop 했는지에 대한 정보가 있음\n","    return img_in, img_tar, img_bic, info_patch\n","\n","'''\n","5. 이미지데이터 증강(augmentation)\n","'''\n","def augment(img_in, img_tar, img_bic, flip_h=True, rot=True):\n","    info_aug = {'flip_h': False, 'flip_v': False, 'trans': False}\n","    \n","    if random.random() < 0.5 and flip_h:\n","        img_in = ImageOps.flip(img_in)\n","        img_tar = ImageOps.flip(img_tar)\n","        img_bic = ImageOps.flip(img_bic)\n","        info_aug['flip_h'] = True\n","    # 50%의 확률로, flip_h = True 면 img_in, img_tar, img_bic 을 모두 flip\n","\n","    if rot:\n","        if random.random() < 0.5:\n","            img_in = ImageOps.mirror(img_in)\n","            img_tar = ImageOps.mirror(img_tar)\n","            img_bic = ImageOps.mirror(img_bic)\n","            info_aug['flip_v'] = True\n","        if random.random() < 0.5:\n","            img_in = img_in.rotate(180)\n","            img_tar = img_tar.rotate(180)\n","            img_bic = img_bic.rotate(180)\n","            info_aug['trans'] = True\n","    # 50%의 확률로, rot = True 면 img_in, img_tar, img_bic 을 모두 mirror & 180도 rotate\n","    \n","    return img_in, img_tar, img_bic, info_aug\n","    # info_aug = 출력된 이미지에 어떤 preprocessing 을 했는지 알려줌\n","    \n","'''\n","6. PIL 이미지나 ndarray 이미지를 Tensor로 바꾸어주는 함수\n","   -> ToTensor 함수 사용시 이미지 pixel 값은 0~255 에서 0~1 로 바뀜\n","'''\n","def transform():\n","    return Compose([ToTensor(),])\n","\n","'''\n","7.사용자 정의 data 로드 - Training Data \n","'''        \n","class DatasetFromFolder(data.Dataset):\n","    '''\n","    def __init__(self, index) 에서는 필요한 변수를 선언 하고 'data 경로' 를 load 한다\n","    '''\n","    def __init__(self, image_dir, patch_size, upscale_factor, data_augmentation, transform=None):\n","        super(DatasetFromFolder, self).__init__()\n","        self.image_filenames = [join(image_dir, x) for x in listdir(image_dir) if is_image_file(x)]\n","        # self.image_filenames = image_dir 에 있는 모든 이미지의 경로 list\n","        self.patch_size = patch_size\n","        self.upscale_factor = upscale_factor\n","        self.transform = transform\n","        self.data_augmentation = data_augmentation\n","    '''\n","    def __getitem__(self, index) 에서는 index 번째 data를 return 하도록 코드를 짠다\n","    '''\n","    def __getitem__(self, index):\n","        target = load_img(self.image_filenames[index])\n","        # target = load_img 함수를 이용하여 index 번째 image 를 RGB 로 불러온 이미지\n","        input = target.resize((int(target.size[0]/self.upscale_factor),int(target.size[1]/self.upscale_factor)), Image.BICUBIC) \n","        # input = target 으로 불러온 이미지를 Bicubic 으로 downscale 한 이미지\n","        bicubic = rescale_img(input, self.upscale_factor)\n","        # bicubic = rescale_img 함수로 input 을 다시 같은 비율로 upscale 한 이미지\n","        \n","        input, target, bicubic, _ = get_patch(input,target,bicubic,self.patch_size, self.upscale_factor)\n","        # input, target, bicubic 이미지를 (upscale_factor*patch_size x upscale_factor*patch_size) 로 crop\n","        \n","        if self.data_augmentation:\n","            input, target, bicubic, _ = augment(input, target, bicubic)\n","        # data_augmentation = True 라면, 세 이미지를 augment 함수로 증강, img_aug 는 필요 없음\n","        \n","        if self.transform:\n","            input = self.transform(input)\n","            bicubic = self.transform(bicubic)\n","            target = self.transform(target)\n","        # self.transform = True 라면, 세 이미지를 PIL image 에서 Tensor로 바꾸어 줌\n","        return input, target, bicubic\n","    '''\n","    def __len__(self) 에서는 data의 len을 return 하도록 코드를 짠다\n","    '''\n","    def __len__(self):\n","        return len(self.image_filenames)\n","    \n","'''\n","8.사용자 정의 data 로드 - Test Data \n","   -> file 이름까지 사용자 정의 데이터화 시킴\n","   -> get_patch 함수를 사용하지 않기 때문에, SRCNN 의 입력으로 (원본 이미지 xscale) 된 이미지가 들어감\n","'''\n","class DatasetFromFolderEval(data.Dataset):\n","    def __init__(self, lr_dir, upscale_factor, transform=None):\n","        super(DatasetFromFolderEval, self).__init__()\n","        self.image_filenames = [join(lr_dir, x) for x in listdir(lr_dir) if is_image_file(x)]\n","        self.upscale_factor = upscale_factor\n","        self.transform = transform\n","\n","    def __getitem__(self, index):\n","        target = load_img(self.image_filenames[index])\n","        # target = load_img 함수를 이용하여 index 번째 image 를 RGB 로 불러온 이미지\n","        _, file = os.path.split(self.image_filenames[index])\n","        # file = 이미지 경로 list 에서 file 이름만 잘라 냄\n","\n","        input = target.resize((int(target.size[0]/self.upscale_factor),int(target.size[1]/self.upscale_factor)), Image.BICUBIC) \n","        # input = target 으로 불러온 이미지를 Bicubic 으로 downscale 한 이미지\n","        bicubic = rescale_img(input, self.upscale_factor)\n","        # bicubic = rescale_img 함수로 input 을 다시 같은 비율로 upscale 한 이미지\n","        \n","        if self.transform:\n","            input = self.transform(input)\n","            bicubic = self.transform(bicubic)\n","            target = self.transform(target)\n","         # self.transform = True 라면, 세 이미지를 PIL image 에서 Tensor로 바꾸어 줌\n","        \n","        return input, bicubic, target, file\n","        # file 이름까지 return\n","      \n","    def __len__(self):\n","        return len(self.image_filenames)\n","'''\n","9. Training Data 불러오기\n","'''\n","def get_training_set(data_dir, hr, upscale_factor, patch_size, data_augmentation):\n","    hr_dir = join(data_dir, hr)\n","    return DatasetFromFolder(hr_dir,patch_size, upscale_factor, data_augmentation,\n","                             transform=transform())\n","'''\n","10. Test Data 불러오기\n","'''\n","def get_eval_set(lr_dir, upscale_factor):\n","    return DatasetFromFolderEval(lr_dir, upscale_factor,\n","                             transform=transform())\n","\n","print('finish')\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["finish\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LCAb64GCKdZ_","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"36406199-c75f-429c-9e16-530e470dae5a"},"source":["# Data Load & Model Load & Optimizer \n","# Training\n","\n","from __future__ import print_function\n","import argparse\n","from math import log10\n","\n","import os\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.backends.cudnn as cudnn\n","from torch.autograd import Variable\n","from torch.utils.data import DataLoader\n","import pdb\n","import socket\n","import time\n","import easydict\n","\n","from torch.utils.tensorboard import SummaryWriter\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","opt = easydict.EasyDict({ \n","    \"batchSize\": 32,           # batch size - 한번에 training할 patch의 숫자\n","    \"lr\": 0.001,                # learning rate\n","    \"upscale_factor\": 2,       # Upscale 정도\n","    \"patch_size\": 64,         # 입력 이미지 크기\n","\n","    \"start_epoch\": 1,           \n","    \"nEpochs\": 100,            # epoch 횟수\n","    \"snapshots\": 10,           # weight 저장 주기\n","   \n","    \"data_dir\":\"/content/gdrive/MyDrive/졸업논문/data_800개/train\", # dataset이 저장된 위치\n","    \"hr_train_dataset\": \"DIV2K_train_HR\", # training에 사용할 dataset 종류\n","\n","    \"model_type\": \"WCNN\",         # 모델이름\n","    \"save_folder\": \"/content/gdrive/MyDrive/졸업논문/졸업논문/scale=2/insize=3_lr=0.001_patch=64/weights/\", # weight 저장 위치\n","\n","    \"pretrained_sr\": None, # pretrained model 경로\n","    \"pretrained\": False,\n","    \"data_augmentation\": False,\n","    \"gpu_mode\": True,\n","    \"threads\": 1, \n","    \"gpus\": 1 # 사용할 gpu 번호\n","    })\n","\n","'''\n","1. Training Data 로드\n","'''\n","print('===> Loading datasets')\n","train_set = get_training_set(opt.data_dir, opt.hr_train_dataset, opt.upscale_factor, opt.patch_size, opt.data_augmentation)\n","training_data_loader = DataLoader(dataset=train_set, num_workers=opt.threads, batch_size=opt.batchSize, shuffle=True)\n","\n","'''\n","2. WCNN 빌드 및 가중치 초기화 (가중치 초기화는 빌드와 동시에 수행)\n","'''\n","print('===> Building model ', opt.model_type)\n","model = WCNN()\n","print('===> Weight Initialization ')\n","\n","'''\n","3. Optimizer & Criterion 정의 \n","  -> MSE loss 사용\n","  -> Optimizer는 Adam 사용\n","'''\n","criterion = nn.MSELoss() \n","optimizer = optimizer = optim.Adam(model.parameters(), lr=opt.lr, betas=(0.9, 0.999), eps=1e-8)\n","# betas = SGD + Momentum 에서 momentum값, 0.9에서 시작하여 0.999로 증가\n","\n","'''\n","4. GPU 설정 및 parameter print\n","'''\n","gpus_list = range(opt.gpus)\n","cudnn.benchmark = True\n","print(opt)\n","\n","cuda = opt.gpu_mode\n","if cuda and not torch.cuda.is_available():\n","    raise Exception(\"No GPU found, please run without --cuda\")\n","\n","'''\n","5. GPU 사용 여부 및 pretrained model 설정\n","'''\n","if cuda:\n","    model = model.cuda(gpus_list[0])\n","    model = torch.nn.DataParallel(model, device_ids=gpus_list)\n","    criterion = criterion.cuda(gpus_list[0])\n","    \n","if opt.pretrained:\n","    model_name = os.path.join(opt.pretrained_sr)\n","    checkpoint = torch.load(model_name)\n","\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","    loss = checkpoint['loss']\n","    opt.start_epoch = checkpoint['epoch']\n","    print('Pre-trained SR model is loaded.')\n","    # pretrained model 불러오기\n","\n","'''\n","6. 한번의 epoch 에서 수행하는 과정 정의 및 Tensorboard\n","'''\n","%load_ext tensorboard\n","\n","%tensorboard tensorboard --logdir=/content/gdrive/My Drive/졸업논문/졸업논문/scale=2/logs_scale=2/ --port=6006\n","\n","writer = SummaryWriter('/content/gdrive/My Drive/졸업논문/졸업논문/scale=2/logs_scale=2/')\n","# log 를 저장할 위치 지정\n","\n","loss_list = []\n","\n","def train(epoch):\n","    epoch_loss = 0\n","    model.train()\n","    # model.train() 을 호출하여 학습 모드로 전환\n","    '''\n","    이때, 각 이미지는 'mini batch' 갯수만큼 가져온다!\n","    이때, autograd.Variable 을 사용하는 이유는 batch_data 라는 list 에 있는 input, target, blur_img 를 Tensor로 불러오기 위해\n","    '''\n","    for batch_idx, batch_data in enumerate(training_data_loader, start=1):\n","    # batch_data = (input[batch_idx], target[batch_idx], blur_img[batch_idx])\n","    # batch_idx = 세개의 mini-batch의 출력 이미지 set의 index\n","    # enumerate({list}, number) 로 사용하면 interation 이 0 이 아니라 number 부터 시작 함\n","        _, target, bicubic = Variable(batch_data[0]), Variable(batch_data[1]), Variable(batch_data[2])\n","        # autograd.Variable({tensor}) 라고 쓰면, {tensor} 를 불러옴 \n","        if cuda:\n","            # input = input.cuda(gpus_list[0])\n","            target = target.cuda(gpus_list[0])\n","            bicubic = bicubic.cuda(gpus_list[0])\n","\n","        optimizer.zero_grad()\n","        # gradient 를 0으로 초기화\n","        t0 = time.time()\n","        prediction = model(bicubic)\n","\n","        loss = criterion(prediction, target)\n","        epoch_loss += loss.data\n","        # 해당 mini-batch 에서 loss function 값\n","        loss.backward()\n","        # loss 를 가지고 gradient 계산\n","        optimizer.step()\n","        # 각 layer들의 weights 갱신\n","        t1 = time.time()\n","\n","        print(\"===> Epoch[{}]({}/{}): Loss: {:.4f} || Timer: {:.4f} sec.\".format(epoch, batch_idx, len(training_data_loader), loss.data, (t1 - t0)))\n","        # t1-t0 = 한 mini-batch 연산에 걸린 시간\n","\n","    print(\"===> Epoch {} Complete: Avg. Loss: {:.4f}\".format(epoch, epoch_loss / len(training_data_loader)))\n","    \n","    '''\n","    Model 의 Checkpoint 저장하기 for test(evaluation)\n","    '''\n","    if (epoch) % (opt.snapshots) == 0:\n","      model_out_path = opt.save_folder+\"WCNN_epoch_{}.pth\".format(epoch)\n","      torch.save({'epoch' : epoch,\n","              'model_state_dict' : model.state_dict(),\n","                'loss' : loss.data}, model_out_path)\n","      print(\"Checkpoint saved to {}\".format(model_out_path))\n","\n","    '''\n","    Tensorboard 에 매 epoch 마다 loss 저장하기\n","    '''\n","    writer.add_scalar('Epoch Loss', epoch_loss / len(training_data_loader), epoch )\n","    # 그래프의 가로축 = epoch, 세로 축 = epoch_loss / len(training_data_loader)\n","\n","    loss_list.append(epoch_loss / len(training_data_loader))\n","\n","if __name__ == '__main__':\n","    for epoch in range(opt.start_epoch, opt.nEpochs + 1):\n","        train(epoch)\n","\n","writer.close()\n","# writer 가 더이상 필요하지 않으므로 닫아준다\n","\n","print('Finished Training')\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n","===> Loading datasets\n","===> Building model  WCNN\n","===> Weight Initialization \n","{'batchSize': 32, 'lr': 0.001, 'upscale_factor': 2, 'patch_size': 64, 'start_epoch': 1, 'nEpochs': 100, 'snapshots': 10, 'data_dir': '/content/gdrive/MyDrive/졸업논문/data_800개/train', 'hr_train_dataset': 'DIV2K_train_HR', 'model_type': 'WCNN', 'save_folder': '/content/gdrive/MyDrive/졸업논문/졸업논문/scale=2/insize=3_lr=0.001_patch=64/weights/', 'pretrained_sr': None, 'pretrained': False, 'data_augmentation': False, 'gpu_mode': True, 'threads': 1, 'gpus': 1}\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/plain":["ERROR: Failed to launch TensorBoard (exited with 2).\n","Contents of stderr:\n","2021-05-20 17:49:30.762228: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","usage: tensorboard [-h] [--helpfull] {serve,dev} ...\n","tensorboard: error: invalid choice: 'tensorboard' (choose from 'serve', 'dev')"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["===> Epoch[1](1/25): Loss: 0.4875 || Timer: 7.1870 sec.\n","===> Epoch[1](2/25): Loss: 0.1721 || Timer: 6.6374 sec.\n","===> Epoch[1](3/25): Loss: 0.0928 || Timer: 6.6232 sec.\n","===> Epoch[1](4/25): Loss: 0.0571 || Timer: 6.6222 sec.\n","===> Epoch[1](5/25): Loss: 0.0384 || Timer: 6.6373 sec.\n","===> Epoch[1](6/25): Loss: 0.0447 || Timer: 6.6352 sec.\n","===> Epoch[1](7/25): Loss: 0.0627 || Timer: 6.6231 sec.\n","===> Epoch[1](8/25): Loss: 0.0339 || Timer: 6.6221 sec.\n","===> Epoch[1](9/25): Loss: 0.0377 || Timer: 6.6159 sec.\n","===> Epoch[1](10/25): Loss: 0.0314 || Timer: 6.6298 sec.\n","===> Epoch[1](11/25): Loss: 0.0287 || Timer: 6.6303 sec.\n","===> Epoch[1](12/25): Loss: 0.0207 || Timer: 6.6290 sec.\n","===> Epoch[1](13/25): Loss: 0.0200 || Timer: 6.6235 sec.\n","===> Epoch[1](14/25): Loss: 0.0241 || Timer: 6.6133 sec.\n","===> Epoch[1](15/25): Loss: 0.0283 || Timer: 6.6307 sec.\n","===> Epoch[1](16/25): Loss: 0.0201 || Timer: 6.6209 sec.\n","===> Epoch[1](17/25): Loss: 0.0203 || Timer: 6.6299 sec.\n","===> Epoch[1](18/25): Loss: 0.0185 || Timer: 6.6294 sec.\n","===> Epoch[1](19/25): Loss: 0.0191 || Timer: 6.6380 sec.\n","===> Epoch[1](20/25): Loss: 0.0148 || Timer: 6.6138 sec.\n","===> Epoch[1](21/25): Loss: 0.0162 || Timer: 6.6285 sec.\n","===> Epoch[1](22/25): Loss: 0.0167 || Timer: 6.6269 sec.\n","===> Epoch[1](23/25): Loss: 0.0167 || Timer: 6.6316 sec.\n","===> Epoch[1](24/25): Loss: 0.0156 || Timer: 6.6134 sec.\n","===> Epoch[1](25/25): Loss: 0.0152 || Timer: 6.6270 sec.\n","===> Epoch 1 Complete: Avg. Loss: 0.0541\n","===> Epoch[2](1/25): Loss: 0.0131 || Timer: 6.6199 sec.\n","===> Epoch[2](2/25): Loss: 0.0175 || Timer: 6.6087 sec.\n","===> Epoch[2](3/25): Loss: 0.0130 || Timer: 6.6170 sec.\n","===> Epoch[2](4/25): Loss: 0.0121 || Timer: 6.6097 sec.\n","===> Epoch[2](5/25): Loss: 0.0133 || Timer: 6.6163 sec.\n","===> Epoch[2](6/25): Loss: 0.0119 || Timer: 6.6091 sec.\n","===> Epoch[2](7/25): Loss: 0.0109 || Timer: 6.6153 sec.\n","===> Epoch[2](8/25): Loss: 0.0132 || Timer: 6.6090 sec.\n","===> Epoch[2](9/25): Loss: 0.0134 || Timer: 6.6151 sec.\n","===> Epoch[2](10/25): Loss: 0.0099 || Timer: 6.6084 sec.\n","===> Epoch[2](11/25): Loss: 0.0108 || Timer: 6.6155 sec.\n","===> Epoch[2](12/25): Loss: 0.0125 || Timer: 6.6096 sec.\n","===> Epoch[2](13/25): Loss: 0.0120 || Timer: 6.6163 sec.\n","===> Epoch[2](14/25): Loss: 0.0080 || Timer: 6.6097 sec.\n","===> Epoch[2](15/25): Loss: 0.0085 || Timer: 6.6165 sec.\n","===> Epoch[2](16/25): Loss: 0.0093 || Timer: 6.6094 sec.\n","===> Epoch[2](17/25): Loss: 0.0115 || Timer: 6.6149 sec.\n","===> Epoch[2](18/25): Loss: 0.0122 || Timer: 6.6092 sec.\n","===> Epoch[2](19/25): Loss: 0.0096 || Timer: 6.6165 sec.\n","===> Epoch[2](20/25): Loss: 0.0117 || Timer: 6.6098 sec.\n","===> Epoch[2](21/25): Loss: 0.0095 || Timer: 6.6161 sec.\n","===> Epoch[2](22/25): Loss: 0.0084 || Timer: 6.6095 sec.\n","===> Epoch[2](23/25): Loss: 0.0082 || Timer: 6.6157 sec.\n","===> Epoch[2](24/25): Loss: 0.0073 || Timer: 6.6096 sec.\n","===> Epoch[2](25/25): Loss: 0.0104 || Timer: 6.6164 sec.\n","===> Epoch 2 Complete: Avg. Loss: 0.0111\n","===> Epoch[3](1/25): Loss: 0.0083 || Timer: 6.6311 sec.\n","===> Epoch[3](2/25): Loss: 0.0092 || Timer: 6.6141 sec.\n","===> Epoch[3](3/25): Loss: 0.0091 || Timer: 6.6130 sec.\n","===> Epoch[3](4/25): Loss: 0.0097 || Timer: 6.6144 sec.\n","===> Epoch[3](5/25): Loss: 0.0061 || Timer: 6.6133 sec.\n","===> Epoch[3](6/25): Loss: 0.0058 || Timer: 6.6147 sec.\n","===> Epoch[3](7/25): Loss: 0.0083 || Timer: 6.6131 sec.\n","===> Epoch[3](8/25): Loss: 0.0087 || Timer: 6.6110 sec.\n","===> Epoch[3](9/25): Loss: 0.0056 || Timer: 6.6137 sec.\n","===> Epoch[3](10/25): Loss: 0.0086 || Timer: 6.6121 sec.\n","===> Epoch[3](11/25): Loss: 0.0074 || Timer: 6.6138 sec.\n","===> Epoch[3](12/25): Loss: 0.0071 || Timer: 6.6141 sec.\n","===> Epoch[3](13/25): Loss: 0.0059 || Timer: 6.6142 sec.\n","===> Epoch[3](14/25): Loss: 0.0077 || Timer: 6.6142 sec.\n","===> Epoch[3](15/25): Loss: 0.0060 || Timer: 6.6164 sec.\n","===> Epoch[3](16/25): Loss: 0.0073 || Timer: 6.6131 sec.\n","===> Epoch[3](17/25): Loss: 0.0074 || Timer: 6.6163 sec.\n","===> Epoch[3](18/25): Loss: 0.0061 || Timer: 6.6131 sec.\n","===> Epoch[3](19/25): Loss: 0.0058 || Timer: 6.6154 sec.\n","===> Epoch[3](20/25): Loss: 0.0056 || Timer: 6.6144 sec.\n","===> Epoch[3](21/25): Loss: 0.0092 || Timer: 6.6152 sec.\n","===> Epoch[3](22/25): Loss: 0.0071 || Timer: 6.6150 sec.\n","===> Epoch[3](23/25): Loss: 0.0064 || Timer: 6.6144 sec.\n","===> Epoch[3](24/25): Loss: 0.0059 || Timer: 6.6141 sec.\n","===> Epoch[3](25/25): Loss: 0.0044 || Timer: 6.6142 sec.\n","===> Epoch 3 Complete: Avg. Loss: 0.0072\n","===> Epoch[4](1/25): Loss: 0.0064 || Timer: 6.6259 sec.\n","===> Epoch[4](2/25): Loss: 0.0067 || Timer: 6.6168 sec.\n","===> Epoch[4](3/25): Loss: 0.0055 || Timer: 6.6098 sec.\n","===> Epoch[4](4/25): Loss: 0.0081 || Timer: 6.6166 sec.\n","===> Epoch[4](5/25): Loss: 0.0068 || Timer: 6.6092 sec.\n","===> Epoch[4](6/25): Loss: 0.0055 || Timer: 6.6168 sec.\n","===> Epoch[4](7/25): Loss: 0.0062 || Timer: 6.6095 sec.\n","===> Epoch[4](8/25): Loss: 0.0062 || Timer: 6.6171 sec.\n","===> Epoch[4](9/25): Loss: 0.0060 || Timer: 6.6093 sec.\n","===> Epoch[4](10/25): Loss: 0.0056 || Timer: 6.6178 sec.\n","===> Epoch[4](11/25): Loss: 0.0041 || Timer: 6.6124 sec.\n","===> Epoch[4](12/25): Loss: 0.0049 || Timer: 6.6169 sec.\n","===> Epoch[4](13/25): Loss: 0.0050 || Timer: 6.6101 sec.\n","===> Epoch[4](14/25): Loss: 0.0058 || Timer: 6.6188 sec.\n","===> Epoch[4](15/25): Loss: 0.0043 || Timer: 6.6101 sec.\n","===> Epoch[4](16/25): Loss: 0.0043 || Timer: 6.6172 sec.\n","===> Epoch[4](17/25): Loss: 0.0049 || Timer: 6.6100 sec.\n","===> Epoch[4](18/25): Loss: 0.0052 || Timer: 6.6170 sec.\n","===> Epoch[4](19/25): Loss: 0.0032 || Timer: 6.6092 sec.\n","===> Epoch[4](20/25): Loss: 0.0049 || Timer: 6.6160 sec.\n","===> Epoch[4](21/25): Loss: 0.0030 || Timer: 6.6126 sec.\n","===> Epoch[4](22/25): Loss: 0.0057 || Timer: 6.6166 sec.\n","===> Epoch[4](23/25): Loss: 0.0031 || Timer: 6.6104 sec.\n","===> Epoch[4](24/25): Loss: 0.0053 || Timer: 6.6188 sec.\n","===> Epoch[4](25/25): Loss: 0.0050 || Timer: 6.6097 sec.\n","===> Epoch 4 Complete: Avg. Loss: 0.0053\n","===> Epoch[5](1/25): Loss: 0.0063 || Timer: 6.6330 sec.\n","===> Epoch[5](2/25): Loss: 0.0073 || Timer: 6.6145 sec.\n","===> Epoch[5](3/25): Loss: 0.0035 || Timer: 6.6139 sec.\n","===> Epoch[5](4/25): Loss: 0.0051 || Timer: 6.6147 sec.\n","===> Epoch[5](5/25): Loss: 0.0043 || Timer: 6.6160 sec.\n","===> Epoch[5](6/25): Loss: 0.0039 || Timer: 6.6144 sec.\n","===> Epoch[5](7/25): Loss: 0.0046 || Timer: 6.6144 sec.\n","===> Epoch[5](8/25): Loss: 0.0058 || Timer: 6.6140 sec.\n","===> Epoch[5](9/25): Loss: 0.0043 || Timer: 6.6156 sec.\n","===> Epoch[5](10/25): Loss: 0.0057 || Timer: 6.6140 sec.\n","===> Epoch[5](11/25): Loss: 0.0051 || Timer: 6.6166 sec.\n","===> Epoch[5](12/25): Loss: 0.0052 || Timer: 6.6146 sec.\n","===> Epoch[5](13/25): Loss: 0.0049 || Timer: 6.6174 sec.\n","===> Epoch[5](14/25): Loss: 0.0058 || Timer: 6.6139 sec.\n","===> Epoch[5](15/25): Loss: 0.0035 || Timer: 6.6153 sec.\n","===> Epoch[5](16/25): Loss: 0.0037 || Timer: 6.6135 sec.\n","===> Epoch[5](17/25): Loss: 0.0047 || Timer: 6.6167 sec.\n","===> Epoch[5](18/25): Loss: 0.0035 || Timer: 6.6135 sec.\n","===> Epoch[5](19/25): Loss: 0.0043 || Timer: 6.6160 sec.\n","===> Epoch[5](20/25): Loss: 0.0037 || Timer: 6.6144 sec.\n","===> Epoch[5](21/25): Loss: 0.0046 || Timer: 6.6166 sec.\n","===> Epoch[5](22/25): Loss: 0.0028 || Timer: 6.6134 sec.\n","===> Epoch[5](23/25): Loss: 0.0038 || Timer: 6.6170 sec.\n","===> Epoch[5](24/25): Loss: 0.0037 || Timer: 6.6136 sec.\n","===> Epoch[5](25/25): Loss: 0.0046 || Timer: 6.6172 sec.\n","===> Epoch 5 Complete: Avg. Loss: 0.0046\n","===> Epoch[6](1/25): Loss: 0.0040 || Timer: 6.6408 sec.\n","===> Epoch[6](2/25): Loss: 0.0041 || Timer: 6.6080 sec.\n","===> Epoch[6](3/25): Loss: 0.0047 || Timer: 6.6198 sec.\n","===> Epoch[6](4/25): Loss: 0.0042 || Timer: 6.6094 sec.\n","===> Epoch[6](5/25): Loss: 0.0048 || Timer: 6.6191 sec.\n","===> Epoch[6](6/25): Loss: 0.0037 || Timer: 6.6092 sec.\n","===> Epoch[6](7/25): Loss: 0.0037 || Timer: 6.6164 sec.\n","===> Epoch[6](8/25): Loss: 0.0047 || Timer: 6.6085 sec.\n","===> Epoch[6](9/25): Loss: 0.0040 || Timer: 6.6191 sec.\n","===> Epoch[6](10/25): Loss: 0.0031 || Timer: 6.6098 sec.\n","===> Epoch[6](11/25): Loss: 0.0044 || Timer: 6.6202 sec.\n","===> Epoch[6](12/25): Loss: 0.0031 || Timer: 6.6093 sec.\n","===> Epoch[6](13/25): Loss: 0.0041 || Timer: 6.6184 sec.\n","===> Epoch[6](14/25): Loss: 0.0044 || Timer: 6.6082 sec.\n","===> Epoch[6](15/25): Loss: 0.0039 || Timer: 6.6165 sec.\n","===> Epoch[6](16/25): Loss: 0.0048 || Timer: 6.6128 sec.\n","===> Epoch[6](17/25): Loss: 0.0039 || Timer: 6.6163 sec.\n","===> Epoch[6](18/25): Loss: 0.0046 || Timer: 6.6124 sec.\n","===> Epoch[6](19/25): Loss: 0.0036 || Timer: 6.6153 sec.\n","===> Epoch[6](20/25): Loss: 0.0025 || Timer: 6.6095 sec.\n","===> Epoch[6](21/25): Loss: 0.0045 || Timer: 6.6169 sec.\n","===> Epoch[6](22/25): Loss: 0.0035 || Timer: 6.6107 sec.\n","===> Epoch[6](23/25): Loss: 0.0045 || Timer: 6.6168 sec.\n","===> Epoch[6](24/25): Loss: 0.0040 || Timer: 6.6126 sec.\n","===> Epoch[6](25/25): Loss: 0.0040 || Timer: 6.6170 sec.\n","===> Epoch 6 Complete: Avg. Loss: 0.0040\n","===> Epoch[7](1/25): Loss: 0.0031 || Timer: 6.6292 sec.\n","===> Epoch[7](2/25): Loss: 0.0029 || Timer: 6.6124 sec.\n","===> Epoch[7](3/25): Loss: 0.0029 || Timer: 6.6171 sec.\n","===> Epoch[7](4/25): Loss: 0.0045 || Timer: 6.6120 sec.\n","===> Epoch[7](5/25): Loss: 0.0030 || Timer: 6.6164 sec.\n","===> Epoch[7](6/25): Loss: 0.0039 || Timer: 6.6116 sec.\n","===> Epoch[7](7/25): Loss: 0.0028 || Timer: 6.6137 sec.\n","===> Epoch[7](8/25): Loss: 0.0033 || Timer: 6.6122 sec.\n","===> Epoch[7](9/25): Loss: 0.0040 || Timer: 6.6183 sec.\n","===> Epoch[7](10/25): Loss: 0.0048 || Timer: 6.6125 sec.\n","===> Epoch[7](11/25): Loss: 0.0025 || Timer: 6.6177 sec.\n","===> Epoch[7](12/25): Loss: 0.0034 || Timer: 6.6116 sec.\n","===> Epoch[7](13/25): Loss: 0.0041 || Timer: 6.6156 sec.\n","===> Epoch[7](14/25): Loss: 0.0040 || Timer: 6.6152 sec.\n","===> Epoch[7](15/25): Loss: 0.0044 || Timer: 6.6177 sec.\n","===> Epoch[7](16/25): Loss: 0.0035 || Timer: 6.6124 sec.\n","===> Epoch[7](17/25): Loss: 0.0036 || Timer: 6.6176 sec.\n","===> Epoch[7](18/25): Loss: 0.0046 || Timer: 6.6124 sec.\n","===> Epoch[7](19/25): Loss: 0.0036 || Timer: 6.6166 sec.\n","===> Epoch[7](20/25): Loss: 0.0035 || Timer: 6.6123 sec.\n","===> Epoch[7](21/25): Loss: 0.0040 || Timer: 6.6172 sec.\n","===> Epoch[7](22/25): Loss: 0.0025 || Timer: 6.6119 sec.\n","===> Epoch[7](23/25): Loss: 0.0032 || Timer: 6.6167 sec.\n","===> Epoch[7](24/25): Loss: 0.0028 || Timer: 6.6111 sec.\n","===> Epoch[7](25/25): Loss: 0.0031 || Timer: 6.6167 sec.\n","===> Epoch 7 Complete: Avg. Loss: 0.0035\n","===> Epoch[8](1/25): Loss: 0.0042 || Timer: 6.6274 sec.\n","===> Epoch[8](2/25): Loss: 0.0038 || Timer: 6.6162 sec.\n","===> Epoch[8](3/25): Loss: 0.0038 || Timer: 6.6119 sec.\n","===> Epoch[8](4/25): Loss: 0.0021 || Timer: 6.6164 sec.\n","===> Epoch[8](5/25): Loss: 0.0034 || Timer: 6.6117 sec.\n","===> Epoch[8](6/25): Loss: 0.0030 || Timer: 6.6186 sec.\n","===> Epoch[8](7/25): Loss: 0.0024 || Timer: 6.6102 sec.\n","===> Epoch[8](8/25): Loss: 0.0034 || Timer: 6.6190 sec.\n","===> Epoch[8](9/25): Loss: 0.0030 || Timer: 6.6083 sec.\n","===> Epoch[8](10/25): Loss: 0.0042 || Timer: 6.6188 sec.\n","===> Epoch[8](11/25): Loss: 0.0028 || Timer: 6.6088 sec.\n","===> Epoch[8](12/25): Loss: 0.0026 || Timer: 6.6192 sec.\n","===> Epoch[8](13/25): Loss: 0.0039 || Timer: 6.6087 sec.\n","===> Epoch[8](14/25): Loss: 0.0030 || Timer: 6.6193 sec.\n","===> Epoch[8](15/25): Loss: 0.0039 || Timer: 6.6088 sec.\n","===> Epoch[8](16/25): Loss: 0.0042 || Timer: 6.6186 sec.\n","===> Epoch[8](17/25): Loss: 0.0022 || Timer: 6.6090 sec.\n","===> Epoch[8](18/25): Loss: 0.0033 || Timer: 6.6186 sec.\n","===> Epoch[8](19/25): Loss: 0.0028 || Timer: 6.6090 sec.\n","===> Epoch[8](20/25): Loss: 0.0044 || Timer: 6.6188 sec.\n","===> Epoch[8](21/25): Loss: 0.0027 || Timer: 6.6090 sec.\n","===> Epoch[8](22/25): Loss: 0.0041 || Timer: 6.6190 sec.\n","===> Epoch[8](23/25): Loss: 0.0031 || Timer: 6.6095 sec.\n","===> Epoch[8](24/25): Loss: 0.0026 || Timer: 6.6179 sec.\n","===> Epoch[8](25/25): Loss: 0.0050 || Timer: 6.6114 sec.\n","===> Epoch 8 Complete: Avg. Loss: 0.0034\n","===> Epoch[9](1/25): Loss: 0.0033 || Timer: 6.6274 sec.\n","===> Epoch[9](2/25): Loss: 0.0030 || Timer: 6.6138 sec.\n","===> Epoch[9](3/25): Loss: 0.0029 || Timer: 6.6164 sec.\n","===> Epoch[9](4/25): Loss: 0.0034 || Timer: 6.6132 sec.\n","===> Epoch[9](5/25): Loss: 0.0032 || Timer: 6.6130 sec.\n","===> Epoch[9](6/25): Loss: 0.0020 || Timer: 6.6169 sec.\n","===> Epoch[9](7/25): Loss: 0.0032 || Timer: 6.6115 sec.\n","===> Epoch[9](8/25): Loss: 0.0030 || Timer: 6.6172 sec.\n","===> Epoch[9](9/25): Loss: 0.0041 || Timer: 6.6109 sec.\n","===> Epoch[9](10/25): Loss: 0.0028 || Timer: 6.6169 sec.\n","===> Epoch[9](11/25): Loss: 0.0019 || Timer: 6.6122 sec.\n","===> Epoch[9](12/25): Loss: 0.0035 || Timer: 6.6166 sec.\n","===> Epoch[9](13/25): Loss: 0.0029 || Timer: 6.6126 sec.\n","===> Epoch[9](14/25): Loss: 0.0024 || Timer: 6.6170 sec.\n","===> Epoch[9](15/25): Loss: 0.0040 || Timer: 6.6123 sec.\n","===> Epoch[9](16/25): Loss: 0.0015 || Timer: 6.6178 sec.\n","===> Epoch[9](17/25): Loss: 0.0031 || Timer: 6.6127 sec.\n","===> Epoch[9](18/25): Loss: 0.0021 || Timer: 6.6185 sec.\n","===> Epoch[9](19/25): Loss: 0.0049 || Timer: 6.6113 sec.\n","===> Epoch[9](20/25): Loss: 0.0022 || Timer: 6.6170 sec.\n","===> Epoch[9](21/25): Loss: 0.0024 || Timer: 6.6118 sec.\n","===> Epoch[9](22/25): Loss: 0.0037 || Timer: 6.6145 sec.\n","===> Epoch[9](23/25): Loss: 0.0031 || Timer: 6.6146 sec.\n","===> Epoch[9](24/25): Loss: 0.0029 || Timer: 6.6141 sec.\n","===> Epoch[9](25/25): Loss: 0.0023 || Timer: 6.6168 sec.\n","===> Epoch 9 Complete: Avg. Loss: 0.0030\n","===> Epoch[10](1/25): Loss: 0.0034 || Timer: 6.6366 sec.\n","===> Epoch[10](2/25): Loss: 0.0038 || Timer: 6.6086 sec.\n","===> Epoch[10](3/25): Loss: 0.0023 || Timer: 6.6187 sec.\n","===> Epoch[10](4/25): Loss: 0.0025 || Timer: 6.6089 sec.\n","===> Epoch[10](5/25): Loss: 0.0021 || Timer: 6.6177 sec.\n","===> Epoch[10](6/25): Loss: 0.0029 || Timer: 6.6126 sec.\n","===> Epoch[10](7/25): Loss: 0.0037 || Timer: 6.6160 sec.\n","===> Epoch[10](8/25): Loss: 0.0033 || Timer: 6.6120 sec.\n","===> Epoch[10](9/25): Loss: 0.0028 || Timer: 6.6158 sec.\n","===> Epoch[10](10/25): Loss: 0.0024 || Timer: 6.6117 sec.\n","===> Epoch[10](11/25): Loss: 0.0021 || Timer: 6.6173 sec.\n","===> Epoch[10](12/25): Loss: 0.0024 || Timer: 6.6125 sec.\n","===> Epoch[10](13/25): Loss: 0.0025 || Timer: 6.6156 sec.\n","===> Epoch[10](14/25): Loss: 0.0027 || Timer: 6.6118 sec.\n","===> Epoch[10](15/25): Loss: 0.0022 || Timer: 6.6157 sec.\n","===> Epoch[10](16/25): Loss: 0.0027 || Timer: 6.6120 sec.\n","===> Epoch[10](17/25): Loss: 0.0027 || Timer: 6.6169 sec.\n","===> Epoch[10](18/25): Loss: 0.0041 || Timer: 6.6073 sec.\n","===> Epoch[10](19/25): Loss: 0.0023 || Timer: 6.6193 sec.\n","===> Epoch[10](20/25): Loss: 0.0032 || Timer: 6.6089 sec.\n","===> Epoch[10](21/25): Loss: 0.0029 || Timer: 6.6163 sec.\n","===> Epoch[10](22/25): Loss: 0.0029 || Timer: 6.6113 sec.\n","===> Epoch[10](23/25): Loss: 0.0025 || Timer: 6.6180 sec.\n","===> Epoch[10](24/25): Loss: 0.0029 || Timer: 6.6084 sec.\n","===> Epoch[10](25/25): Loss: 0.0033 || Timer: 6.6166 sec.\n","===> Epoch 10 Complete: Avg. Loss: 0.0028\n","Checkpoint saved to /content/gdrive/MyDrive/졸업논문/졸업논문/scale=2/insize=3_lr=0.001_patch=64/weights/WCNN_epoch_10.pth\n","===> Epoch[11](1/25): Loss: 0.0033 || Timer: 6.6277 sec.\n","===> Epoch[11](2/25): Loss: 0.0037 || Timer: 6.6129 sec.\n","===> Epoch[11](3/25): Loss: 0.0029 || Timer: 6.6172 sec.\n","===> Epoch[11](4/25): Loss: 0.0030 || Timer: 6.6119 sec.\n","===> Epoch[11](5/25): Loss: 0.0021 || Timer: 6.6157 sec.\n","===> Epoch[11](6/25): Loss: 0.0016 || Timer: 6.6124 sec.\n","===> Epoch[11](7/25): Loss: 0.0025 || Timer: 6.6165 sec.\n","===> Epoch[11](8/25): Loss: 0.0036 || Timer: 6.6114 sec.\n","===> Epoch[11](9/25): Loss: 0.0024 || Timer: 6.6163 sec.\n","===> Epoch[11](10/25): Loss: 0.0021 || Timer: 6.6113 sec.\n","===> Epoch[11](11/25): Loss: 0.0037 || Timer: 6.6161 sec.\n","===> Epoch[11](12/25): Loss: 0.0036 || Timer: 6.6127 sec.\n","===> Epoch[11](13/25): Loss: 0.0027 || Timer: 6.6175 sec.\n","===> Epoch[11](14/25): Loss: 0.0020 || Timer: 6.6121 sec.\n","===> Epoch[11](15/25): Loss: 0.0023 || Timer: 6.6146 sec.\n","===> Epoch[11](16/25): Loss: 0.0036 || Timer: 6.6122 sec.\n","===> Epoch[11](17/25): Loss: 0.0032 || Timer: 6.6112 sec.\n","===> Epoch[11](18/25): Loss: 0.0035 || Timer: 6.6154 sec.\n","===> Epoch[11](19/25): Loss: 0.0021 || Timer: 6.6164 sec.\n","===> Epoch[11](20/25): Loss: 0.0029 || Timer: 6.6120 sec.\n","===> Epoch[11](21/25): Loss: 0.0024 || Timer: 6.6161 sec.\n","===> Epoch[11](22/25): Loss: 0.0020 || Timer: 6.6122 sec.\n","===> Epoch[11](23/25): Loss: 0.0034 || Timer: 6.6132 sec.\n","===> Epoch[11](24/25): Loss: 0.0024 || Timer: 6.6165 sec.\n","===> Epoch[11](25/25): Loss: 0.0028 || Timer: 6.6154 sec.\n","===> Epoch 11 Complete: Avg. Loss: 0.0028\n","===> Epoch[12](1/25): Loss: 0.0024 || Timer: 6.6307 sec.\n","===> Epoch[12](2/25): Loss: 0.0033 || Timer: 6.6157 sec.\n","===> Epoch[12](3/25): Loss: 0.0026 || Timer: 6.6113 sec.\n","===> Epoch[12](4/25): Loss: 0.0032 || Timer: 6.6156 sec.\n","===> Epoch[12](5/25): Loss: 0.0030 || Timer: 6.6125 sec.\n","===> Epoch[12](6/25): Loss: 0.0035 || Timer: 6.6152 sec.\n","===> Epoch[12](7/25): Loss: 0.0020 || Timer: 6.6118 sec.\n","===> Epoch[12](8/25): Loss: 0.0024 || Timer: 6.6154 sec.\n","===> Epoch[12](9/25): Loss: 0.0019 || Timer: 6.6112 sec.\n","===> Epoch[12](10/25): Loss: 0.0028 || Timer: 6.6148 sec.\n","===> Epoch[12](11/25): Loss: 0.0036 || Timer: 6.6110 sec.\n","===> Epoch[12](12/25): Loss: 0.0024 || Timer: 6.6164 sec.\n","===> Epoch[12](13/25): Loss: 0.0028 || Timer: 6.6122 sec.\n","===> Epoch[12](14/25): Loss: 0.0023 || Timer: 6.6162 sec.\n","===> Epoch[12](15/25): Loss: 0.0020 || Timer: 6.6119 sec.\n","===> Epoch[12](16/25): Loss: 0.0026 || Timer: 6.6156 sec.\n","===> Epoch[12](17/25): Loss: 0.0028 || Timer: 6.6097 sec.\n","===> Epoch[12](18/25): Loss: 0.0030 || Timer: 6.6193 sec.\n","===> Epoch[12](19/25): Loss: 0.0036 || Timer: 6.6081 sec.\n","===> Epoch[12](20/25): Loss: 0.0027 || Timer: 6.6194 sec.\n","===> Epoch[12](21/25): Loss: 0.0027 || Timer: 6.6090 sec.\n","===> Epoch[12](22/25): Loss: 0.0027 || Timer: 6.6182 sec.\n","===> Epoch[12](23/25): Loss: 0.0019 || Timer: 6.6090 sec.\n","===> Epoch[12](24/25): Loss: 0.0027 || Timer: 6.6193 sec.\n","===> Epoch[12](25/25): Loss: 0.0026 || Timer: 6.6086 sec.\n","===> Epoch 12 Complete: Avg. Loss: 0.0027\n","===> Epoch[13](1/25): Loss: 0.0023 || Timer: 6.6382 sec.\n","===> Epoch[13](2/25): Loss: 0.0026 || Timer: 6.6126 sec.\n","===> Epoch[13](3/25): Loss: 0.0024 || Timer: 6.6150 sec.\n","===> Epoch[13](4/25): Loss: 0.0021 || Timer: 6.6136 sec.\n","===> Epoch[13](5/25): Loss: 0.0034 || Timer: 6.6153 sec.\n","===> Epoch[13](6/25): Loss: 0.0025 || Timer: 6.6129 sec.\n","===> Epoch[13](7/25): Loss: 0.0022 || Timer: 6.6137 sec.\n","===> Epoch[13](8/25): Loss: 0.0021 || Timer: 6.6169 sec.\n","===> Epoch[13](9/25): Loss: 0.0031 || Timer: 6.6125 sec.\n","===> Epoch[13](10/25): Loss: 0.0028 || Timer: 6.6159 sec.\n","===> Epoch[13](11/25): Loss: 0.0025 || Timer: 6.6117 sec.\n","===> Epoch[13](12/25): Loss: 0.0030 || Timer: 6.6162 sec.\n","===> Epoch[13](13/25): Loss: 0.0031 || Timer: 6.6118 sec.\n","===> Epoch[13](14/25): Loss: 0.0028 || Timer: 6.6166 sec.\n","===> Epoch[13](15/25): Loss: 0.0027 || Timer: 6.6128 sec.\n","===> Epoch[13](16/25): Loss: 0.0026 || Timer: 6.6178 sec.\n","===> Epoch[13](17/25): Loss: 0.0020 || Timer: 6.6118 sec.\n","===> Epoch[13](18/25): Loss: 0.0030 || Timer: 6.6184 sec.\n","===> Epoch[13](19/25): Loss: 0.0026 || Timer: 6.6136 sec.\n","===> Epoch[13](20/25): Loss: 0.0013 || Timer: 6.6161 sec.\n","===> Epoch[13](21/25): Loss: 0.0013 || Timer: 6.6122 sec.\n","===> Epoch[13](22/25): Loss: 0.0036 || Timer: 6.6186 sec.\n","===> Epoch[13](23/25): Loss: 0.0026 || Timer: 6.6148 sec.\n","===> Epoch[13](24/25): Loss: 0.0020 || Timer: 6.6192 sec.\n","===> Epoch[13](25/25): Loss: 0.0036 || Timer: 6.6166 sec.\n","===> Epoch 13 Complete: Avg. Loss: 0.0026\n","===> Epoch[14](1/25): Loss: 0.0025 || Timer: 6.6430 sec.\n","===> Epoch[14](2/25): Loss: 0.0039 || Timer: 6.6087 sec.\n","===> Epoch[14](3/25): Loss: 0.0026 || Timer: 6.6186 sec.\n","===> Epoch[14](4/25): Loss: 0.0025 || Timer: 6.6100 sec.\n","===> Epoch[14](5/25): Loss: 0.0024 || Timer: 6.6202 sec.\n","===> Epoch[14](6/25): Loss: 0.0034 || Timer: 6.6084 sec.\n","===> Epoch[14](7/25): Loss: 0.0027 || Timer: 6.6195 sec.\n","===> Epoch[14](8/25): Loss: 0.0019 || Timer: 6.6088 sec.\n","===> Epoch[14](9/25): Loss: 0.0034 || Timer: 6.6153 sec.\n","===> Epoch[14](10/25): Loss: 0.0026 || Timer: 6.6094 sec.\n","===> Epoch[14](11/25): Loss: 0.0026 || Timer: 6.6169 sec.\n","===> Epoch[14](12/25): Loss: 0.0023 || Timer: 6.6127 sec.\n","===> Epoch[14](13/25): Loss: 0.0022 || Timer: 6.6152 sec.\n","===> Epoch[14](14/25): Loss: 0.0025 || Timer: 6.6081 sec.\n","===> Epoch[14](15/25): Loss: 0.0027 || Timer: 6.6164 sec.\n","===> Epoch[14](16/25): Loss: 0.0019 || Timer: 6.6100 sec.\n","===> Epoch[14](17/25): Loss: 0.0023 || Timer: 6.6214 sec.\n","===> Epoch[14](18/25): Loss: 0.0023 || Timer: 6.6091 sec.\n","===> Epoch[14](19/25): Loss: 0.0023 || Timer: 6.6194 sec.\n","===> Epoch[14](20/25): Loss: 0.0021 || Timer: 6.6086 sec.\n","===> Epoch[14](21/25): Loss: 0.0031 || Timer: 6.6157 sec.\n","===> Epoch[14](22/25): Loss: 0.0036 || Timer: 6.6123 sec.\n","===> Epoch[14](23/25): Loss: 0.0022 || Timer: 6.6172 sec.\n","===> Epoch[14](24/25): Loss: 0.0020 || Timer: 6.6106 sec.\n","===> Epoch[14](25/25): Loss: 0.0019 || Timer: 6.6166 sec.\n","===> Epoch 14 Complete: Avg. Loss: 0.0026\n","===> Epoch[15](1/25): Loss: 0.0019 || Timer: 6.6329 sec.\n","===> Epoch[15](2/25): Loss: 0.0023 || Timer: 6.6129 sec.\n","===> Epoch[15](3/25): Loss: 0.0017 || Timer: 6.6137 sec.\n","===> Epoch[15](4/25): Loss: 0.0020 || Timer: 6.6153 sec.\n","===> Epoch[15](5/25): Loss: 0.0035 || Timer: 6.6131 sec.\n","===> Epoch[15](6/25): Loss: 0.0031 || Timer: 6.6157 sec.\n","===> Epoch[15](7/25): Loss: 0.0018 || Timer: 6.6136 sec.\n","===> Epoch[15](8/25): Loss: 0.0028 || Timer: 6.6163 sec.\n","===> Epoch[15](9/25): Loss: 0.0023 || Timer: 6.6140 sec.\n","===> Epoch[15](10/25): Loss: 0.0018 || Timer: 6.6163 sec.\n","===> Epoch[15](11/25): Loss: 0.0030 || Timer: 6.6136 sec.\n","===> Epoch[15](12/25): Loss: 0.0019 || Timer: 6.6125 sec.\n","===> Epoch[15](13/25): Loss: 0.0028 || Timer: 6.6131 sec.\n","===> Epoch[15](14/25): Loss: 0.0024 || Timer: 6.6162 sec.\n","===> Epoch[15](15/25): Loss: 0.0015 || Timer: 6.6134 sec.\n","===> Epoch[15](16/25): Loss: 0.0022 || Timer: 6.6163 sec.\n","===> Epoch[15](17/25): Loss: 0.0031 || Timer: 6.6130 sec.\n","===> Epoch[15](18/25): Loss: 0.0027 || Timer: 6.6120 sec.\n","===> Epoch[15](19/25): Loss: 0.0020 || Timer: 6.6170 sec.\n","===> Epoch[15](20/25): Loss: 0.0023 || Timer: 6.6119 sec.\n","===> Epoch[15](21/25): Loss: 0.0023 || Timer: 6.6170 sec.\n","===> Epoch[15](22/25): Loss: 0.0029 || Timer: 6.6137 sec.\n","===> Epoch[15](23/25): Loss: 0.0018 || Timer: 6.6148 sec.\n","===> Epoch[15](24/25): Loss: 0.0025 || Timer: 6.6162 sec.\n","===> Epoch[15](25/25): Loss: 0.0026 || Timer: 6.6135 sec.\n","===> Epoch 15 Complete: Avg. Loss: 0.0024\n","===> Epoch[16](1/25): Loss: 0.0028 || Timer: 6.6349 sec.\n","===> Epoch[16](2/25): Loss: 0.0020 || Timer: 6.6162 sec.\n","===> Epoch[16](3/25): Loss: 0.0026 || Timer: 6.6117 sec.\n","===> Epoch[16](4/25): Loss: 0.0022 || Timer: 6.6168 sec.\n","===> Epoch[16](5/25): Loss: 0.0020 || Timer: 6.6102 sec.\n","===> Epoch[16](6/25): Loss: 0.0022 || Timer: 6.6155 sec.\n","===> Epoch[16](7/25): Loss: 0.0017 || Timer: 6.6105 sec.\n","===> Epoch[16](8/25): Loss: 0.0024 || Timer: 6.6165 sec.\n","===> Epoch[16](9/25): Loss: 0.0020 || Timer: 6.6115 sec.\n","===> Epoch[16](10/25): Loss: 0.0024 || Timer: 6.6166 sec.\n","===> Epoch[16](11/25): Loss: 0.0017 || Timer: 6.6091 sec.\n","===> Epoch[16](12/25): Loss: 0.0030 || Timer: 6.6188 sec.\n","===> Epoch[16](13/25): Loss: 0.0018 || Timer: 6.6086 sec.\n","===> Epoch[16](14/25): Loss: 0.0015 || Timer: 6.6157 sec.\n","===> Epoch[16](15/25): Loss: 0.0023 || Timer: 6.6122 sec.\n","===> Epoch[16](16/25): Loss: 0.0024 || Timer: 6.6165 sec.\n","===> Epoch[16](17/25): Loss: 0.0031 || Timer: 6.6087 sec.\n","===> Epoch[16](18/25): Loss: 0.0028 || Timer: 6.6158 sec.\n","===> Epoch[16](19/25): Loss: 0.0029 || Timer: 6.6115 sec.\n","===> Epoch[16](20/25): Loss: 0.0022 || Timer: 6.6170 sec.\n","===> Epoch[16](21/25): Loss: 0.0026 || Timer: 6.6121 sec.\n","===> Epoch[16](22/25): Loss: 0.0028 || Timer: 6.6144 sec.\n","===> Epoch[16](23/25): Loss: 0.0023 || Timer: 6.6125 sec.\n","===> Epoch[16](24/25): Loss: 0.0027 || Timer: 6.6162 sec.\n","===> Epoch[16](25/25): Loss: 0.0019 || Timer: 6.6119 sec.\n","===> Epoch 16 Complete: Avg. Loss: 0.0023\n","===> Epoch[17](1/25): Loss: 0.0027 || Timer: 6.6396 sec.\n","===> Epoch[17](2/25): Loss: 0.0018 || Timer: 6.6132 sec.\n","===> Epoch[17](3/25): Loss: 0.0021 || Timer: 6.6155 sec.\n","===> Epoch[17](4/25): Loss: 0.0016 || Timer: 6.6138 sec.\n","===> Epoch[17](5/25): Loss: 0.0021 || Timer: 6.6163 sec.\n","===> Epoch[17](6/25): Loss: 0.0029 || Timer: 6.6174 sec.\n","===> Epoch[17](7/25): Loss: 0.0023 || Timer: 6.6119 sec.\n","===> Epoch[17](8/25): Loss: 0.0025 || Timer: 6.6165 sec.\n","===> Epoch[17](9/25): Loss: 0.0025 || Timer: 6.6139 sec.\n","===> Epoch[17](10/25): Loss: 0.0012 || Timer: 6.6140 sec.\n","===> Epoch[17](11/25): Loss: 0.0017 || Timer: 6.6165 sec.\n","===> Epoch[17](12/25): Loss: 0.0029 || Timer: 6.6146 sec.\n","===> Epoch[17](13/25): Loss: 0.0020 || Timer: 6.6112 sec.\n","===> Epoch[17](14/25): Loss: 0.0019 || Timer: 6.6153 sec.\n","===> Epoch[17](15/25): Loss: 0.0022 || Timer: 6.6159 sec.\n","===> Epoch[17](16/25): Loss: 0.0020 || Timer: 6.6175 sec.\n","===> Epoch[17](17/25): Loss: 0.0032 || Timer: 6.6119 sec.\n","===> Epoch[17](18/25): Loss: 0.0023 || Timer: 6.6168 sec.\n","===> Epoch[17](19/25): Loss: 0.0026 || Timer: 6.6150 sec.\n","===> Epoch[17](20/25): Loss: 0.0024 || Timer: 6.6128 sec.\n","===> Epoch[17](21/25): Loss: 0.0026 || Timer: 6.6162 sec.\n","===> Epoch[17](22/25): Loss: 0.0025 || Timer: 6.6133 sec.\n","===> Epoch[17](23/25): Loss: 0.0014 || Timer: 6.6175 sec.\n","===> Epoch[17](24/25): Loss: 0.0023 || Timer: 6.6156 sec.\n","===> Epoch[17](25/25): Loss: 0.0038 || Timer: 6.6159 sec.\n","===> Epoch 17 Complete: Avg. Loss: 0.0023\n","===> Epoch[18](1/25): Loss: 0.0024 || Timer: 6.6376 sec.\n","===> Epoch[18](2/25): Loss: 0.0023 || Timer: 6.6081 sec.\n","===> Epoch[18](3/25): Loss: 0.0020 || Timer: 6.6187 sec.\n","===> Epoch[18](4/25): Loss: 0.0025 || Timer: 6.6089 sec.\n","===> Epoch[18](5/25): Loss: 0.0017 || Timer: 6.6189 sec.\n","===> Epoch[18](6/25): Loss: 0.0019 || Timer: 6.6095 sec.\n","===> Epoch[18](7/25): Loss: 0.0020 || Timer: 6.6155 sec.\n","===> Epoch[18](8/25): Loss: 0.0025 || Timer: 6.6072 sec.\n","===> Epoch[18](9/25): Loss: 0.0023 || Timer: 6.6169 sec.\n","===> Epoch[18](10/25): Loss: 0.0023 || Timer: 6.6112 sec.\n","===> Epoch[18](11/25): Loss: 0.0029 || Timer: 6.6162 sec.\n","===> Epoch[18](12/25): Loss: 0.0020 || Timer: 6.6118 sec.\n","===> Epoch[18](13/25): Loss: 0.0026 || Timer: 6.6160 sec.\n","===> Epoch[18](14/25): Loss: 0.0020 || Timer: 6.6128 sec.\n","===> Epoch[18](15/25): Loss: 0.0020 || Timer: 6.6162 sec.\n","===> Epoch[18](16/25): Loss: 0.0031 || Timer: 6.6125 sec.\n","===> Epoch[18](17/25): Loss: 0.0019 || Timer: 6.6169 sec.\n","===> Epoch[18](18/25): Loss: 0.0020 || Timer: 6.6118 sec.\n","===> Epoch[18](19/25): Loss: 0.0026 || Timer: 6.6165 sec.\n","===> Epoch[18](20/25): Loss: 0.0018 || Timer: 6.6128 sec.\n","===> Epoch[18](21/25): Loss: 0.0010 || Timer: 6.6160 sec.\n","===> Epoch[18](22/25): Loss: 0.0016 || Timer: 6.6095 sec.\n","===> Epoch[18](23/25): Loss: 0.0020 || Timer: 6.6172 sec.\n","===> Epoch[18](24/25): Loss: 0.0029 || Timer: 6.6135 sec.\n","===> Epoch[18](25/25): Loss: 0.0033 || Timer: 6.6165 sec.\n","===> Epoch 18 Complete: Avg. Loss: 0.0022\n","===> Epoch[19](1/25): Loss: 0.0020 || Timer: 6.6409 sec.\n","===> Epoch[19](2/25): Loss: 0.0020 || Timer: 6.6149 sec.\n","===> Epoch[19](3/25): Loss: 0.0021 || Timer: 6.6142 sec.\n","===> Epoch[19](4/25): Loss: 0.0014 || Timer: 6.6161 sec.\n","===> Epoch[19](5/25): Loss: 0.0028 || Timer: 6.6136 sec.\n","===> Epoch[19](6/25): Loss: 0.0016 || Timer: 6.6122 sec.\n","===> Epoch[19](7/25): Loss: 0.0018 || Timer: 6.6176 sec.\n","===> Epoch[19](8/25): Loss: 0.0018 || Timer: 6.6116 sec.\n","===> Epoch[19](9/25): Loss: 0.0014 || Timer: 6.6170 sec.\n","===> Epoch[19](10/25): Loss: 0.0018 || Timer: 6.6115 sec.\n","===> Epoch[19](11/25): Loss: 0.0015 || Timer: 6.6165 sec.\n","===> Epoch[19](12/25): Loss: 0.0018 || Timer: 6.6120 sec.\n","===> Epoch[19](13/25): Loss: 0.0018 || Timer: 6.6173 sec.\n","===> Epoch[19](14/25): Loss: 0.0020 || Timer: 6.6126 sec.\n","===> Epoch[19](15/25): Loss: 0.0022 || Timer: 6.6174 sec.\n","===> Epoch[19](16/25): Loss: 0.0017 || Timer: 6.6116 sec.\n","===> Epoch[19](17/25): Loss: 0.0016 || Timer: 6.6190 sec.\n","===> Epoch[19](18/25): Loss: 0.0016 || Timer: 6.6116 sec.\n","===> Epoch[19](19/25): Loss: 0.0008 || Timer: 6.6181 sec.\n","===> Epoch[19](20/25): Loss: 0.0014 || Timer: 6.6164 sec.\n","===> Epoch[19](21/25): Loss: 0.0029 || Timer: 6.6158 sec.\n","===> Epoch[19](22/25): Loss: 0.0033 || Timer: 6.6126 sec.\n","===> Epoch[19](23/25): Loss: 0.0024 || Timer: 6.6171 sec.\n","===> Epoch[19](24/25): Loss: 0.0013 || Timer: 6.6127 sec.\n","===> Epoch[19](25/25): Loss: 0.0019 || Timer: 6.6171 sec.\n","===> Epoch 19 Complete: Avg. Loss: 0.0019\n","===> Epoch[20](1/25): Loss: 0.0014 || Timer: 6.6220 sec.\n","===> Epoch[20](2/25): Loss: 0.0022 || Timer: 6.6160 sec.\n","===> Epoch[20](3/25): Loss: 0.0028 || Timer: 6.6121 sec.\n","===> Epoch[20](4/25): Loss: 0.0016 || Timer: 6.6158 sec.\n","===> Epoch[20](5/25): Loss: 0.0023 || Timer: 6.6126 sec.\n","===> Epoch[20](6/25): Loss: 0.0015 || Timer: 6.6172 sec.\n","===> Epoch[20](7/25): Loss: 0.0024 || Timer: 6.6087 sec.\n","===> Epoch[20](8/25): Loss: 0.0019 || Timer: 6.6171 sec.\n","===> Epoch[20](9/25): Loss: 0.0016 || Timer: 6.6100 sec.\n","===> Epoch[20](10/25): Loss: 0.0027 || Timer: 6.6158 sec.\n","===> Epoch[20](11/25): Loss: 0.0015 || Timer: 6.6122 sec.\n","===> Epoch[20](12/25): Loss: 0.0015 || Timer: 6.6165 sec.\n","===> Epoch[20](13/25): Loss: 0.0023 || Timer: 6.6111 sec.\n","===> Epoch[20](14/25): Loss: 0.0025 || Timer: 6.6189 sec.\n","===> Epoch[20](15/25): Loss: 0.0025 || Timer: 6.6087 sec.\n","===> Epoch[20](16/25): Loss: 0.0019 || Timer: 6.6182 sec.\n","===> Epoch[20](17/25): Loss: 0.0015 || Timer: 6.6094 sec.\n","===> Epoch[20](18/25): Loss: 0.0026 || Timer: 6.6197 sec.\n","===> Epoch[20](19/25): Loss: 0.0024 || Timer: 6.6095 sec.\n","===> Epoch[20](20/25): Loss: 0.0021 || Timer: 6.6192 sec.\n","===> Epoch[20](21/25): Loss: 0.0020 || Timer: 6.6089 sec.\n","===> Epoch[20](22/25): Loss: 0.0021 || Timer: 6.6186 sec.\n","===> Epoch[20](23/25): Loss: 0.0017 || Timer: 6.6098 sec.\n","===> Epoch[20](24/25): Loss: 0.0019 || Timer: 6.6187 sec.\n","===> Epoch[20](25/25): Loss: 0.0025 || Timer: 6.6078 sec.\n","===> Epoch 20 Complete: Avg. Loss: 0.0021\n","Checkpoint saved to /content/gdrive/MyDrive/졸업논문/졸업논문/scale=2/insize=3_lr=0.001_patch=64/weights/WCNN_epoch_20.pth\n","===> Epoch[21](1/25): Loss: 0.0026 || Timer: 6.6286 sec.\n","===> Epoch[21](2/25): Loss: 0.0023 || Timer: 6.6140 sec.\n","===> Epoch[21](3/25): Loss: 0.0020 || Timer: 6.6154 sec.\n","===> Epoch[21](4/25): Loss: 0.0013 || Timer: 6.6131 sec.\n","===> Epoch[21](5/25): Loss: 0.0022 || Timer: 6.6157 sec.\n","===> Epoch[21](6/25): Loss: 0.0017 || Timer: 6.6129 sec.\n","===> Epoch[21](7/25): Loss: 0.0023 || Timer: 6.6166 sec.\n","===> Epoch[21](8/25): Loss: 0.0015 || Timer: 6.6144 sec.\n","===> Epoch[21](9/25): Loss: 0.0023 || Timer: 6.6161 sec.\n","===> Epoch[21](10/25): Loss: 0.0015 || Timer: 6.6131 sec.\n","===> Epoch[21](11/25): Loss: 0.0027 || Timer: 6.6167 sec.\n","===> Epoch[21](12/25): Loss: 0.0014 || Timer: 6.6129 sec.\n","===> Epoch[21](13/25): Loss: 0.0017 || Timer: 6.6146 sec.\n","===> Epoch[21](14/25): Loss: 0.0017 || Timer: 6.6128 sec.\n","===> Epoch[21](15/25): Loss: 0.0024 || Timer: 6.6158 sec.\n","===> Epoch[21](16/25): Loss: 0.0024 || Timer: 6.6135 sec.\n","===> Epoch[21](17/25): Loss: 0.0024 || Timer: 6.6140 sec.\n","===> Epoch[21](18/25): Loss: 0.0021 || Timer: 6.6133 sec.\n","===> Epoch[21](19/25): Loss: 0.0017 || Timer: 6.6166 sec.\n","===> Epoch[21](20/25): Loss: 0.0033 || Timer: 6.6132 sec.\n","===> Epoch[21](21/25): Loss: 0.0024 || Timer: 6.6172 sec.\n","===> Epoch[21](22/25): Loss: 0.0018 || Timer: 6.6142 sec.\n","===> Epoch[21](23/25): Loss: 0.0032 || Timer: 6.6124 sec.\n","===> Epoch[21](24/25): Loss: 0.0014 || Timer: 6.6171 sec.\n","===> Epoch[21](25/25): Loss: 0.0020 || Timer: 6.6145 sec.\n","===> Epoch 21 Complete: Avg. Loss: 0.0021\n","===> Epoch[22](1/25): Loss: 0.0018 || Timer: 6.6331 sec.\n","===> Epoch[22](2/25): Loss: 0.0024 || Timer: 6.6081 sec.\n","===> Epoch[22](3/25): Loss: 0.0027 || Timer: 6.6192 sec.\n","===> Epoch[22](4/25): Loss: 0.0016 || Timer: 6.6088 sec.\n","===> Epoch[22](5/25): Loss: 0.0029 || Timer: 6.6182 sec.\n","===> Epoch[22](6/25): Loss: 0.0027 || Timer: 6.6088 sec.\n","===> Epoch[22](7/25): Loss: 0.0021 || Timer: 6.6189 sec.\n","===> Epoch[22](8/25): Loss: 0.0022 || Timer: 6.6093 sec.\n","===> Epoch[22](9/25): Loss: 0.0023 || Timer: 6.6190 sec.\n","===> Epoch[22](10/25): Loss: 0.0014 || Timer: 6.6086 sec.\n","===> Epoch[22](11/25): Loss: 0.0019 || Timer: 6.6197 sec.\n","===> Epoch[22](12/25): Loss: 0.0017 || Timer: 6.6106 sec.\n","===> Epoch[22](13/25): Loss: 0.0014 || Timer: 6.6150 sec.\n","===> Epoch[22](14/25): Loss: 0.0024 || Timer: 6.6090 sec.\n","===> Epoch[22](15/25): Loss: 0.0014 || Timer: 6.6200 sec.\n","===> Epoch[22](16/25): Loss: 0.0023 || Timer: 6.6088 sec.\n","===> Epoch[22](17/25): Loss: 0.0018 || Timer: 6.6191 sec.\n","===> Epoch[22](18/25): Loss: 0.0025 || Timer: 6.6082 sec.\n","===> Epoch[22](19/25): Loss: 0.0016 || Timer: 6.6195 sec.\n","===> Epoch[22](20/25): Loss: 0.0021 || Timer: 6.6090 sec.\n","===> Epoch[22](21/25): Loss: 0.0018 || Timer: 6.6188 sec.\n","===> Epoch[22](22/25): Loss: 0.0010 || Timer: 6.6089 sec.\n","===> Epoch[22](23/25): Loss: 0.0019 || Timer: 6.6176 sec.\n","===> Epoch[22](24/25): Loss: 0.0025 || Timer: 6.6115 sec.\n","===> Epoch[22](25/25): Loss: 0.0017 || Timer: 6.6163 sec.\n","===> Epoch 22 Complete: Avg. Loss: 0.0020\n","===> Epoch[23](1/25): Loss: 0.0017 || Timer: 6.6284 sec.\n","===> Epoch[23](2/25): Loss: 0.0019 || Timer: 6.6126 sec.\n","===> Epoch[23](3/25): Loss: 0.0019 || Timer: 6.6169 sec.\n","===> Epoch[23](4/25): Loss: 0.0016 || Timer: 6.6131 sec.\n","===> Epoch[23](5/25): Loss: 0.0023 || Timer: 6.6167 sec.\n","===> Epoch[23](6/25): Loss: 0.0018 || Timer: 6.6128 sec.\n","===> Epoch[23](7/25): Loss: 0.0021 || Timer: 6.6167 sec.\n","===> Epoch[23](8/25): Loss: 0.0030 || Timer: 6.6117 sec.\n","===> Epoch[23](9/25): Loss: 0.0024 || Timer: 6.6175 sec.\n","===> Epoch[23](10/25): Loss: 0.0013 || Timer: 6.6127 sec.\n","===> Epoch[23](11/25): Loss: 0.0014 || Timer: 6.6163 sec.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IJZEGSHLlw9i","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620788082310,"user_tz":-540,"elapsed":15485,"user":{"displayName":"김정기","photoUrl":"","userId":"02654207523640478753"}},"outputId":"f246c0cf-7906-40d8-a84b-eac29f23c13e"},"source":["# Test\n","\n","from __future__ import print_function\n","import argparse\n","\n","import os\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.autograd import Variable\n","import torch.backends.cudnn as cudnn\n","from torch.utils.data import DataLoader\n","from functools import reduce\n","from math import log10\n","\n","# from scipy.misc import imsave\n","import scipy.io as sio\n","import time\n","import cv2\n","import easydict\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","\n","opt = easydict.EasyDict({ \n","    \"testBatchSize\": 1,     # 이미지를 1개씩불러옴 \n","    \"upscale_factor\": 2,    # Upscale 정도\n","    \"input_channel\": 3,     # WCNN model 입력의 Channel (color = 3, gray = 1)\n","\n","    \"model_type\": \"WCNN\",         # 모델이름\n","    \n","    \"input_dir\":\"/content/gdrive/My Drive/졸업논문/data_800개/test\",  # test dataset 불러올위치\n","    \"test_dataset\": \"low_color_test\",                             # test에 사용할 dataset 종류\n","    \"output\": \"/content/gdrive/My Drive/졸업논문/졸업논문/scale=2/insize=3_lr=0.001_patch=64/results/\", # 결과영상 저장위치\n","    \"model_type\": \"WCNN\",\n","    \"model\": \"/content/gdrive/My Drive/졸업논문/졸업논문/scale=2/insize=3_lr=0.001_patch=64/weights/WCNN_epoch_100.pth\",\n","    # test에 사용할 weight 불러올 파일 경로\n","    \n","    \"pretrained\": True,\n","    \"data_augmentation\": False,\n","    \"gpu_mode\": True,\n","    \"threads\": 0, \n","    \"gpus\": 1 # 사용할 gpu 번호\n","    })\n","\n","'''\n","1. GPU 설정 및 parameter print\n","'''\n","gpus_list = range(opt.gpus)\n","cudnn.benchmark = True\n","print(opt)\n","\n","cuda = opt.gpu_mode\n","if cuda and not torch.cuda.is_available():\n","    raise Exception(\"No GPU found, please run without --cuda\")\n","\n","'''\n","2. Test Data 로드\n","'''\n","print('===> Loading datasets')\n","test_set = get_eval_set(os.path.join(opt.input_dir,opt.test_dataset), opt.upscale_factor)\n","testing_data_loader = DataLoader(dataset=test_set, num_workers=opt.threads, batch_size=opt.testBatchSize, shuffle=False)\n","\n","'''\n","3. Criterion 정의 \n","  -> MSE loss 사용\n","'''\n","criterion = nn.MSELoss() \n","\n","'''\n","4. NN 정의\n","'''\n","model = WCNN()\n","\n","'''\n","5. pretrained model 및 GPU 사용 여부 설정\n","'''\n","if cuda:\n","    model = model.cuda(gpus_list[0])\n","    model = torch.nn.DataParallel(model, device_ids=gpus_list)\n","    criterion = criterion.cuda(gpus_list[0])\n","if opt.pretrained:\n","    model_name = os.path.join(opt.model)\n","    checkpoint = torch.load(model_name)\n","\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","    loss = checkpoint['loss']\n","    epoch = checkpoint['epoch']\n","    print('Pre-trained SR model is loaded.')\n","    # pretrained model 불러오기\n","    \n","'''\n","6. 이미지 저장 함수 -> 원본 이미지의 크기 그대로 저장 됨\n","'''\n","def save_img(img, img_name):\n","    save_img = img.squeeze().clamp(0, 1).numpy().transpose(1,2,0)\n","    # save img\n","    save_dir=os.path.join(opt.output,opt.test_dataset)\n","    if not os.path.exists(save_dir):\n","        os.makedirs(save_dir)\n","        \n","    save_fn = save_dir +'/'+ img_name\n","    cv2.imwrite(save_fn, cv2.cvtColor(save_img*255, cv2.COLOR_BGR2RGB),  [cv2.IMWRITE_PNG_COMPRESSION, 0])\n","    \n","'''\n","7. 한번의 epoch 에서 수행하는 과정 정의\n","'''\n","def eval():\n","    avg_psnr = 0\n","    psnr_sq = 0\n","    model.eval()\n","    count_image = 0\n","    # model.eval() 을 호출하여 평가(test) 모드로 변환 \n","    \n","    for batch_data in testing_data_loader:\n","        with torch.no_grad():\n","            input, bicubic, target, file_name = Variable(batch_data[0]), Variable(batch_data[1]), Variable(batch_data[2]), batch_data[3] \n","                                                                \n","        if cuda:\n","            input = input.cuda(gpus_list[0])\n","            bicubic = bicubic.cuda(gpus_list[0])\n","            target = target.cuda(gpus_list[0])\n","\n","        prediction = model(bicubic)\n","        print(prediction.shape, target.shape)\n","\n","        if prediction.shape != target.shape:\n","          H = prediction.shape[2]\n","          W = prediction.shape[3]\n","          target = target[:, :, 0:H, 0:W]\n","        # prediction 과 target 의 shape 이 맞지 않을때 맞춰줌\n","        \n","        if prediction.shape == target.shape:\n","          mse = criterion(prediction, target)\n","          psnr = 10 * log10(1 / mse.item())\n","          avg_psnr += psnr\n","          psnr_sq += psnr*psnr\n","          count_image += 1\n","        # Image.BICUBIC 에서 이미지의 H나 W가 3의 배수가 아니면 나머지를 버려버리기 때문에 prediction 과 target 의 shape 이 맞지 않는 경우가 생김\n","        \n","\n","        save_img(prediction.cpu().data, 'SR_'+file_name[0])\n","        save_img(bicubic.cpu().data, 'blur_'+file_name[0])\n","        # save_img(target.cpu().data, file_name[0]+'/original')\n","       \n","    average = avg_psnr/count_image\n","    variance = psnr_sq/count_image-average*average\n","        \n","        # psnr 의 분산\n","    print('Image Amount: %d' %(count_image))\n","    print(\"===> epoch number : %d\" % (epoch)) \n","    print(\"===> Processing Done, Average PSNR : %.4f\" % (average))\n","    print(\"===>PSNR Variance : %.4f\" % (variance))\n","    \n","'''\n","우리는 훈련시에 128x128 이미지를 SR 하도록 훈련 했지만,\n","test 에서 입력 이미지의 크기는 상관이 없다\n","왜냐하면, 우리는 훈련하여 'filter' 를 얻었고,\n","입력의 크기가 128x128 가 아니더라도 훈련된 filter 를 stride 하면서 Conv. 연산 해 주면 되는 것이기 때문이다.\n","'''\n","\n","##Eval Start!!!!\n","if __name__ == '__main__':\n","    eval()\n","    \n","print('finish')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","{'testBatchSize': 1, 'upscale_factor': 2, 'input_channel': 3, 'model_type': 'WCNN', 'input_dir': '/content/gdrive/My Drive/졸업논문/data_800개/test', 'test_dataset': 'low_color_test', 'output': '/content/gdrive/My Drive/졸업논문/졸업논문/scale=2/results_scale=2/', 'model': '/content/gdrive/My Drive/졸업논문/졸업논문/scale=2/weights_scale=2/WCNN_epoch_100.pth', 'pretrained': True, 'data_augmentation': False, 'gpu_mode': True, 'threads': 0, 'gpus': 1}\n","===> Loading datasets\n","Pre-trained SR model is loaded.\n","torch.Size([1, 3, 436, 700]) torch.Size([1, 3, 437, 700])\n","torch.Size([1, 3, 534, 800]) torch.Size([1, 3, 534, 800])\n","torch.Size([1, 3, 532, 800]) torch.Size([1, 3, 532, 800])\n","Image Amount: 2\n","===> epoch number : 100\n","===> Processing Done, Average PSNR : 23.7153\n","===>PSNR Variance : 0.1042\n","finish\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZXs3luv82Tug","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617725335864,"user_tz":-540,"elapsed":20778,"user":{"displayName":"김정기","photoUrl":"","userId":"02654207523640478753"}},"outputId":"7ba59b2b-f67b-45b0-ecba-9e3a238f9995"},"source":["# Test - blur 되고 down scale 된 이미지가 아닌 원본 이미지를 입력으로 넣음\n","\n","from __future__ import print_function\n","import argparse\n","\n","import os\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.autograd import Variable\n","from torch.utils.data import DataLoader\n","import torch.backends.cudnn as cudnn\n","from functools import reduce\n","from math import log10\n","\n","# from scipy.misc import imsave\n","import scipy.io as sio\n","import time\n","import cv2\n","import easydict\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","opt = easydict.EasyDict({ \n","    \"testBatchSize\": 1,     # 이미지를 1개씩불러옴 \n","    \"upscale_factor\": 3,    # Upscale 정도\n","    \"input_channel\": 3,     # ESPCN model 입력의 Channel (color = 3, gray = 1)\n","\n","    \"model_type\": \"ESPCN\",         # 모델이름\n","    \n","    \"input_dir\":\"/content/gdrive/My Drive/졸업논문/data_800개/test\",  # test dataset 불러올위치\n","    \"test_dataset\": \"Color_test\",                             # test에 사용할 dataset 종류\n","    \"output\": \"/content/gdrive/My Drive/졸업논문/ESPCN/results/\", # 결과영상 저장위치\n","    \"model_type\": \"ESPCN\",\n","    \"model\": \"/content/gdrive/My Drive/졸업논문/ESPCN/weights/ESPCN_epoch_200.pth\",\n","    # test에 사용할 weight 불러올 파일 경로\n","    \n","    \"pretrained\": True,\n","    \"data_augmentation\": False,\n","    \"gpu_mode\": True,\n","    \"threads\": 0, \n","    \"gpus\": 1 # 사용할 gpu 번호\n","    })\n","\n","'''\n","1. GPU 설정 및 parameter print\n","'''\n","gpus_list = range(opt.gpus)\n","cudnn.benchmark = True\n","print(opt)\n","\n","cuda = opt.gpu_mode\n","if cuda and not torch.cuda.is_available():\n","    raise Exception(\"No GPU found, please run without --cuda\")\n","\n","'''\n","2. Test Data 로드\n","'''\n","print('===> Loading datasets')\n","test_set = get_eval_set(os.path.join(opt.input_dir,opt.test_dataset), opt.upscale_factor)\n","testing_data_loader = DataLoader(dataset=test_set, num_workers=opt.threads, batch_size=opt.testBatchSize, shuffle=False)\n","\n","'''\n","3. Criterion 정의 \n","  -> MSE loss 사용\n","'''\n","criterion = nn.MSELoss() \n","\n","'''\n","4. NN 정의\n","'''\n","model = model = ESPCN(input_channel=3, base_channel=64, upscale_factor=3, activation='tanh', norm='batch')\n","\n","'''\n","5. pretrained model 및 GPU 사용 여부 설정\n","'''\n","if cuda:\n","    model = model.cuda(gpus_list[0])\n","    model = torch.nn.DataParallel(model, device_ids=gpus_list)\n","    criterion = criterion.cuda(gpus_list[0])\n","if opt.pretrained:\n","    model_name = os.path.join(opt.model)\n","    checkpoint = torch.load(model_name)\n","\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","    loss = checkpoint['loss']\n","    opt.start_epoch = checkpoint['epoch']\n","    print('Pre-trained SR model is loaded.')\n","    # pretrained model 불러오기\n","    \n","'''\n","6. 이미지 저장 함수 -> 원본 이미지의 크기 그대로 저장 됨\n","'''\n","def save_img(img, img_name):\n","    save_img = img.squeeze().clamp(0, 1).numpy().transpose(1,2,0)\n","    # save img\n","    save_dir=os.path.join(opt.output,opt.test_dataset)\n","    if not os.path.exists(save_dir):\n","        os.makedirs(save_dir)\n","        \n","    save_fn = save_dir +'/'+ img_name\n","    cv2.imwrite(save_fn, cv2.cvtColor(save_img*255, cv2.COLOR_BGR2RGB),  [cv2.IMWRITE_PNG_COMPRESSION, 0])\n","    \n","'''\n","7. 한번의 epoch 에서 수행하는 과정 정의\n","'''\n","def eval():\n","    avg_psnr = 0\n","    psnr_sq = 0\n","    model.eval()\n","    # model.eval() 을 호출하여 평가(test) 모드로 변환 \n","    \n","    for batch_data in testing_data_loader:\n","        with torch.no_grad():\n","            input, blur_img, target, file_name = Variable(batch_data[0]), Variable(batch_data[1]), Variable(batch_data[2]), batch_data[3] \n","                                                                \n","        if cuda:\n","            input = input.cuda(gpus_list[0])\n","            blur_img = blur_img.cuda(gpus_list[0])\n","            target = target.cuda(gpus_list[0])\n","\n","        SR_img = model(target)\n","        # target = 원본 이미지 -> 그러므로 원본 이미지가 그대로 들어가서 3배 scale 됨\n","        print(SR_img.shape, target.shape)\n","      \n","      \n","        save_img(SR_img.cpu().data, 'Origin_SR_'+file_name[0])\n","    \n","'''\n","우리는 훈련시에 128x128 이미지를 SR 하도록 훈련 했지만,\n","test 에서 입력 이미지의 크기는 상관이 없다\n","왜냐하면, 우리는 훈련하여 'filter' 를 얻었고,\n","입력의 크기가 128x128 가 아니더라도 훈련된 filter 를 stride 하면서 Conv. 연산 해 주면 되는 것이기 때문이다.\n","'''\n","\n","##Eval Start!!!!\n","if __name__ == '__main__':\n","    eval()\n","    \n","print('finish')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","{'testBatchSize': 1, 'upscale_factor': 3, 'input_channel': 3, 'model_type': 'ESPCN', 'input_dir': '/content/gdrive/My Drive/졸업논문/data_800개/test', 'test_dataset': 'Color_test', 'output': '/content/gdrive/My Drive/졸업논문/ESPCN/results/', 'model': '/content/gdrive/My Drive/졸업논문/ESPCN/weights/ESPCN_epoch_200.pth', 'pretrained': True, 'data_augmentation': False, 'gpu_mode': True, 'threads': 0, 'gpus': 1}\n","===> Loading datasets\n","Pre-trained SR model is loaded.\n","torch.Size([1, 3, 6120, 4068]) torch.Size([1, 3, 2040, 1356])\n","torch.Size([1, 3, 4932, 6120]) torch.Size([1, 3, 1644, 2040])\n","torch.Size([1, 3, 4068, 6120]) torch.Size([1, 3, 1356, 2040])\n","torch.Size([1, 3, 4068, 6120]) torch.Size([1, 3, 1356, 2040])\n","finish\n"],"name":"stdout"}]}]}