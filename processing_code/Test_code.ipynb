{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Test_code.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyMysYcEgz/U3GUGxf6PaqrA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rDAv-ZE8ZJck","executionInfo":{"status":"ok","timestamp":1620669144562,"user_tz":-540,"elapsed":876,"user":{"displayName":"김정기","photoUrl":"","userId":"02654207523640478753"}},"outputId":"37362316-4ebd-4153-e597-6e93ca7f463c"},"source":["# sample 0\n","\n","import numpy as np\n","import math\n","import os\n","import torch\n","import torch.nn as nn\n","import torch.backends.cudnn as cudnn\n","from google.colab import drive\n","from torchsummary import summary\n","\n","drive.mount('/content/gdrive')\n","\n","class ConvBlock(nn.Module):\n","    def __init__(self, input_size, output_size, kernel_size=3, stride=1, padding=1, bias=True, activation='prelu', norm=None):\n","        super(ConvBlock, self).__init__()\n","        self.conv = torch.nn.Conv2d(input_size, output_size, kernel_size, stride, padding, bias=bias)\n","\n","        self.norm = norm\n","        if self.norm =='batch':\n","            self.bn = torch.nn.BatchNorm2d(output_size)\n","        elif self.norm == 'instance':\n","            self.bn = torch.nn.InstanceNorm2d(output_size)\n","        \n","        # self.bn : Conv Layer 출력에서 normalization 을 Instance 로 할지 Batch 로 할지 선택\n","        \n","        self.activation = activation\n","        if self.activation == 'relu':\n","            self.act = torch.nn.ReLU(True)\n","        elif self.activation == 'prelu':\n","            self.act = torch.nn.PReLU()\n","        elif self.activation == 'lrelu':\n","            self.act = torch.nn.LeakyReLU(0.2, True)\n","        elif self.activation == 'tanh':\n","            self.act = torch.nn.Tanh()\n","        elif self.activation == 'sigmoid':\n","            self.act = torch.nn.Sigmoid()\n","        \n","        # self.act : Conv Layer 출력 Activation Function 선택\n","        \n","    def forward(self, x):\n","        if self.norm is not None:\n","            out = self.bn(self.conv(x))\n","        else:\n","            out = self.conv(x)\n","\n","        if self.activation is not None:\n","            return self.act(out)\n","        else:\n","            return out\n","\n","class SRCNN(nn.Module):\n","    def __init__(self, num_channels, base_filter, scale_factor):\n","        super(SRCNN, self).__init__()\n","        \n","        self.layer1 = ConvBlock(num_channels, base_filter, kernel_size=9, stride=1, padding=4, activation='relu', norm=None)\n","        self.layer2 = ConvBlock(base_filter, base_filter // 2, kernel_size=1, stride=1, padding=0, activation='relu', norm=None)   \n","        self.layer3 = ConvBlock(base_filter // 2, 3, kernel_size=5, stride=1, padding=2, activation=None, norm=None)\n","       \n","    def forward(self, x):\n","        f1 = self.layer1(x)\n","        f2 = self.layer2(f1)\n","        y = self.layer3(f2)\n","        \n","        return y\n","\n","'''\n","1. GPU 설정 및 parameter print\n","'''\n","gpus_list = range(1)\n","cudnn.benchmark = True\n","\n","cuda = True\n","if cuda and not torch.cuda.is_available():\n","    raise Exception(\"No GPU found, please run without --cuda\")\n","\n","model = SRCNN(num_channels = 16, base_filter=32, scale_factor=3)\n","\n","'''\n","4. GPU 사용 여부 및 pretrained model 사용 여부 설정\n","'''\n","if cuda:\n","    model = model.cuda(gpus_list[0])\n","    model = torch.nn.DataParallel(model, device_ids=gpus_list)\n","\n","summary(model, (16,32,32))\n","    "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 32, 32, 32]          41,504\n","              ReLU-2           [-1, 32, 32, 32]               0\n","         ConvBlock-3           [-1, 32, 32, 32]               0\n","            Conv2d-4           [-1, 16, 32, 32]             528\n","              ReLU-5           [-1, 16, 32, 32]               0\n","         ConvBlock-6           [-1, 16, 32, 32]               0\n","            Conv2d-7            [-1, 3, 32, 32]           1,203\n","         ConvBlock-8            [-1, 3, 32, 32]               0\n","             SRCNN-9            [-1, 3, 32, 32]               0\n","================================================================\n","Total params: 43,235\n","Trainable params: 43,235\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.06\n","Forward/backward pass size (MB): 1.20\n","Params size (MB): 0.16\n","Estimated Total Size (MB): 1.42\n","----------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hQh2ZVS5TDCr","executionInfo":{"status":"ok","timestamp":1620711779816,"user_tz":-540,"elapsed":945,"user":{"displayName":"김정기","photoUrl":"","userId":"02654207523640478753"}},"outputId":"0af2ba2d-eda1-4652-b457-61a153e7902e"},"source":["# sample 1\n","\n","import numpy as np\n","import math\n","import os\n","import torch\n","import torch.nn as nn\n","import torch.backends.cudnn as cudnn\n","from google.colab import drive\n","from torchsummary import summary\n","\n","drive.mount('/content/gdrive')\n","\n","class Channel_weighted_Conv(nn.Module):\n","  def __init__(self, input_size, kernel_size, stride=1, bias=True):\n","    super(Channel_weighted_Conv, self).__init__()\n","    self.input_size = input_size \n","    # input_size = r^2\n","\n","    self.conv = torch.nn.Conv2d(1, 1, kernel_size, stride, padding=int((kernel_size-1)/2), bias=bias)\n","    self.PS =  nn.PixelShuffle (upscale_factor = int(math.sqrt(input_size)))\n","    self.inner_conv = torch.nn.Conv2d(1, 1, kernel_size=int(math.sqrt(input_size)), stride=int(math.sqrt(input_size)), padding=0, bias=bias)\n","\n","    '''\n","    apply 함수로 initialization 하기 힘들기 때문에 class 내에서 initialization 을 수행하도록 함\n","    '''\n","    for m in self.modules():\n","        # 이 class 에서 정의한 self.(변수)[인스턴스 변수] 목록 (conv, PS, inner_conv) 불러오기 \n","            classname = m.__class__.__name__\n","            # 불러온 module의 class 이름\n","            if classname.find('Conv2d') != -1:\n","                torch.nn.init.kaiming_normal_(m.weight)\n","                if m.bias is not None:\n","                    m.bias.data.zero_()\n","            # Conv2d Layer 라면 He 방법으로 해당 Layer 의 weight 들을 초기화, bias 가 True 면 bias 를 0 으로 초기화\n","            elif classname.find('ConvTranspose2d') != -1:\n","                torch.nn.init.kaiming_normal_(m.weight)\n","                if m.bias is not None:\n","                    m.bias.data.zero_()\n","           # ConvTranspose2d Layer 라면 He 방법으로 해당 Layer 의 weight 들을 초기화, bias 가 True 면 bias 를 0 으로 초기화:\n","             \n","            \n","            \n","  def forward(self, x):\n","    s = self.conv(x[:, 0:1, :, :])\n","\n","    for i in range(1, self.input_size):\n","      m = self.conv(x[:, i:i+1, :, :])\n","      s = torch.cat([s, m], dim=1)\n","    \n","    ps = self.PS(s)\n","    out = self.inner_conv(ps)\n","    return out\n","\n","class WCNN_block(nn.Module):\n","  def __init__(self, input_size, output_size, kernel_size):\n","    super(WCNN_block, self).__init__()\n","    self.filters = [0]*output_size\n","\n","    '''\n","    여기서 filter 갯수(=output_size)만큼 Channel_weighted_Conv 을 list 형태로 담고,\n","    '''\n","    self.filters = nn.ModuleList([Channel_weighted_Conv(input_size, kernel_size, stride=1, bias=True) for _ in range(0, output_size)])\n","    self.filter_num = output_size\n","  \n","  def forward(self, x):\n","    '''\n","    여기서 각 Channel_weighted_Conv에 x(입력) 를 대입하고 나온 출력을 concatenation 해 준다.\n","    -> ModuleList 는 list 안의 각 Module 을 하나씩 접근 할 수 있게 해 줌\n","    '''\n","    out = self.filters[0](x)\n","    for i in range(1, self.filter_num):\n","      filtering = self.filters[i](x)\n","      out = torch.cat([out, filtering], dim=1)\n","    # out.shape = [batch, K, N, N]\n","    # out = 각 filter 들의 WCNN 결과의 concatenation\n","    return out\n","\n","class WCNN(nn.Module):\n","    def __init__(self):\n","        super(WCNN, self).__init__()\n","        \n","        '''\n","        1. layer2 만을 WCNN_block 으로 바꿈\n","        2. WCNN_block 의 input_size = r^2 이어야 하는 것을 유의함\n","        '''\n","        self.layer1 = nn.Sequential(\n","            nn.Conv2d(3,64,kernel_size=9),\n","            nn.ReLU(),\n","        )\n","        self.layer2 = nn.Sequential(\n","            WCNN_block(input_size=64, output_size=32, kernel_size=3),\n","            nn.ReLU(),\n","        )\n","        # WCNN_block 의 Kernel_size = 홀수 여야 출력이미지의 size 가 입력과 같아진다\n","        self.layer3 = nn.Sequential(\n","            nn.Conv2d(32,3,kernel_size=5),\n","        )\n","\n","    def forward(self, x):\n","        f1 = self.layer1(x)\n","        f2 = self.layer2(f1)\n","        y = self.layer3(f2)\n","        \n","        return y\n","\n","'''\n","1. GPU 설정 및 parameter print\n","'''\n","gpus_list = range(1)\n","cudnn.benchmark = True\n","\n","cuda = True\n","if cuda and not torch.cuda.is_available():\n","    raise Exception(\"No GPU found, please run without --cuda\")\n","\n","model = WCNN()\n","\n","'''\n","4. GPU 사용 여부 및 pretrained model 사용 여부 설정\n","'''\n","if cuda:\n","    model = model.cuda(gpus_list[0])\n","    model = torch.nn.DataParallel(model, device_ids=gpus_list)\n","\n","# summary(model, (3,32,32))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","check\n","check\n","check\n","check\n","check\n","check\n","check\n","check\n","check\n","check\n","check\n","check\n","check\n","check\n","check\n","check\n","check\n","check\n","check\n","check\n","check\n","check\n","check\n","check\n","check\n","check\n","check\n","check\n","check\n","check\n","check\n","check\n","check\n","check\n","check\n","check\n","check\n","check\n","check\n","check\n","check\n","check\n","check\n","check\n","check\n","check\n","check\n","check\n","check\n","check\n","check\n","check\n","check\n","check\n","check\n","check\n","check\n","check\n","check\n","check\n","check\n","check\n","check\n","check\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z5sPtmo-PhM_","executionInfo":{"status":"ok","timestamp":1620675934294,"user_tz":-540,"elapsed":604,"user":{"displayName":"김정기","photoUrl":"","userId":"02654207523640478753"}},"outputId":"f7c3bd7d-cec5-42b8-eaac-8510c00b4bb8"},"source":["# sample 2\n","\n","import numpy as np\n","import math\n","import os\n","import torch\n","import torch.nn as nn\n","import torch.backends.cudnn as cudnn\n","from google.colab import drive\n","from torchsummary import summary\n","\n","drive.mount('/content/gdrive')\n","\n","class Channel_weighted_Conv(nn.Module):\n","  def __init__(self, input_size, kernel_size, stride=1, bias=True):\n","    super(Channel_weighted_Conv, self).__init__()\n","    self.input_size = input_size \n","    # input_size = r^2\n","\n","    self.conv = torch.nn.Conv2d(1, 1, kernel_size, stride, padding=int((kernel_size-1)/2), bias=bias)\n","    self.PS =  nn.PixelShuffle (upscale_factor = int(math.sqrt(input_size)))\n","    self.inner_conv = torch.nn.Conv2d(1, 1, kernel_size=int(math.sqrt(input_size)), stride=int(math.sqrt(input_size)), padding=0, bias=bias)\n","\n","  def forward(self, x):\n","    s = self.conv(x[:, 0:1, :, :])\n","\n","    for i in range(1, self.input_size):\n","      m = self.conv(x[:, i:i+1, :, :])\n","      s = torch.cat([s, m], dim=1)\n","    \n","    print('S의 shape = ',s.shape)\n","    ps = self.PS(s)\n","    print('PS의 shape = ',ps.shape)\n","    out = self.inner_conv(ps)\n","    print('OUT의 shape = ',out.shape)\n","    return out\n","    \n","\n","'''\n","1. GPU 설정 및 parameter print\n","'''\n","gpus_list = range(1)\n","cudnn.benchmark = True\n","\n","cuda = True\n","if cuda and not torch.cuda.is_available():\n","    raise Exception(\"No GPU found, please run without --cuda\")\n","\n","model = Channel_weighted_Conv(input_size=16, kernel_size=5)\n","\n","'''\n","4. GPU 사용 여부 및 pretrained model 사용 여부 설정\n","'''\n","if cuda:\n","    model = model.cuda(gpus_list[0])\n","    model = torch.nn.DataParallel(model, device_ids=gpus_list)\n","    \n","summary(model, (16,32,32))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","S의 shape =  torch.Size([2, 16, 32, 32])\n","PS의 shape =  torch.Size([2, 1, 128, 128])\n","OUT의 shape =  torch.Size([2, 1, 32, 32])\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1            [-1, 1, 32, 32]              26\n","            Conv2d-2            [-1, 1, 32, 32]              26\n","            Conv2d-3            [-1, 1, 32, 32]              26\n","            Conv2d-4            [-1, 1, 32, 32]              26\n","            Conv2d-5            [-1, 1, 32, 32]              26\n","            Conv2d-6            [-1, 1, 32, 32]              26\n","            Conv2d-7            [-1, 1, 32, 32]              26\n","            Conv2d-8            [-1, 1, 32, 32]              26\n","            Conv2d-9            [-1, 1, 32, 32]              26\n","           Conv2d-10            [-1, 1, 32, 32]              26\n","           Conv2d-11            [-1, 1, 32, 32]              26\n","           Conv2d-12            [-1, 1, 32, 32]              26\n","           Conv2d-13            [-1, 1, 32, 32]              26\n","           Conv2d-14            [-1, 1, 32, 32]              26\n","           Conv2d-15            [-1, 1, 32, 32]              26\n","           Conv2d-16            [-1, 1, 32, 32]              26\n","     PixelShuffle-17          [-1, 1, 128, 128]               0\n","           Conv2d-18            [-1, 1, 32, 32]              17\n","Channel_weighted_Conv-19            [-1, 1, 32, 32]               0\n","================================================================\n","Total params: 433\n","Trainable params: 433\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.06\n","Forward/backward pass size (MB): 0.27\n","Params size (MB): 0.00\n","Estimated Total Size (MB): 0.33\n","----------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KxE9U5VhPodR","executionInfo":{"status":"ok","timestamp":1620666612376,"user_tz":-540,"elapsed":716,"user":{"displayName":"김정기","photoUrl":"","userId":"02654207523640478753"}},"outputId":"067b8f34-666f-409f-f9f7-689aa3bcce97"},"source":["# sample 3\n","\n","import numpy as np\n","import math\n","import os\n","import torch\n","import torch.nn as nn\n","import torch.backends.cudnn as cudnn\n","from google.colab import drive\n","from torchsummary import summary\n","\n","drive.mount('/content/gdrive')\n","\n","class test(nn.Module):\n","  def __init__(self, input_size):\n","    super(test, self).__init__()\n","    self.input_size = input_size\n","    self.conv = torch.nn.Conv2d(1, 1, 3, 1, 1, bias=True)\n","\n","  def forward(self, x):\n","    out = self.conv(x[:, 0:1, :, :])\n","\n","    for i in range(1, self.input_size):\n","      m = self.conv(x[:,i:i+1,:,:])\n","      out = torch.cat([out, m], dim=1)\n","    return out\n","  \n","  def num_dim(self, x):\n","    size = x.size() # 입력의 모든 차원\n","    print(size)\n","    \n","\n","'''\n","1. GPU 설정 및 parameter print\n","'''\n","gpus_list = range(1)\n","cudnn.benchmark = True\n","\n","cuda = True\n","if cuda and not torch.cuda.is_available():\n","    raise Exception(\"No GPU found, please run without --cuda\")\n","\n","model = test(input_size=16)\n","\n","'''\n","4. GPU 사용 여부 및 pretrained model 사용 여부 설정\n","'''\n","if cuda:\n","    model = model.cuda(gpus_list[0])\n","    model = torch.nn.DataParallel(model, device_ids=gpus_list)\n","    \n","summary(model, (16,32,32))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1            [-1, 1, 32, 32]              10\n","            Conv2d-2            [-1, 1, 32, 32]              10\n","            Conv2d-3            [-1, 1, 32, 32]              10\n","            Conv2d-4            [-1, 1, 32, 32]              10\n","            Conv2d-5            [-1, 1, 32, 32]              10\n","            Conv2d-6            [-1, 1, 32, 32]              10\n","            Conv2d-7            [-1, 1, 32, 32]              10\n","            Conv2d-8            [-1, 1, 32, 32]              10\n","            Conv2d-9            [-1, 1, 32, 32]              10\n","           Conv2d-10            [-1, 1, 32, 32]              10\n","           Conv2d-11            [-1, 1, 32, 32]              10\n","           Conv2d-12            [-1, 1, 32, 32]              10\n","           Conv2d-13            [-1, 1, 32, 32]              10\n","           Conv2d-14            [-1, 1, 32, 32]              10\n","           Conv2d-15            [-1, 1, 32, 32]              10\n","           Conv2d-16            [-1, 1, 32, 32]              10\n","             test-17           [-1, 16, 32, 32]               0\n","================================================================\n","Total params: 160\n","Trainable params: 160\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.06\n","Forward/backward pass size (MB): 0.25\n","Params size (MB): 0.00\n","Estimated Total Size (MB): 0.31\n","----------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":287},"id":"MMGFS_NxPnUV","executionInfo":{"status":"error","timestamp":1620671957158,"user_tz":-540,"elapsed":678,"user":{"displayName":"김정기","photoUrl":"","userId":"02654207523640478753"}},"outputId":"cec68dad-d4df-4230-9f7c-25ec0ff8cb19"},"source":["# sample 4\n","\n","import torch\n","\n","t1 = torch.tensor([[[[1,2,3],\n","                   [4,5,6],\n","                   [7,8,9]],\n","                  [[1,2,3],\n","                   [4,5,6],\n","                   [7,8,9]]]\n","                 ,[[[1,2,3],\n","                   [4,5,6],\n","                   [7,8,9.]],\n","                  [[1,2,3],\n","                   [4,5,6],\n","                   [7,8,9]]]])\n","\n","t2 = torch.tensor([[[[0,0,0],\n","                   [4,5,6],\n","                   [7,8,9]],\n","                  [[0,0,0],\n","                   [4,5,6],\n","                   [7,8,9]]]\n","                 ,[[[0,0,0],\n","                   [4,5,6],\n","                   [7,8,9.]],\n","                  [[0,0,0],\n","                   [4,5,6],\n","                   [7,8,9]]]])\n","\n","print(t1.shape)\n","print(t2.shape)\n","print(torch.cat([out, t2], dim=1).shape)\n","print(t1[:, 1:2,:,:].size())\n","\n","def printf(a):\n","  print(a)\n","  return 0\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["torch.Size([2, 2, 3, 3])\n","torch.Size([2, 2, 3, 3])\n"],"name":"stdout"},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-46-5ae6824a6b11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'out' is not defined"]}]},{"cell_type":"code","metadata":{"id":"SQqSuKNABZ3u"},"source":["def get_patch(img_in, img_tar, img_bic, patch_size, scale, ix=-1, iy=-1):\n","    (ih, iw) = img_in.size\n","    (th, tw) = (scale * ih, scale * iw)\n","\n","    patch_mult = scale #if len(scale) > 1 else 1\n","    tp = patch_mult * patch_size\n","    # tp = upscale_factor*n (n = patch_size)\n","    ip = tp // scale\n","    # ip = n (n = patch_size)\n","    \n","    if ix == -1:\n","        ix = random.randrange(0, iw - ip + 1)\n","    if iy == -1:\n","        iy = random.randrange(0, ih - ip + 1)\n","\n","    (tx, ty) = (scale * ix, scale * iy)\n","\n","    img_in = img_in.crop((iy,ix,iy + ip, ix + ip))\n","    # 원본이미지 임의의 영역을 n x n 크기로 자름\n","    img_tar = img_tar.crop((ty,tx,ty + tp, tx + tp))\n","    # downscale 한 이미지 임의의 영역을 upscale_factor*n x upscale_factor*n 크기로 자름\n","    img_bic = img_bic.crop((ty,tx,ty + tp, tx + tp))\n","    # upscale 한 이미지 임의의 영역을 upscale_factor*n x upscale_factor*n 크기로 자름            \n","    info_patch = {\n","        'ix': ix, 'iy': iy, 'ip': ip, 'tx': tx, 'ty': ty, 'tp': tp}\n","    # info_patch 에는 어떤 크기로 crop 했는지에 대한 정보가 있음\n","    return img_in, img_tar, img_bic, info_patch\n","\n","'''\n","입력 이미지의 가로/세로 pixel 수가 upscale_factor 의 배수가 아니면 입력 이미지를 crop 하여 가로 세로를 upscale_factor 의 배수로 맞춰주는 함수를\n","'''\n","def get_patch()\n","\n","\n","    \n","'''\n","8.사용자 정의 data 로드 - Test Data \n","   -> file 이름까지 사용자 정의 데이터화 시킴\n","   -> get_patch 함수를 사용하지 않기 때문에, SRCNN 의 입력으로 (원본 이미지 xscale) 된 이미지가 들어감\n","'''\n","class DatasetFromFolderEval(data.Dataset):\n","    def __init__(self, lr_dir, upscale_factor, transform=None):\n","        super(DatasetFromFolderEval, self).__init__()\n","        self.image_filenames = [join(lr_dir, x) for x in listdir(lr_dir) if is_image_file(x)]\n","        self.upscale_factor = upscale_factor\n","        self.transform = transform\n","\n","    def __getitem__(self, index):\n","        target = load_img(self.image_filenames[index])\n","        # target = load_img 함수를 이용하여 index 번째 image 를 RGB 로 불러온 이미지\n","        _, file = os.path.split(self.image_filenames[index])\n","        # file = 이미지 경로 list 에서 file 이름만 잘라 냄\n","\n","        input = target.resize((int(target.size[0]/self.upscale_factor),int(target.size[1]/self.upscale_factor)), Image.BICUBIC) \n","        # input = target 으로 불러온 이미지를 Bicubic 으로 downscale 한 이미지\n","        bicubic = rescale_img(input, self.upscale_factor)\n","        # bicubic = rescale_img 함수로 input 을 다시 같은 비율로 upscale 한 이미지\n","\n","        input, target, bicubic, _ = get_patch(input,target,bicubic,self.patch_size, self.upscale_factor)\n","        # input, target, bicubic 이미지를 (upscale_factor*patch_size x upscale_factor*patch_size) 로 crop\n","        \n","        if self.transform:\n","            input = self.transform(input)\n","            bicubic = self.transform(bicubic)\n","            target = self.transform(target)\n","         # self.transform = True 라면, 세 이미지를 PIL image 에서 Tensor로 바꾸어 줌\n","        \n","        return input, bicubic, target, file\n","        # file 이름까지 return\n","      \n","    def __len__(self):\n","        return len(self.image_filenames)"],"execution_count":null,"outputs":[]}]}